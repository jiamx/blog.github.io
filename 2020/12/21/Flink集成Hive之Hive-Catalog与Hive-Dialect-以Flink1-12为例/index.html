<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="记录朴实无华且枯燥的生活"><title>Flink集成Hive之Hive Catalog与Hive Dialect--以Flink1.12为例 | Jmx's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + '912b6cfc43243cd27aeb428f7dbf7823';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();</script><script type="text/javascript" src="/js/toc.js?v=0.0.0"></script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Flink集成Hive之Hive Catalog与Hive Dialect--以Flink1.12为例</h1><a id="logo" href="/.">Jmx's Blog</a><p class="description">Keep it Simple and Stupid!</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-pied-piper-alt"> 关于</i></a><a href="/tags"><i class="fa fa-tags"> 标签</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Flink集成Hive之Hive Catalog与Hive Dialect--以Flink1.12为例</h1><div class="post-meta">Dec 21, 2020<span> | </span><span class="category"><a href="/categories/Flink/">Flink</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 2.4k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 10</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><p>在上一篇分享<a href="https://mp.weixin.qq.com/s/99ehmNzJVwW3cOrw_UkGsg" target="_blank" rel="noopener">Flink集成Hive之快速入门–以Flink1.12为例</a>中，介绍了Flink集成Hive的进本步骤。本文分享，将继续介绍Flink集成Hive的另外两个概念：<strong>Hive Catalog与Hive Dialect</strong>。本文包括以下内容，希望对你有所帮助。</p>
<ul>
<li>什么是Hive Catalog</li>
<li>如何使用Hive Catalog</li>
<li>什么是Hive Dialect</li>
<li>如何使用Hive Dialect</li>
</ul>
<blockquote>
<p>公众号『大数据技术与数仓』，回复『资料』领取大数据资料包</p>
</blockquote>
<h2 id="什么是Hive-Catalog"><a href="#什么是Hive-Catalog" class="headerlink" title="什么是Hive Catalog"></a>什么是Hive Catalog</h2><p>我们知道，Hive使用Hive Metastore(HMS)存储元数据信息，使用关系型数据库来持久化存储这些信息。所以，Flink集成Hive需要打通Hive的metastore，去管理Flink的元数据，这就是Hive Catalog的功能。</p>
<p>Hive Catalog的主要作用是使用Hive MetaStore去管理Flink的元数据。Hive Catalog可以将元数据进行持久化，这样后续的操作就可以反复使用这些表的元数据，而不用每次使用时都要重新注册。如果不去持久化catalog，那么在每个session中取处理数据，都要去重复地创建元数据对象，这样是非常耗时的。</p>
<h2 id="如何使用Hive-Catalog"><a href="#如何使用Hive-Catalog" class="headerlink" title="如何使用Hive Catalog"></a>如何使用Hive Catalog</h2><p>HiveCatalog是开箱即用的，所以，一旦配置好Flink与Hive集成，就可以使用HiveCatalog。比如，我们通过FlinkSQL 的DDL语句创建一张kafka的数据源表，立刻就能查看该表的元数据信息。</p>
<p>HiveCatalog可以处理两种类型的表：一种是Hive兼容的表，另一种是普通表(generic table)。其中Hive兼容表是以兼容Hive的方式来存储的，所以，对于Hive兼容表而言，我们既可以使用Flink去操作该表，又可以使用Hive去操作该表。</p>
<p>普通表是对Flink而言的，当使用HiveCatalog创建一张普通表，仅仅是使用Hive MetaStore将其元数据进行了持久化，所以可以通过Hive查看这些表的元数据信息(通过DESCRIBE FORMATTED命令)，但是不能通过Hive去处理这些表，因为语法不兼容。</p>
<p>对于是否是普通表，Flink使用<strong>is_generic</strong>属性进行标识。默认情况下，创建的表是普通表，即<strong>is_generic=true</strong>，如果要创建Hive兼容表，需要在建表属性中指定<strong>is_generic=false</strong>。</p>
<blockquote>
<p>尖叫提示：</p>
<p>由于依赖Hive Metastore，所以必须开启Hive MetaStore服务</p>
</blockquote>
<h3 id="代码中使用Hive-Catalog"><a href="#代码中使用Hive-Catalog" class="headerlink" title="代码中使用Hive Catalog"></a>代码中使用Hive Catalog</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">EnvironmentSettings settings = EnvironmentSettings.newInstance().useBlinkPlanner().build();</span><br><span class="line">     TableEnvironment tableEnv = TableEnvironment.create(settings);</span><br><span class="line"></span><br><span class="line">     String name            = <span class="string">"myhive"</span>;</span><br><span class="line">     String defaultDatabase = <span class="string">"default"</span>;</span><br><span class="line">     String hiveConfDir = <span class="string">"/opt/modules/apache-hive-2.3.4-bin/conf"</span>;</span><br><span class="line"></span><br><span class="line">     HiveCatalog hive = <span class="keyword">new</span> HiveCatalog(name, defaultDatabase, hiveConfDir);</span><br><span class="line">     tableEnv.registerCatalog(<span class="string">"myhive"</span>, hive);</span><br><span class="line">     <span class="comment">// 使用注册的catalog</span></span><br><span class="line">     tableEnv.useCatalog(<span class="string">"myhive"</span>);</span><br></pre></td></tr></table></figure>

<h3 id="Flink-SQLCli中使用Hive-Catalog"><a href="#Flink-SQLCli中使用Hive-Catalog" class="headerlink" title="Flink SQLCli中使用Hive Catalog"></a>Flink SQLCli中使用Hive Catalog</h3><p>在FlinkSQL Cli中使用Hive Catalog很简单，只需要配置一下sql-cli-defaults.yaml文件即可。配置内容如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">catalogs:</span><br><span class="line">   - name: myhive</span><br><span class="line">     <span class="built_in">type</span>: hive</span><br><span class="line">     default-database: default</span><br><span class="line">     hive-conf-dir: /opt/modules/apache-hive-2.3.4-bin/conf</span><br></pre></td></tr></table></figure>

<img src="//jiamaoxiang.top/2020/12/21/Flink集成Hive之Hive-Catalog与Hive-Dialect-以Flink1-12为例/yarm.png" style="zoom: 67%;">

<p>在FlinkSQL Cli中创建一张kafka表，该表默认为普通表，即is_generic=true</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> user_behavior ( </span><br><span class="line">    <span class="string">`user_id`</span> <span class="built_in">BIGINT</span>, <span class="comment">-- 用户id</span></span><br><span class="line">    <span class="string">`item_id`</span> <span class="built_in">BIGINT</span>, <span class="comment">-- 商品id</span></span><br><span class="line">    <span class="string">`cat_id`</span> <span class="built_in">BIGINT</span>, <span class="comment">-- 品类id</span></span><br><span class="line">    <span class="string">`action`</span> <span class="keyword">STRING</span>, <span class="comment">-- 用户行为</span></span><br><span class="line">    <span class="string">`province`</span> <span class="built_in">INT</span>, <span class="comment">-- 用户所在的省份</span></span><br><span class="line">    <span class="string">`ts`</span> <span class="built_in">BIGINT</span>, <span class="comment">-- 用户行为发生的时间戳</span></span><br><span class="line">    <span class="string">`proctime`</span> <span class="keyword">AS</span> PROCTIME(), <span class="comment">-- 通过计算列产生一个处理时间列</span></span><br><span class="line">    <span class="string">`eventTime`</span> <span class="keyword">AS</span> TO_TIMESTAMP(FROM_UNIXTIME(ts, <span class="string">'yyyy-MM-dd HH:mm:ss'</span>)), <span class="comment">-- 事件时间</span></span><br><span class="line">     WATERMARK <span class="keyword">FOR</span> eventTime <span class="keyword">AS</span> eventTime - <span class="built_in">INTERVAL</span> <span class="string">'5'</span> <span class="keyword">SECOND</span>  <span class="comment">-- 定义watermark</span></span><br><span class="line"> ) <span class="keyword">WITH</span> ( </span><br><span class="line">    <span class="string">'connector'</span> = <span class="string">'kafka'</span>, <span class="comment">-- 使用 kafka connector</span></span><br><span class="line">    <span class="string">'topic'</span> = <span class="string">'user_behavior'</span>, <span class="comment">-- kafka主题</span></span><br><span class="line">    <span class="string">'scan.startup.mode'</span> = <span class="string">'earliest-offset'</span>, <span class="comment">-- 偏移量</span></span><br><span class="line">    <span class="string">'properties.group.id'</span> = <span class="string">'group1'</span>, <span class="comment">-- 消费者组</span></span><br><span class="line">    <span class="string">'properties.bootstrap.servers'</span> = <span class="string">'kms-2:9092,kms-3:9092,kms-4:9092'</span>, </span><br><span class="line">    <span class="string">'format'</span> = <span class="string">'json'</span>, <span class="comment">-- 数据源格式为json</span></span><br><span class="line">    <span class="string">'json.fail-on-missing-field'</span> = <span class="string">'true'</span>,</span><br><span class="line">    <span class="string">'json.ignore-parse-errors'</span> = <span class="string">'false'</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>我们可以在Hive客户端中查看该表的元数据信息</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">hive (default)&gt; desc formatted  user_behavior;</span><br><span class="line">Table Parameters:                </span><br><span class="line">       ...</span><br><span class="line">        is_generic              true                </span><br><span class="line">      ...</span><br></pre></td></tr></table></figure>

<p>从上面的元数据信息可以看出，is_generic=true，说明该表是一张普通表，如果在Hive中去查看该表，则会报错。</p>
<p>上面创建的表是普通表，该表不能使用Hive去查询。那么，该如何创建一张Hive兼容表呢？我们只需要在建表的属性中显示指定<strong>is_generic=false</strong>即可，具体如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> hive_compatible_tbl ( </span><br><span class="line">    <span class="string">`user_id`</span> <span class="built_in">BIGINT</span>, <span class="comment">-- 用户id</span></span><br><span class="line">    <span class="string">`item_id`</span> <span class="built_in">BIGINT</span>, <span class="comment">-- 商品id</span></span><br><span class="line">    <span class="string">`cat_id`</span> <span class="built_in">BIGINT</span>, <span class="comment">-- 品类id</span></span><br><span class="line">    <span class="string">`action`</span> <span class="keyword">STRING</span>, <span class="comment">-- 用户行为</span></span><br><span class="line">    <span class="string">`province`</span> <span class="built_in">INT</span>, <span class="comment">-- 用户所在的省份</span></span><br><span class="line">    <span class="string">`ts`</span> <span class="built_in">BIGINT</span> <span class="comment">-- 用户行为发生的时间戳</span></span><br><span class="line"> ) <span class="keyword">WITH</span> ( </span><br><span class="line">    <span class="string">'connector'</span> = <span class="string">'kafka'</span>, <span class="comment">-- 使用 kafka connector</span></span><br><span class="line">    <span class="string">'topic'</span> = <span class="string">'user_behavior'</span>, <span class="comment">-- kafka主题</span></span><br><span class="line">    <span class="string">'scan.startup.mode'</span> = <span class="string">'earliest-offset'</span>, <span class="comment">-- 偏移量</span></span><br><span class="line">    <span class="string">'properties.group.id'</span> = <span class="string">'group1'</span>, <span class="comment">-- 消费者组</span></span><br><span class="line">    <span class="string">'properties.bootstrap.servers'</span> = <span class="string">'kms-2:9092,kms-3:9092,kms-4:9092'</span>, </span><br><span class="line">    <span class="string">'format'</span> = <span class="string">'json'</span>, <span class="comment">-- 数据源格式为json</span></span><br><span class="line">    <span class="string">'json.fail-on-missing-field'</span> = <span class="string">'true'</span>,</span><br><span class="line">    <span class="string">'json.ignore-parse-errors'</span> = <span class="string">'false'</span>,</span><br><span class="line">    <span class="string">'is_generic'</span> = <span class="string">'false'</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>当我们在Hive中查看该表的元数据信息时，可以看出：<strong>is_generic =false</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">hive (default)&gt; desc formatted hive_compatible_tbl;</span><br><span class="line">Table Parameters:                </span><br><span class="line">        ...           </span><br><span class="line">        is_generic              false               </span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>

<p>我们可以使用FlinkSQL Cli或者HiveCli向该表中写入数据，然后分别通过FlinkSQL Cli和Hive Cli去查看该表数据的变化</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">hive (default)&gt; insert into hive_compatible_tbl select 2020,1221,100,'buy',11,1574330486;</span><br><span class="line">hive (default)&gt; select * from hive_compatible_tbl;</span><br></pre></td></tr></table></figure>

<p>再在FlinkSQL Cli中查看该表，</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">Flink SQL&gt; select user_id,item_id,action from hive_compatible_tbl;</span><br><span class="line">                   user_id                   item_id                    action</span><br><span class="line">                      2020                      1221                       buy</span><br></pre></td></tr></table></figure>

<p>同样，我们可以在FlinkSQL Cli中去向该表中写入数据：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">Flink SQL&gt;  insert into hive_compatible_tbl select 2020,1222,101,'fav',11,1574330486;</span><br><span class="line">Flink SQL&gt; select user_id,item_id,action from hive_compatible_tbl;</span><br><span class="line"></span><br><span class="line">                   user_id                   item_id                    action</span><br><span class="line">                      2020                      1221                       buy</span><br><span class="line">                      2020                      1222                       fav</span><br></pre></td></tr></table></figure>

<blockquote>
<p>尖叫提示：</p>
<p>对于Hive兼容的表，需要注意数据类型，具体的数据类型对应关系以及注意点如下</p>
</blockquote>
<table>
<thead>
<tr>
<th align="center">Flink 数据类型</th>
<th align="center">Hive 数据类型</th>
</tr>
</thead>
<tbody><tr>
<td align="center">CHAR(p)</td>
<td align="center">CHAR(p)</td>
</tr>
<tr>
<td align="center">VARCHAR(p)</td>
<td align="center">VARCHAR(p)</td>
</tr>
<tr>
<td align="center">STRING</td>
<td align="center">STRING</td>
</tr>
<tr>
<td align="center">BOOLEAN</td>
<td align="center">BOOLEAN</td>
</tr>
<tr>
<td align="center">TINYINT</td>
<td align="center">TINYINT</td>
</tr>
<tr>
<td align="center">SMALLINT</td>
<td align="center">SMALLINT</td>
</tr>
<tr>
<td align="center">INT</td>
<td align="center">INT</td>
</tr>
<tr>
<td align="center">BIGINT</td>
<td align="center">LONG</td>
</tr>
<tr>
<td align="center">FLOAT</td>
<td align="center">FLOAT</td>
</tr>
<tr>
<td align="center">DOUBLE</td>
<td align="center">DOUBLE</td>
</tr>
<tr>
<td align="center">DECIMAL(p, s)</td>
<td align="center">DECIMAL(p, s)</td>
</tr>
<tr>
<td align="center">DATE</td>
<td align="center">DATE</td>
</tr>
<tr>
<td align="center">TIMESTAMP(9)</td>
<td align="center">TIMESTAMP</td>
</tr>
<tr>
<td align="center">BYTES</td>
<td align="center">BINARY</td>
</tr>
<tr>
<td align="center">ARRAY<t></t></td>
<td align="center">LIST<t></t></td>
</tr>
<tr>
<td align="center">MAP&lt;K, V&gt;</td>
<td align="center">MAP&lt;K, V&gt;</td>
</tr>
<tr>
<td align="center">ROW</td>
<td align="center">STRUCT</td>
</tr>
</tbody></table>
<p><strong>注意</strong>：</p>
<ul>
<li>Hive <code>CHAR(p)</code> 类型的最大长度为255</li>
<li>Hive <code>VARCHAR(p)</code>类型的最大长度为65535</li>
<li>Hive <code>MAP</code>类型的key仅支持基本类型，而Flink’s <code>MAP</code> 类型的key执行任意类型</li>
<li>Hive不支持联合数据类型，比如STRUCT</li>
<li>Hive’s <code>TIMESTAMP</code> 的精度是 9 ， Hive UDFs函数只能处理 precision &lt;= 9的 <code>TIMESTAMP</code> 值</li>
<li>Hive 不支持 Flink提供的 <code>TIMESTAMP_WITH_TIME_ZONE</code>, <code>TIMESTAMP_WITH_LOCAL_TIME_ZONE</code>, 及<code>MULTISET</code>类型</li>
<li>Flink<code>INTERVAL</code> 类型与 Hive <code>INTERVAL</code> 类型不一样</li>
</ul>
<p>上面介绍了普通表和Hive兼容表，那么我们该如何使用Hive的语法进行建表呢？这个时候就需要使用<strong>Hive Dialect</strong>。</p>
<h2 id="什么是Hive-Dialect"><a href="#什么是Hive-Dialect" class="headerlink" title="什么是Hive Dialect"></a>什么是Hive Dialect</h2><p>从Flink1.11.0开始，只要开启了Hive dialect配置，用户就可以使用HiveQL语法，这样我们就可以在Flink中使用Hive的语法使用一些DDL和DML操作。</p>
<p>Flink目前支持两种SQL方言(SQL dialects),分别为：<strong>default和hive</strong>。默认的SQL方言是<strong>default</strong>，如果要使用Hive的语法，需要将SQL方言切换到<strong>hive</strong>。</p>
<h2 id="如何使用Hive-Dialect"><a href="#如何使用Hive-Dialect" class="headerlink" title="如何使用Hive Dialect"></a>如何使用Hive Dialect</h2><h3 id="在SQL-Cli中使用Hive-dialect"><a href="#在SQL-Cli中使用Hive-dialect" class="headerlink" title="在SQL Cli中使用Hive dialect"></a>在SQL Cli中使用Hive dialect</h3><p>使用hive dialect只需要配置一个参数即可，该参数名称为：<strong>table.sql-dialect</strong>。我们就可以在sql-client-defaults.yaml配置文件中进行配置，也可以在具体的会话窗口中进行设定，对于SQL dialect的切换，不需要进行重启session。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">execution:</span></span><br><span class="line"><span class="attr">  planner:</span> <span class="string">blink</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">batch</span></span><br><span class="line"><span class="attr">  result-mode:</span> <span class="string">table</span></span><br><span class="line"></span><br><span class="line"><span class="attr">configuration:</span></span><br><span class="line">  <span class="string">table.sql-dialect:</span> <span class="string">hive</span></span><br></pre></td></tr></table></figure>

<p>如果我们需要在SQL Cli中进行切换hive dialect，可以使用如下命令：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">Flink SQL&gt; set table.sql-dialect=hive; -- 使用hive dialect</span><br><span class="line">Flink SQL&gt; set table.sql-dialect=default; -- 使用default dialect</span><br></pre></td></tr></table></figure>

<blockquote>
<p>尖叫提示：</p>
<p>一旦切换到了hive dialect，就只能使用Hive的语法建表，如果尝试使用Flink的语法建表，则会报错</p>
</blockquote>
<h3 id="在Table-API中配合dialect"><a href="#在Table-API中配合dialect" class="headerlink" title="在Table API中配合dialect"></a>在Table API中配合dialect</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">EnvironmentSettings settings = EnvironmentSettings.newInstance().useBlinkPlanner()...build();</span><br><span class="line">TableEnvironment tableEnv = TableEnvironment.create(settings);</span><br><span class="line"><span class="comment">// 使用hive dialect</span></span><br><span class="line">tableEnv.getConfig().setSqlDialect(SqlDialect.HIVE);</span><br><span class="line"><span class="comment">// 使用 default dialect</span></span><br><span class="line">tableEnv.getConfig().setSqlDialect(SqlDialect.DEFAULT);</span><br></pre></td></tr></table></figure>

<h3 id="操作示例"><a href="#操作示例" class="headerlink" title="操作示例"></a>操作示例</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">Flink SQL&gt; set table.sql-dialect=hive;</span><br><span class="line"><span class="comment">-- 使用Hive语法创建一张表</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> <span class="string">`hive_dialect_tbl`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">int</span> <span class="keyword">COMMENT</span> <span class="string">'id'</span>,</span><br><span class="line">  <span class="string">`name`</span> <span class="keyword">string</span> <span class="keyword">COMMENT</span> <span class="string">'名称'</span>,</span><br><span class="line">  <span class="string">`age`</span> <span class="built_in">int</span> <span class="keyword">COMMENT</span> <span class="string">'年龄'</span> </span><br><span class="line">)</span><br><span class="line"><span class="keyword">COMMENT</span> <span class="string">'hive dialect表测试'</span></span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">','</span>;</span><br></pre></td></tr></table></figure>

<p>进入Hive客户端去查看该表的元数据信息</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">desc formatted hive_dialect_tbl;</span><br><span class="line">col_name        data_type       <span class="keyword">comment</span></span><br><span class="line"><span class="comment"># col_name              data_type               comment             </span></span><br><span class="line">                 </span><br><span class="line"><span class="keyword">id</span>                      <span class="built_in">int</span>                                         </span><br><span class="line"><span class="keyword">name</span>                    <span class="keyword">string</span>                                      </span><br><span class="line">age                     <span class="built_in">int</span>                                         </span><br><span class="line">                 </span><br><span class="line"><span class="comment"># Detailed Table Information             </span></span><br><span class="line"><span class="keyword">Database</span>:               <span class="keyword">default</span>                  </span><br><span class="line">Owner:                  <span class="literal">null</span>                     </span><br><span class="line">CreateTime:             Mon <span class="built_in">Dec</span> <span class="number">21</span> <span class="number">17</span>:<span class="number">23</span>:<span class="number">48</span> CST <span class="number">2020</span>     </span><br><span class="line">LastAccessTime:         <span class="literal">UNKNOWN</span>                  </span><br><span class="line"><span class="keyword">Retention</span>:              <span class="number">0</span>                        </span><br><span class="line">Location:               hdfs://kms<span class="number">-1.</span>apache.com:<span class="number">8020</span>/<span class="keyword">user</span>/hive/warehouse/hive_dialect_tbl        </span><br><span class="line"><span class="keyword">Table</span> <span class="keyword">Type</span>:             MANAGED_TABLE            </span><br><span class="line"><span class="keyword">Table</span> <span class="keyword">Parameters</span>:                </span><br><span class="line">        <span class="keyword">comment</span>                 hive dialect表测试     </span><br><span class="line">        is_generic              <span class="literal">false</span>               </span><br><span class="line">        transient_lastDdlTime   <span class="number">1608542628</span>          </span><br><span class="line">                 </span><br><span class="line"><span class="comment"># Storage Information            </span></span><br><span class="line">SerDe <span class="keyword">Library</span>:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe       </span><br><span class="line">InputFormat:            org.apache.hadoop.mapred.TextInputFormat         </span><br><span class="line">OutputFormat:           org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat   </span><br><span class="line">Compressed:             <span class="keyword">No</span>                       </span><br><span class="line"><span class="keyword">Num</span> Buckets:            <span class="number">-1</span>                       </span><br><span class="line"><span class="keyword">Bucket</span> <span class="keyword">Columns</span>:         []                       </span><br><span class="line"><span class="keyword">Sort</span> <span class="keyword">Columns</span>:           []                       </span><br><span class="line"><span class="keyword">Storage</span> <span class="keyword">Desc</span> Params:             </span><br><span class="line">        field.delim             ,                   </span><br><span class="line">        serialization.format    ,</span><br></pre></td></tr></table></figure>

<p>很明显，该表是一张Hive兼容表，即<strong>is_generic=false</strong>。</p>
<p>使用FlinkSQLCli向该表中写入一条数据：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">Flink SQL&gt; insert into hive_dialect_tbl select 1,'tom',20;</span><br></pre></td></tr></table></figure>

<p>我们也可以在Hive的Cli中去操作该表</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">hive (default)&gt; select * from hive_dialect_tbl;</span><br><span class="line">hive (default)&gt; insert into hive_dialect_tbl select 2,'jack',22;</span><br></pre></td></tr></table></figure>

<p>以下是使用Hive方言的一些注意事项。</p>
<ul>
<li>Hive dialect只能用于操作Hive表，不能用于普通表。Hive方言应与HiveCatalog一起使用。</li>
<li>虽然所有Hive版本都支持相同的语法，但是是否有特定功能仍然取决于使用的Hive版本。例如，仅在Hive-2.4.0或更高版本中支持更新数据库位置。</li>
<li>Hive和Calcite具有不同的保留关键字。例如，<code>default</code>在Calcite中是保留关键字，在Hive中是非保留关键字。所以，在使用Hive dialect时，必须使用反引号（`）引用此类关键字，才能将其用作标识符。</li>
<li>在Hive中不能查询在Flink中创建的视图。</li>
</ul>
<p>当然，一旦开启了Hive dialect，我们就可以按照Hive的操作方式在Flink中去处理Hive的数据了，具体的操作与Hive一致，本文不再赘述。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要介绍了Hive Catalog和Hive Dialect。其中Hive Catalog的作用是持久化Flink的元数据信息，Hive Dialect是支持Hive语法的一个配置参数，这两个概念是Flink集成Hive的关键。下一篇分享将介绍如何使用Flink读写Hive。</p>
<blockquote>
<p>公众号『大数据技术与数仓』，回复『资料』领取大数据资料包</p>
</blockquote>
</div><div class="recommended_posts"><h3>相关推荐 ☟</h3><li><a href="https://jiamaoxiang.top/2021/01/08/实时数仓-以upsert的方式读写Kafka数据——以Flink1-12为例/" target="_blank">实时数仓|以upsert的方式读写Kafka数据——以Flink1.12为例</a></li><li><a href="https://jiamaoxiang.top/2020/12/22/Flink-on-Hive构建流批一体数仓/" target="_blank">Flink on Hive构建流批一体数仓</a></li><li><a href="https://jiamaoxiang.top/2020/12/18/Flink集成Hive之快速入门-以Flink1-12为例/" target="_blank">Flink集成Hive之快速入门--以Flink1.12为例</a></li><li><a href="https://jiamaoxiang.top/2020/12/15/使用自定义分区器解决Spark-DataSet数据分区不均匀的问题/" target="_blank">使用自定义分区器解决Spark DataSet数据分区不均匀的问题</a></li></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>Jia MaoXiang</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2020/12/21/Flink集成Hive之Hive-Catalog与Hive-Dialect-以Flink1-12为例/">https://jiamaoxiang.top/2020/12/21/Flink集成Hive之Hive-Catalog与Hive-Dialect-以Flink1-12为例/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本文为博主原创文章，遵循CC BY-SA 4.0版权协议，转载请附上原文出处链接和本声明</li></ul></div><br><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://jiamaoxiang.top/2020/12/21/Flink集成Hive之Hive-Catalog与Hive-Dialect-以Flink1-12为例/" data-id="ckkb75201003c187qrmym3zaq" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPYAAAD2CAAAAADAeSUUAAADOklEQVR42u3awY7iQAwEUP7/p1lpT3tYMlU2SKTn5TSaQJLXORS2+/GIj+ff49V/Xp3993h1zevvvrr+9bO97cDGxsa+Cft5eeTsfCGSBX11/eQ5rz+DjY2NfSr7OhiSsMlh1yHXLn0SddjY2NjYebGRL0QbRfndsbGxsbGvA2wWUe1D58UPNjY2NnYbJ22jpx0zzEYRH+ylYWNjY389ux30fvPfH5xvY2NjY38l+1kebUnQbuVpS5Tn6MDGxsY+iZ38uG+Lljb2kibUbEj8Q7xhY2NjH8G+vkFCmrWZNiOBpFiq3zM2Njb2bdltbNTZGA+PkyvPxhXY2NjYv4c966LPBrSbAmbWwMLGxsY+lZ03iZKzs/BrA3K2Qec/gwFsbGzs49iz4GmXYN9gmkUXNjY29qnstgGUB1JSNuSMdiFm4YqNjY19R3a+7WbWyi+a9WUbaxW32NjY2Mex21iabe7Jh77JRp9ZWD42aYyNjY399ez9qCCPtNkIIR8A/LDQ2NjY2Mex9z/637UobZi1TSVsbGzs89h5c6cdyubDgLxc2RQ/0WwEGxsb+7bsvIlft29Gm2/akmMWbNjY2NhnsJ+jI//RPxsh53mbv6p6noyNjY19E/bsEpsi5F2tqPYlRW8eGxsb+wh2HkVtsOVLlg+J8xbVy3thY2NjH8cuxqKLoJoNGNoAi+IZGxsb+wh2GyT7icRs/tyOH4oiBBsbG/vm7Pynf4vfFBJ5KLavBxsbG/ts9qb5vh8kJAHWnq33K2FjY2Pfip1vykma/vmQdQ+YFSrY2NjYp7LfxWhHvPnnNwOD/ywZNjY29kHsfPjatmzyVn5bnOSlSzHoxcbGxr4t+12N+zZ+2uKhLWyKkQA2Njb2Eex2dLoPqmQwvGkw/XAXbGxs7OPY7Vh30+7Jh8HtALgoirCxsbEPYrdNmc1D59t9Ns+WF07Y2NjYJ7H3odWWJfkGoHaJi4XGxsbGPo49a/1slmwfn6tvYWNjY/9Kdt7QyRs9++Lk4wGGjY2NfSg7edzkbNsSaouQR/tw2NjY2Ldl79s6SRkzG+7m2zrzp8LGxsY+if2Jts5m803e0tosMTY2NvYR7D+RxrWpwiUPswAAAABJRU5ErkJggg==">分享</a><div class="tags"><a href="/tags/Flink/">Flink</a></div><div class="post-nav"><a class="pre" href="/2020/12/22/Flink-on-Hive构建流批一体数仓/">Flink on Hive构建流批一体数仓</a><a class="next" href="/2020/12/18/Flink集成Hive之快速入门-以Flink1-12为例/">Flink集成Hive之快速入门--以Flink1.12为例</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar-toc"><div class="stoc-article" id="sidebar-stoc"><strong class="stoc-title"><i class="fa fa-list-ul"> 目录</i></strong><div class="toc-nav" id="stoc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是Hive-Catalog"><span class="toc-number">1.</span> <span class="toc-text">什么是Hive Catalog</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#如何使用Hive-Catalog"><span class="toc-number">2.</span> <span class="toc-text">如何使用Hive Catalog</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#代码中使用Hive-Catalog"><span class="toc-number">2.1.</span> <span class="toc-text">代码中使用Hive Catalog</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Flink-SQLCli中使用Hive-Catalog"><span class="toc-number">2.2.</span> <span class="toc-text">Flink SQLCli中使用Hive Catalog</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是Hive-Dialect"><span class="toc-number">3.</span> <span class="toc-text">什么是Hive Dialect</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#如何使用Hive-Dialect"><span class="toc-number">4.</span> <span class="toc-text">如何使用Hive Dialect</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#在SQL-Cli中使用Hive-dialect"><span class="toc-number">4.1.</span> <span class="toc-text">在SQL Cli中使用Hive dialect</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#在Table-API中配合dialect"><span class="toc-number">4.2.</span> <span class="toc-text">在Table API中配合dialect</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#操作示例"><span class="toc-number">4.3.</span> <span class="toc-text">操作示例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">5.</span> <span class="toc-text">总结</span></a></li></ol></div></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 - 2021 <a href="/." rel="nofollow">Jmx's Blog.</a>All rights reserved.<br>Thoughts on technology, life and everything else.</div></div></div><script type="text/javascript" src="/js/toc.js?v=0.0.0"></script><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" color="100,99,98" opacity="0.5" zindex="0.7" count="150" src="//lib.baomitu.com/canvas-nest.js/2.0.4/canvas-nest.umd.js"></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>