<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="记录朴实无华且枯燥的生活"><title>Flink1.10集成Hive快速入门 | Jmx's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + '912b6cfc43243cd27aeb428f7dbf7823';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();</script><script type="text/javascript" src="/js/toc.js?v=0.0.0"></script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Flink1.10集成Hive快速入门</h1><a id="logo" href="/.">Jmx's Blog</a><p class="description">Keep it Simple and Stupid!</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-pied-piper-alt"> 关于</i></a><a href="/tags"><i class="fa fa-tags"> 标签</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Flink1.10集成Hive快速入门</h1><div class="post-meta">Mar 31, 2020<span> | </span><span class="category"><a href="/categories/Flink/">Flink</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.4k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 6</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><p>Hive 是大数据领域最早出现的 SQL 引擎，发展至今有着丰富的功能和广泛的用户基础。之后出现的 SQL 引擎，如 Spark SQL、Impala 等，都在一定程度上提供了与 Hive 集成的功能，从而方便用户使用现有的数据仓库、进行作业迁移等。</p>
<a id="more"></a>

<p>Flink从1.9开始支持集成Hive，不过1.9版本为beta版，不推荐在生产环境中使用。在最新版Flink1.10版本，标志着对 Blink的整合宣告完成，随着对 Hive 的生产级别集成，Hive作为数据仓库系统的绝对核心，承担着绝大多数的离线数据ETL计算和数据管理，期待Flink未来对Hive的完美支持。</p>
<p>而 HiveCatalog 会与一个 Hive Metastore 的实例连接，提供元数据持久化的能力。要使用 Flink 与 Hive 进行交互，用户需要配置一个 HiveCatalog，并通过 HiveCatalog 访问 Hive 中的元数据。</p>
<h2 id="添加依赖"><a href="#添加依赖" class="headerlink" title="添加依赖"></a>添加依赖</h2><p>要与Hive集成，需要在Flink的lib目录下添加额外的依赖jar包，以使集成在Table API程序或SQL Client中的SQL中起作用。或者，可以将这些依赖项放在文件夹中，并分别使用Table API程序或SQL Client 的<code>-C</code> 或<code>-l</code>选项将它们添加到classpath中。本文使用第一种方式，即将jar包直接复制到$FLINK_HOME/lib目录下。本文使用的Hive版本为2.3.4(对于不同版本的Hive，可以参照官网选择不同的jar包依赖)，总共需要3个jar包，如下：</p>
<ul>
<li>flink-connector-hive_2.11-1.10.0.jar</li>
<li>flink-shaded-hadoop-2-uber-2.7.5-8.0.jar</li>
<li>hive-exec-2.3.4.jar</li>
</ul>
<p>其中hive-exec-2.3.4.jar在hive的lib文件夹下，另外两个需要自行下载，下载地址：<a href="https://repo1.maven.org/maven2/org/apache/flink/flink-connector-hive_2.11/1.10.0/" target="_blank" rel="noopener">flink-connector-hive_2.11-1.10.0.jar</a>，<a href="//https://maven.aliyun.com/mvn/search">flink-shaded-hadoop-2-uber-2.7.5-8.0.jar</a></p>
<p><img src="//jiamaoxiang.top/2020/03/31/Flink1-10集成Hive快速入门/demo.png" alt></p>
<p><strong>切莫拔剑四顾心茫然，话不多说，直接上代码。</strong></p>
<h2 id="构建程序"><a href="#构建程序" class="headerlink" title="构建程序"></a>构建程序</h2><h3 id="添加Maven依赖"><a href="#添加Maven依赖" class="headerlink" title="添加Maven依赖"></a>添加Maven依赖</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Flink Dependency --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-hive_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-api-java-bridge_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Hive Dependency --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-exec<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hive.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="实例代码"><a href="#实例代码" class="headerlink" title="实例代码"></a>实例代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.flink.sql.hiveintegration;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.EnvironmentSettings;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.api.TableEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.table.catalog.hive.HiveCatalog;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *  <span class="doctag">@Created</span> with IntelliJ IDEA.</span></span><br><span class="line"><span class="comment"> *  <span class="doctag">@author</span> : jmx</span></span><br><span class="line"><span class="comment"> *  <span class="doctag">@Date</span>: 2020/3/31</span></span><br><span class="line"><span class="comment"> *  <span class="doctag">@Time</span>: 13:22</span></span><br><span class="line"><span class="comment"> *  </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FlinkHiveIntegration</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        EnvironmentSettings settings = EnvironmentSettings</span><br><span class="line">                .newInstance()</span><br><span class="line">                .useBlinkPlanner() <span class="comment">// 使用BlinkPlanner</span></span><br><span class="line">                .inBatchMode() <span class="comment">// Batch模式，默认为StreamingMode</span></span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//使用StreamingMode</span></span><br><span class="line">       <span class="comment">/* EnvironmentSettings settings = EnvironmentSettings</span></span><br><span class="line"><span class="comment">                .newInstance()</span></span><br><span class="line"><span class="comment">                .useBlinkPlanner() // 使用BlinkPlanner</span></span><br><span class="line"><span class="comment">                .inStreamingMode() // StreamingMode</span></span><br><span class="line"><span class="comment">                .build();*/</span></span><br><span class="line"></span><br><span class="line">        TableEnvironment tableEnv = TableEnvironment.create(settings);</span><br><span class="line"></span><br><span class="line">        String name = <span class="string">"myhive"</span>;      <span class="comment">// Catalog名称，定义一个唯一的名称表示</span></span><br><span class="line">        String defaultDatabase = <span class="string">"qfbap_ods"</span>;  <span class="comment">// 默认数据库名称</span></span><br><span class="line">        String hiveConfDir = <span class="string">"/opt/modules/apache-hive-2.3.4-bin/conf"</span>;  <span class="comment">// hive-site.xml路径</span></span><br><span class="line">        String version = <span class="string">"2.3.4"</span>;       <span class="comment">// Hive版本号</span></span><br><span class="line"></span><br><span class="line">        HiveCatalog hive = <span class="keyword">new</span> HiveCatalog(name, defaultDatabase, hiveConfDir, version);</span><br><span class="line"></span><br><span class="line">        tableEnv.registerCatalog(<span class="string">"myhive"</span>, hive);</span><br><span class="line">        tableEnv.useCatalog(<span class="string">"myhive"</span>);</span><br><span class="line">        <span class="comment">// 创建数据库，目前不支持创建hive表</span></span><br><span class="line">        String createDbSql = <span class="string">"CREATE DATABASE IF NOT EXISTS myhive.test123"</span>;</span><br><span class="line"></span><br><span class="line">        tableEnv.sqlUpdate(createDbSql);  </span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Flink-SQL-Client集成Hive"><a href="#Flink-SQL-Client集成Hive" class="headerlink" title="Flink SQL Client集成Hive"></a>Flink SQL Client集成Hive</h2><p>Flink的表和SQL API可以处理用SQL语言编写的查询，但是这些查询需要嵌入到用Java或Scala编写的程序中。此外，这些程序在提交到集群之前需要与构建工具打包。这或多或少地限制了Java/Scala程序员对Flink的使用。</p>
<p>SQL客户端旨在提供一种简单的方式，无需一行Java或Scala代码，即可将表程序编写、调试和提交到Flink集群。Flink SQL客户端CLI允许通过命令行的形式运行分布式程序。使用Flink SQL cli访问Hive，需要配置sql-client-defaults.yaml文件。</p>
<h3 id="sql-client-defaults-yaml配置"><a href="#sql-client-defaults-yaml配置" class="headerlink" title="sql-client-defaults.yaml配置"></a>sql-client-defaults.yaml配置</h3><p>目前 HiveTableSink 不支持流式写入（未实现 AppendStreamTableSink）。需要将执行模式改成 batch<br>模式，否则会报如下错误：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">org.apache.flink.table.api.TableException: Stream Tables can only be emitted by AppendStreamTableSink, RetractStreamTableSink, or UpsertStreamTableSink.</span><br></pre></td></tr></table></figure>

<p>需要修改的配置内容如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#...省略的配置项...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#==============================================================================</span></span><br><span class="line"><span class="comment"># Catalogs</span></span><br><span class="line"><span class="comment">#==============================================================================</span></span><br><span class="line"><span class="comment"># 配置catalogs,可以配置多个.</span></span><br><span class="line">catalogs: <span class="comment"># empty list</span></span><br><span class="line">  - name: myhive</span><br><span class="line">    <span class="built_in">type</span>: hive</span><br><span class="line">    hive-conf-dir: /opt/modules/apache-hive-2.3.4-bin/conf</span><br><span class="line">    hive-version: 2.3.4</span><br><span class="line">    default-database: qfbap_ods</span><br><span class="line"></span><br><span class="line"><span class="comment">#...省略的配置项...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#==============================================================================</span></span><br><span class="line"><span class="comment"># Execution properties</span></span><br><span class="line"><span class="comment">#==============================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Properties that change the fundamental execution behavior of a table program.</span></span><br><span class="line"></span><br><span class="line">execution:</span><br><span class="line">  <span class="comment"># select the implementation responsible for planning table programs</span></span><br><span class="line">  <span class="comment"># possible values are 'blink' (used by default) or 'old'</span></span><br><span class="line">  planner: blink</span><br><span class="line">  <span class="comment"># 'batch' or 'streaming' execution</span></span><br><span class="line">  <span class="built_in">type</span>: batch</span><br></pre></td></tr></table></figure>

<h3 id="启动Flink-SQL-Cli"><a href="#启动Flink-SQL-Cli" class="headerlink" title="启动Flink SQL Cli"></a>启动Flink SQL Cli</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/sql-client.sh  embedded</span><br></pre></td></tr></table></figure>

<p>启动之后，就可以在此Cli下执行SQL命令访问Hive的表了，基本的操作如下：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 命令行帮助</span></span><br><span class="line">Flink SQL&gt; help</span><br><span class="line"><span class="comment">-- 查看当前会话的catalog，其中myhive为自己配置的，default_catalog为默认的</span></span><br><span class="line">Flink SQL&gt; show catalogs;</span><br><span class="line">default_catalog</span><br><span class="line">myhive</span><br><span class="line"><span class="comment">-- 使用catalog</span></span><br><span class="line">Flink SQL&gt; use catalog myhive;</span><br><span class="line"><span class="comment">-- 查看当前catalog的数据库</span></span><br><span class="line">Flink SQL&gt; show databases;</span><br><span class="line"><span class="comment">-- 创建数据库</span></span><br><span class="line">Flink SQL&gt; create database testdb;</span><br><span class="line"><span class="comment">-- 删除数据库</span></span><br><span class="line">Flink SQL&gt; drop database testdb;</span><br><span class="line"><span class="comment">-- 创建表</span></span><br><span class="line">Flink SQL&gt; create table tbl(id int,name string);</span><br><span class="line"><span class="comment">-- 删除表</span></span><br><span class="line">Flink SQL&gt; drop table tbl;</span><br><span class="line"><span class="comment">-- 查询表</span></span><br><span class="line">Flink SQL&gt; select * from  code_city;</span><br><span class="line"><span class="comment">-- 插入数据</span></span><br><span class="line">Flink SQL&gt; insert overwrite code_city select id,city,province,event_time from code_city_delta ;</span><br><span class="line">Flink SQL&gt; INSERT into code_city values(1,'南京','江苏','');</span><br></pre></td></tr></table></figure>

<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文以最新版本的Flink为例，对Flink集成Hive进行了实操。首先通过代码的方式与Hive进行集成，然后介绍了如何使用Flink SQL 客户端访问Hive，并对其中会遇到的坑进行了描述，最后给出了Flink SQL Cli的详细使用。相信在未来的版本中Flink SQL会越来越完善，期待Flink未来对Hive的完美支持。</p>
<p>欢迎添加我的公众号，随时随地了解更多精彩内容。</p>
<p><img src="//jiamaoxiang.top/2020/03/31/Flink1-10集成Hive快速入门/%E4%B8%89%E7%BB%B4%E7%A0%81.png" alt></p>
</div><div class="recommended_posts"><h3>相关推荐 ☟</h3><li><a href="https://jiamaoxiang.top/2020/04/09/如何使用Hive进行OLAP分析/" target="_blank">如何使用Hive进行OLAP分析</a></li><li><a href="https://jiamaoxiang.top/2020/04/02/你真的了解Flink-Kafka-connector吗？/" target="_blank">你真的了解Flink Kafka source吗？</a></li><li><a href="https://jiamaoxiang.top/2020/03/30/Flink的八种分区策略源码解读/" target="_blank">Flink的八种分区策略源码解读</a></li><li><a href="https://jiamaoxiang.top/2020/03/24/基于Canal与Flink实现数据实时增量同步-二/" target="_blank">基于Canal与Flink实现数据实时增量同步(二)</a></li></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>Jia MaoXiang</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2020/03/31/Flink1-10集成Hive快速入门/">https://jiamaoxiang.top/2020/03/31/Flink1-10集成Hive快速入门/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本文为博主原创文章，遵循CC BY-SA 4.0版权协议，转载请附上原文出处链接和本声明</li></ul></div><br><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://jiamaoxiang.top/2020/03/31/Flink1-10集成Hive快速入门/" data-id="ckicw3vm00001e47ql4008pw2" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACvUlEQVR42u3aQW4bMRAEQP3/0wqQUwBbSvcM6QhB7UlYWyaLBw7dnMcjfp6/nz8/f33z6ltff/p88bwf69UoBx48PDy80dSTIfNp5QuRA9r54OHh4d3mtX8umVy+ledlJv8dPDw8vE/gtVPP8e0c8PDw8P4n3iy2uFE88PDw8G7z2mi1jWvfTyIPfC9mLXh4eHgxb7Mp/6vP1+/38PDw8Ea36psi0bYUtMUjmi0eHh7eBV5ybN2XjfwAnfz9pApEWTIeHh7egpdvxG1LwSyA2MynyKrx8PDwFmO1h+C8sbUNFPJwNh8dDw8P7yxvtsXnx+hZMZi1CHzzLTw8PLwLvPyf/1Mb/aYRYdaGhYeHh3ePF52+f2T7zo/1+U/x8PDwTvGSBtBihYILsKSQzC7AogAXDw8P7wJvNt02YshLRb7o37zBw8PDu8ZrI4O8mSC/rNqUk78UBjw8PLyjvFmo2r451W6V44uDNR4eHl7Ja8OIWSC7D4Lzo/YqxsXDw8MLePk1//742y5W/kTLjYeHh3eUN1yPYCr7Lf7A6Hh4eHhHebMWgeTN2daB4QEdDw8P7xqvDVJzQBv+5g0E0TUYHh4e3mVeHkNsYtl9c0DRFoaHh4d3mZdfceWBxSyYyAtS1FOGh4eHd5SXH2Hb8nD2oJwHzS9Tajw8PLxDvLwhoN2+D2zo8UEfDw8P7xN478tDHuBGdWnRXhBVPDw8PLyjvCR6aEOKUxFGHu9Gv4+Hh4d3iPcsn5ZXXFbF1KJE4eHh4V3gba7nZ0FDe6TetHPh4eHh3ePlxaAdrC0z+dIUcQYeHh7eNd4mnmgvsdqGgEf54OHh4X0OL7l8yrfvdiGGh3U8PDy8D+C1b/Jj96yoRP0ReHh4eBd4bWNTu4nnB/F89AMNBHh4eHgj3uYCrI1rNwv3vmzMYgs8PDy8kvcL/p7kKYk6gYIAAAAASUVORK5CYII=">分享</a><div class="tags"><a href="/tags/flink/">flink</a></div><div class="post-nav"><a class="pre" href="/2020/04/02/你真的了解Flink-Kafka-connector吗？/">你真的了解Flink Kafka source吗？</a><a class="next" href="/2020/03/30/Flink的八种分区策略源码解读/">Flink的八种分区策略源码解读</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar-toc"><div class="stoc-article" id="sidebar-stoc"><strong class="stoc-title"><i class="fa fa-list-ul"> 目录</i></strong><div class="toc-nav" id="stoc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#添加依赖"><span class="toc-number">1.</span> <span class="toc-text">添加依赖</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#构建程序"><span class="toc-number">2.</span> <span class="toc-text">构建程序</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#添加Maven依赖"><span class="toc-number">2.1.</span> <span class="toc-text">添加Maven依赖</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#实例代码"><span class="toc-number">2.2.</span> <span class="toc-text">实例代码</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Flink-SQL-Client集成Hive"><span class="toc-number">3.</span> <span class="toc-text">Flink SQL Client集成Hive</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#sql-client-defaults-yaml配置"><span class="toc-number">3.1.</span> <span class="toc-text">sql-client-defaults.yaml配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#启动Flink-SQL-Cli"><span class="toc-number">3.2.</span> <span class="toc-text">启动Flink SQL Cli</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#小结"><span class="toc-number">4.</span> <span class="toc-text">小结</span></a></li></ol></div></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 - 2020 <a href="/." rel="nofollow">Jmx's Blog.</a>All rights reserved.<br>Thoughts on technology, life and everything else.</div></div></div><script type="text/javascript" src="/js/toc.js?v=0.0.0"></script><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" color="100,99,98" opacity="0.5" zindex="0.7" count="150" src="//lib.baomitu.com/canvas-nest.js/2.0.4/canvas-nest.umd.js"></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>