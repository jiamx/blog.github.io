<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="记录朴实无华且枯燥的生活"><title>面试|不可不知的十大Hive调优技巧最佳实践 | Jmx's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + '912b6cfc43243cd27aeb428f7dbf7823';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();</script><script type="text/javascript" src="/js/toc.js?v=0.0.0"></script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">面试|不可不知的十大Hive调优技巧最佳实践</h1><a id="logo" href="/.">Jmx's Blog</a><p class="description">Keep it Simple and Stupid!</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-pied-piper-alt"> 关于</i></a><a href="/tags"><i class="fa fa-tags"> 标签</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">面试|不可不知的十大Hive调优技巧最佳实践</h1><div class="post-meta">Nov 16, 2020<span> | </span><span class="category"><a href="/categories/Hive/">Hive</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 2.6k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 9</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><p>Apache <strong>Hive</strong>是建立在Apache <strong>Hadoop</strong>之上的数据仓库软件项目，用于提供数据查询和分析。Hive是Hadoop在HDFS上的SQL接口，它提供了类似于SQL的接口来查询存储在与<strong>Hadoop</strong>集成的各种数据库和文件系统中的数据。可以说从事数据开发工作，无论是在平时的工作中，还是在面试中，Hive具有举足轻重的地位，尤其是Hive的性能调优方面，不仅能够在工作中提升效率而且还可以在面试中脱颖而出。在本文中，我将分享十个性能优化技术，全文如下。</p>
<h1 id="1-多次INSERT单次扫描表"><a href="#1-多次INSERT单次扫描表" class="headerlink" title="1.多次INSERT单次扫描表"></a>1.多次INSERT单次扫描表</h1><p>默认情况下，Hive会执行多次表扫描。因此，如果要在某张hive表中执行多个操作，建议使用一次扫描并使用该扫描来执行多个操作。</p>
<p>比如将一张表的数据多次查询出来装载到另外一张表中。如下面的示例，表<strong>my_table</strong>是一个分区表，分区字段为<strong>dt</strong>，如果需要在表中查询2个特定的分区日期数据，并将记录装载到2个不同的表中。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> temp_table_20201115 <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> my_table <span class="keyword">WHERE</span> dt =<span class="string">'2020-11-15'</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> temp_table_20201116 <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> my_table <span class="keyword">WHERE</span> dt =<span class="string">'2020-11-16'</span>;</span><br></pre></td></tr></table></figure>

<p>在以上查询中，Hive将扫描表2次，为了避免这种情况，我们可以使用下面的方式：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">FROM my_table</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> temp_table_20201115 <span class="keyword">SELECT</span> * <span class="keyword">WHERE</span> dt =<span class="string">'2020-11-15'</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> temp_table_20201116 <span class="keyword">SELECT</span> * <span class="keyword">WHERE</span> dt =<span class="string">'2020-11-16'</span></span><br></pre></td></tr></table></figure>

<p>这样可以确保只对<strong>my_table</strong>表执行一次扫描，从而可以大大减少执行的时间和资源。</p>
<h1 id="2-分区表"><a href="#2-分区表" class="headerlink" title="2.分区表"></a>2.分区表</h1><p>对于一张比较大的表，将其设计成分区表可以提升查询的性能，对于一个特定分区的查询，只会加载对应分区路径的文件数据，因此，当用户使用特定分区列值执行选择查询时，将仅针对该特定分区执行查询，由于将针对较少的数据量进行扫描，所以可以提供更好的性能。值得注意的是，分区字段的选择是影响查询性能的重要因素，尽量避免层级较深的分区，这样会造成太多的子文件夹。</p>
<p>现在问题来了，该使用哪些列进行分区呢？一条基本的法则是：<strong>选择低基数属性作为“分区键”</strong>，比如“地区”或“日期”等。</p>
<p>一些常见的分区字段可以是：</p>
<ul>
<li>日期或者时间</li>
</ul>
<p>比如year、month、day或者hour，当表中存在时间或者日期字段时，可以使用些字段。</p>
<ul>
<li>地理位置</li>
</ul>
<p>比如国家、省份、城市等</p>
<ul>
<li>业务逻辑</li>
</ul>
<p>比如部门、销售区域、客户等等</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> table_name (</span><br><span class="line">    col1 data_type,</span><br><span class="line">    col2 data_type)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span> (partition1 data_type, partition2 data_type,….);</span><br></pre></td></tr></table></figure>

<h1 id="3-分桶表"><a href="#3-分桶表" class="headerlink" title="3.分桶表"></a>3.分桶表</h1><p>通常，当很难在列上创建分区时，我们会使用分桶，比如某个经常被筛选的字段，如果将其作为分区字段，会造成大量的分区。在Hive中，会对分桶字段进行哈希，从而提供了中额外的数据结构，进行提升查询效率。</p>
<p>与分区表类似，分桶表的组织方式是将HDFS上的文件分割成多个文件。分桶可以加快数据采样，也可以提升join的性能(join的字段是分桶字段)，因为分桶可以确保某个key对应的数据在一个特定的桶内(文件)，所以巧妙地选择分桶字段可以大幅度提升join的性能。通常情况下，分桶字段可以选择经常用在过滤操作或者join操作的字段。</p>
<p>我们可以使用<strong>set.hive.enforce.bucketing = true</strong>启用分桶设置。</p>
<p>当使用分桶表时，最好将<strong>bucketmapjoin</strong>标志设置为true，具体配置参数为：</p>
<p><strong>SET hive.optimize.bucketmapjoin = true</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE table_name </span><br><span class="line">PARTITIONED BY (partition1 data_type, partition2 data_type,….) CLUSTERED BY (column_name1, column_name2, …) </span><br><span class="line">SORTED BY (column_name [ASC|DESC], …)] </span><br><span class="line">INTO num_buckets BUCKETS;</span><br></pre></td></tr></table></figure>

<h1 id="4-对中间数据启用压缩"><a href="#4-对中间数据启用压缩" class="headerlink" title="4.对中间数据启用压缩"></a>4.对中间数据启用压缩</h1><p>复杂的Hive查询通常会转换为一系列多阶段的MapReduce作业，并且这些作业将由Hive引擎链接起来以完成整个查询。因此，此处的“中间输出”是指上一个MapReduce作业的输出，它将用作下一个MapReduce作业的输入数据。</p>
<p>压缩可以显著减少中间数据量，从而在内部减少了Map和Reduce之间的数据传输量。</p>
<p>我们可以使用以下属性在中间输出上启用压缩。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set hive.exec.compress.intermediate=true;</span><br><span class="line">set hive.intermediate.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;</span><br><span class="line">set hive.intermediate.compression.type=BLOCK;</span><br></pre></td></tr></table></figure>

<p>为了将最终输出到HDFS的数据进行压缩，可以使用以下属性：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set hive.exec.compress.output=true;</span><br></pre></td></tr></table></figure>

<p>下面是一些可以使用的压缩编解码器</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">org.apache.hadoop.io.compress.DefaultCodec</span><br><span class="line">org.apache.hadoop.io.compress.GzipCodec</span><br><span class="line">org.apache.hadoop.io.compress.BZip2Codec</span><br><span class="line">com.hadoop.compression.lzo.LzopCodec</span><br><span class="line">org.apache.hadoop.io.compress.Lz4Codec</span><br><span class="line">org.apache.hadoop.io.compress.SnappyCodec</span><br></pre></td></tr></table></figure>

<h1 id="5-Map端JOIN"><a href="#5-Map端JOIN" class="headerlink" title="5.Map端JOIN"></a>5.Map端JOIN</h1><p>map端join适用于当一张表很小(可以存在内存中)的情况，即可以将小表加载至内存。Hive从0.7开始支持自动转为map端join，具体配置如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SET hive.auto.convert.join=true; --  hivev0.11.0之后默认true</span><br><span class="line">SET hive.mapjoin.smalltable.filesize=600000000; -- 默认 25m</span><br><span class="line">SET hive.auto.convert.join.noconditionaltask=true; -- 默认true，所以不需要指定map join hint</span><br><span class="line">SET hive.auto.convert.join.noconditionaltask.size=10000000; -- 控制加载到内存的表的大小</span><br></pre></td></tr></table></figure>

<p>一旦开启map端join配置，Hive会自动检查小表是否大于<code>hive.mapjoin.smalltable.filesize</code>配置的大小，如果大于则转为普通的join，如果小于则转为map端join。</p>
<p>关于map端join的原理，如下图所示：</p>
<img src="//jiamaoxiang.top/2020/11/16/面试-不可不知的十大Hive调优技巧最佳实践/map端join.png" style="zoom:67%;">

<p>首先，Task A(客户端本地执行的task)负责读取小表a，并将其转成一个HashTable的数据结构，写入到本地文件，之后将其加载至分布式缓存。</p>
<p>然后，Task B任务会启动map任务读取大表b，在Map阶段，根据每条记录与分布式缓存中的a表对应的hashtable关联，并输出结果</p>
<p>注意：map端join没有reduce任务，所以map直接输出结果，即有多少个map任务就会产生多少个结果文件。</p>
<h1 id="6-向量化"><a href="#6-向量化" class="headerlink" title="6.向量化"></a>6.向量化</h1><p>Hive中的向量化查询执行大大减少了典型查询操作（如扫描，过滤器，聚合和连接）的CPU使用率。</p>
<p>标准查询执行系统一次处理一行，在处理下一行之前，单行数据会被查询中的所有运算符进行处理，导致CPU使用效率非常低。在向量化查询执行中，数据行被批处理在一起（默认=&gt; 1024行），表示为一组列向量。</p>
<p>要使用向量化查询执行，必须以ORC格式（CDH 5）存储数据，并设置以下变量。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SET hive.vectorized.execution.enabled=true</span><br></pre></td></tr></table></figure>

<p>在CDH 6中默认启用Hive查询向量化，启用查询向量化后，还可以设置其他属性来调整查询向量化的方式，具体可以参考cloudera官网。</p>
<h1 id="7-谓词下推"><a href="#7-谓词下推" class="headerlink" title="7.谓词下推"></a>7.谓词下推</h1><p>默认生成的执行计划会在可见的位置执行过滤器，但在某些情况下，某些过滤器表达式可以被推到更接近首次看到此特定数据的运算符的位置。</p>
<p>比如下面的查询：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select</span><br><span class="line">    a.*,</span><br><span class="line">    b.* </span><br><span class="line">from </span><br><span class="line">    a join b on (a.col1 = b.col1)</span><br><span class="line">where a.col1 &gt; 15 and b.col2 &gt; 16</span><br></pre></td></tr></table></figure>

<p><strong>如果没有谓词下推</strong>，则在完成JOIN处理之后将执行过滤条件<strong>(a.col1&gt; 15和b.col2&gt; 16)</strong>。因此，在这种情况下，JOIN将首先发生，并且可能产生更多的行，然后在进行过滤操作。</p>
<p><strong>使用谓词下推</strong>，这两个谓词<strong>(a.col1&gt; 15和b.col2&gt; 16)</strong>将在JOIN之前被处理，因此它可能会从a和b中过滤掉连接中较早处理的大部分数据行，因此，建议启用谓词下推。</p>
<p>通过将hive.optimize.ppd设置为true可以启用谓词下推。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SET hive.optimize.ppd=true</span><br></pre></td></tr></table></figure>

<h1 id="8-输入格式选择"><a href="#8-输入格式选择" class="headerlink" title="8.输入格式选择"></a>8.输入格式选择</h1><p>Hive支持TEXTFILE, SEQUENCEFILE, AVRO, RCFILE, ORC,以及PARQUET文件格式，可以通过两种方式指定表的文件格式：</p>
<ul>
<li>CREATE TABLE … STORE AS :即在建表时指定文件格式，默认是TEXTFILE</li>
<li>ALTER TABLE … [PARTITION partition_spec] SET FILEFORMAT :修改具体表的文件格式</li>
</ul>
<p>如果未指定文件存储格式，则默认使用的是参数<strong>hive.default.fileformat</strong>设定的格式。</p>
<p>如果数据存储在小于块大小的小文件中，则可以使用<strong>SEQUENCE</strong>文件格式。如果要以减少存储空间并提高性能的优化方式存储数据，则可以使用<strong>ORC文件</strong>格式，而当列中嵌套的数据过多时，<strong>Parquet</strong>格式会很有用。因此，需要根据拥有的数据确定输入文件格式。</p>
<h1 id="9-启动严格模式"><a href="#9-启动严格模式" class="headerlink" title="9.启动严格模式"></a>9.启动严格模式</h1><p>如果要查询分区的Hive表，但不提供分区谓词（分区列条件），则在这种情况下，将针对该表的所有分区发出查询，这可能会非常耗时且占用资源。因此，我们将下面的属性定义为<strong>strict</strong>，以指示在分区表上未提供分区谓词的情况下编译器将引发错误。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SET hive.partition.pruning=strict</span><br></pre></td></tr></table></figure>

<h1 id="10-基于成本的优化"><a href="#10-基于成本的优化" class="headerlink" title="10.基于成本的优化"></a>10.基于成本的优化</h1><p>Hive在提交最终执行之前会优化每个查询的逻辑和物理执行计划。基于成本的优化会根据查询成本进行进一步的优化，从而可能产生不同的决策：比如如何决定JOIN的顺序，执行哪种类型的JOIN以及并行度等。</p>
<p>可以通过设置以下参数来启用基于成本的优化。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set hive.cbo.enable=true;</span><br><span class="line">set hive.compute.query.using.stats=true;</span><br><span class="line">set hive.stats.fetch.column.stats=true;</span><br><span class="line">set hive.stats.fetch.partition.stats=true;</span><br></pre></td></tr></table></figure>

<p>可以使用统计信息来优化查询以提高性能。基于成本的优化器（CBO）还使用统计信息来比较查询计划并选择最佳计划。通过查看统计信息而不是运行查询，效率会很高。</p>
<p>收集表的列统计信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ANALYZE TABLE mytable COMPUTE STATISTICS FOR COLUMNS;</span><br></pre></td></tr></table></figure>

<p>查看my_db数据库中my_table中<strong>my_id</strong>列的列统计信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DESCRIBE FORMATTED my_db.my_table my_id</span><br></pre></td></tr></table></figure>

<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>本文主要分享了10个Hive优化的基本技巧，希望能够为你优化Hive查询提供一个基本的思路。再次感谢你的阅读，希望本文对你有所帮助。</p>
<blockquote>
<p>公众号『大数据技术与数仓』，回复『资料』领取大数据资料包</p>
</blockquote>
</div><div class="recommended_posts"><h3>相关推荐 ☟</h3><li><a href="https://jiamaoxiang.top/2020/11/20/第十一篇-基于SparkSQL的电影分析项目实战/" target="_blank">第十一篇|基于SparkSQL的电影分析项目实战</a></li><li><a href="https://jiamaoxiang.top/2020/11/17/第五篇-ClickHouse数据导入-Flink、Spark、Kafka、MySQL/" target="_blank">篇五|ClickHouse数据导入(Flink、Spark、Kafka、MySQL、Hive)</a></li><li><a href="https://jiamaoxiang.top/2020/11/11/第十篇-SparkStreaming手动维护Kafka-Offset的几种方式/" target="_blank">第十篇|SparkStreaming手动维护Kafka Offset的几种方式</a></li><li><a href="https://jiamaoxiang.top/2020/11/01/Spark的五种JOIN方式解析/" target="_blank">Spark的五种JOIN策略解析</a></li></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>Jia MaoXiang</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2020/11/16/面试-不可不知的十大Hive调优技巧最佳实践/">https://jiamaoxiang.top/2020/11/16/面试-不可不知的十大Hive调优技巧最佳实践/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本文为博主原创文章，遵循CC BY-SA 4.0版权协议，转载请附上原文出处链接和本声明</li></ul></div><br><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://jiamaoxiang.top/2020/11/16/面试-不可不知的十大Hive调优技巧最佳实践/" data-id="ckipouvgr0053cg7qlmwj8eqp" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPYAAAD2CAAAAADAeSUUAAADJ0lEQVR42u3aS27jQAwFwNz/0p7tLMaa90gFsNqlVZAoMqsFhOHn5ye+Xn9dyU9fb67r+9/97iyqGy5sbGzsh7Bfl1cbaHtYSTzv7s+P+x+fhY2NjX0c+zqsPMTkqkOMYyuOGBsbGxs7uD9JhLMCI09y2NjY2NgJKUkn7f35C8DGxsbGzsuG6wclKSdpQuXPzF8JNjY29tnsfCr6+V//ynwbGxsb+4PZm7b+bEicjIRnhUqhwMbGxj6I3f67vxnHJshkVNAOG97eiY2NjX0Ee9a+z1tOs6JiVmbkaRIbGxv7JPb1h+UFQ76mkwS0H/dG6Q0bGxv7IPYmUd216JMPgPcDZmxsbOxvY+f/+udJcV+izFLvcJMIGxsb+4PZm1DuxdxVWkQvDxsbG/sgdt5eb8uGvJzYLwy1rwQbGxv7bHbbxGl5dxUzd7WxsLGxsZ/Ozh99/Zd/s16TN6HaZPb2O9jY2NjHsZOA8qJlf3xtsszHGEW/ChsbG/sh7LsY+WFFazQjfHuI2NjY2Gewkwb6LNzZ8GCzplNEiI2Njf017M1gYD8GaNd3iq+xsbGxD2K3YeVJq20G5Z87Gyr8bN4GNjY29gez2yLkrsFA3qK6xs+eg42NjX0qezMSaBPMfn2nTYd1BYaNjY39EPYsGSS8/VB2fwT/+SxsbGzsI9iv+JoFvT+UfPMoeSVv8zY2Njb2Y9l5S32W3vKyZNYkyr8fTTOwsbGxH8jet3juWvFp0+FsbouNjY19Kjvf7mmbOLOE1I6N66PBxsbGPoi9adDkGaFdvpmNh9tEiI2NjX0SO192aX/aru9sSp36wsbGxj6OnaelzSC2HSTPVnyiUgcbGxv7UHYbxKbkaBtVm6SFjY2NfSp73wbKU12bFJPntK8NGxsb+zz2rAOTPy4pctrUlbSubmtCYWNjYz+EPWv3bNZu2mIjPw5sbGzsb2a3A+B8PDCDJQfaTnKxsbGxsZOElLSH8qooT0h1isXGxsb+ena7RpMnodmIIn8ONjY29qns31i42SBnifBXemnY2NjYH8/Og9uknDbE61TaNp6GzSlsbGzsT2f/AfvHIUzhG5i0AAAAAElFTkSuQmCC">分享</a><div class="tags"><a href="/tags/Hive/">Hive</a></div><div class="post-nav"><a class="pre" href="/2020/11/17/第五篇-ClickHouse数据导入-Flink、Spark、Kafka、MySQL/">篇五|ClickHouse数据导入(Flink、Spark、Kafka、MySQL、Hive)</a><a class="next" href="/2020/11/11/第十篇-SparkStreaming手动维护Kafka-Offset的几种方式/">第十篇|SparkStreaming手动维护Kafka Offset的几种方式</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar-toc"><div class="stoc-article" id="sidebar-stoc"><strong class="stoc-title"><i class="fa fa-list-ul"> 目录</i></strong><div class="toc-nav" id="stoc"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-多次INSERT单次扫描表"><span class="toc-number">1.</span> <span class="toc-text">1.多次INSERT单次扫描表</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-分区表"><span class="toc-number">2.</span> <span class="toc-text">2.分区表</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-分桶表"><span class="toc-number">3.</span> <span class="toc-text">3.分桶表</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-对中间数据启用压缩"><span class="toc-number">4.</span> <span class="toc-text">4.对中间数据启用压缩</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-Map端JOIN"><span class="toc-number">5.</span> <span class="toc-text">5.Map端JOIN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6-向量化"><span class="toc-number">6.</span> <span class="toc-text">6.向量化</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#7-谓词下推"><span class="toc-number">7.</span> <span class="toc-text">7.谓词下推</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#8-输入格式选择"><span class="toc-number">8.</span> <span class="toc-text">8.输入格式选择</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#9-启动严格模式"><span class="toc-number">9.</span> <span class="toc-text">9.启动严格模式</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#10-基于成本的优化"><span class="toc-number">10.</span> <span class="toc-text">10.基于成本的优化</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#结论"><span class="toc-number">11.</span> <span class="toc-text">结论</span></a></li></ol></div></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 - 2020 <a href="/." rel="nofollow">Jmx's Blog.</a>All rights reserved.<br>Thoughts on technology, life and everything else.</div></div></div><script type="text/javascript" src="/js/toc.js?v=0.0.0"></script><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" color="100,99,98" opacity="0.5" zindex="0.7" count="150" src="//lib.baomitu.com/canvas-nest.js/2.0.4/canvas-nest.umd.js"></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>