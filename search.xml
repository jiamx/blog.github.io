<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Flink运行架构剖析</title>
      <link href="/2019/10/23/Flink%E8%BF%90%E8%A1%8C%E6%9E%B6%E6%9E%84%E5%89%96%E6%9E%90/"/>
      <url>/2019/10/23/Flink%E8%BF%90%E8%A1%8C%E6%9E%B6%E6%9E%84%E5%89%96%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>本文主要介绍 Flink Runtime 的作业执行的核心机制。首先介绍 Flink Runtime 的整体架构以及 Job 的基本执行流程，然后介绍Flink 的Standalone运行架构，最后对Flink on YARN的两种模式进行了详细剖析。</p><a id="more"></a><h2 id="Flink-Runtime作业执行流程分析"><a href="#Flink-Runtime作业执行流程分析" class="headerlink" title="Flink Runtime作业执行流程分析"></a>Flink Runtime作业执行流程分析</h2><h3 id="整体架构图"><a href="#整体架构图" class="headerlink" title="整体架构图"></a>整体架构图</h3><p>Flink Runtime 层的主要架构如下图所示，它展示了一个 Flink 集群的基本结构。整体来说，它采用了标准 master-slave 的结构，master负责管理整个集群中的资源和作业；TaskExecutor 则是 Slave，负责提供具体的资源并实际执行作业。  </p><p><img src="//jiamaoxiang.top/2019/10/23/Flink运行架构剖析/Runtime.png" alt></p><h3 id="执行流程分析"><a href="#执行流程分析" class="headerlink" title="执行流程分析"></a>执行流程分析</h3><h4 id="组件介绍"><a href="#组件介绍" class="headerlink" title="组件介绍"></a>组件介绍</h4><p>Application Master 部分包含了三个组件，即 Dispatcher、ResourceManager 和 JobManager。其中，Dispatcher 负责接收用户提供的作业，并且负责为这个新提交的作业拉起一个新的 JobManager 组件。ResourceManager 负责资源的管理，在整个 Flink 集群中只有一个 ResourceManager。JobManager 负责管理作业的执行，在一个 Flink 集群中可能有多个作业同时执行，每个作业都有自己的 JobManager 组件。这三个组件都包含在 AppMaster 进程。  </p><p>TaskManager主要负责执行具体的task任务，<a href="https://jiamaoxiang.top/2019/08/23/Flink%E7%9A%84%E7%8A%B6%E6%80%81%E5%90%8E%E7%AB%AF-State-Backends/">StateBackend</a> 主要应用于状态的checkpoint。  </p><p>Cluster Manager是集群管理器，比如Standalone、YARN、K8s等。  </p><h4 id="流程分析"><a href="#流程分析" class="headerlink" title="流程分析"></a>流程分析</h4><p>1.当用户提交作业的时候，提交脚本会首先启动一个 Client进程负责作业的编译与提交。它首先将用户编写的代码编译为一个 JobGraph，在这个过程，它还会进行一些检查或优化等工作，例如判断哪些 Operator 可以 Chain 到同一个 Task 中。然后，Client 将产生的 JobGraph 提交到集群中执行。此时有两种情况，一种是类似于 Standalone 这种 Session 模式，AM 会预先启动，此时 Client 直接与 Dispatcher 建立连接并提交作业即可。另一种是 Per-Job 模式，AM 不会预先启动，此时 Client 将首先向资源管理系统 （如Yarn、K8S）申请资源来启动 AM，然后再向 AM 中的 Dispatcher 提交作业。  </p><p>2.当作业到 Dispatcher 后，Dispatcher 会首先启动一个 JobManager 组件，然后 JobManager 会向 ResourceManager 申请资源来启动作业中具体的任务。如果是Session模式，则TaskManager已经启动了，就可以直接分配资源。如果是per-Job模式，ResourceManager 也需要首先向外部资源管理系统申请资源来启动 TaskExecutor，然后等待 TaskExecutor 注册相应资源后再继续选择空闲资源进程分配，JobManager 收到 TaskExecutor 注册上来的 Slot 后，就可以实际提交 Task 了。  </p><p>3.TaskExecutor 收到 JobManager 提交的 Task 之后，会启动一个新的线程来执行该 Task。Task 启动后就会开始进行预先指定的计算，并通过数据 Shuffle 模块互相交换数据。</p><h2 id="Flink-Standalone运行架构"><a href="#Flink-Standalone运行架构" class="headerlink" title="Flink Standalone运行架构"></a>Flink Standalone运行架构</h2><p>Flink Standalone运行架构如下图所示：</p><p><img src="//jiamaoxiang.top/2019/10/23/Flink运行架构剖析/standalone.png" alt><br>Standalone模式需要先启动Jobmanager和TaskManager进程，每一个作业都是自己的JobManager。<br>Client：任务提交，生成JobGraph  </p><p>JobManager：调度Job，协调Task，通信，申请资源  </p><p>TaskManager：具体任务执行，请求资源</p><h2 id="Flink-On-YARN运行架构"><a href="#Flink-On-YARN运行架构" class="headerlink" title="Flink On YARN运行架构"></a>Flink On YARN运行架构</h2><p>关于YARN的基本架构原理，详见另一篇我的博客<a href="https://blog.csdn.net/jmx_bigdata/article/details/84320188" target="_blank" rel="noopener">YARN架构原理</a></p><h3 id="Per-Job模式"><a href="#Per-Job模式" class="headerlink" title="Per-Job模式"></a>Per-Job模式</h3><p>Per-job 模式下整个 Flink 集群只执行单个作业，即每个作业会独享 Dispatcher 和 ResourceManager 组件。此外，Per-job 模式下 AppMaster 和 TaskExecutor 都是按需申请的。因此，Per-job 模式更适合运行执行时间较长的大作业，这些作业对稳定性要求较高，并且对申请资源的时间不敏感。<br>1.独享Dispatcher与ResourceManager  </p><p>2.按需申请资源(TaskExecutor)  </p><p>3.适合执行时间较长的大作业  </p><p><img src="//jiamaoxiang.top/2019/10/23/Flink运行架构剖析/perjob.png" alt></p><h3 id="Session模式"><a href="#Session模式" class="headerlink" title="Session模式"></a>Session模式</h3><p>在 Session 模式下，Flink 预先启动 AppMaster 以及一组 TaskExecutor，然后在整个集群的生命周期中会执行多个作业。可以看出，Session 模式更适合规模小，执行时间短的作业。<br>1.共享Dispatcher与ResourceManager  </p><p>2.共享资源  </p><p>3.适合小规模，执行时间较短的作业  </p><p><img src="//jiamaoxiang.top/2019/10/23/Flink运行架构剖析/session.png" alt></p><p>Reference:<br>[1]<a href="https://ververica.cn/developers/advanced-tutorial-1-analysis-of-the-core-mechanism-of-runtime/" target="_blank" rel="noopener">https://ververica.cn/developers/advanced-tutorial-1-analysis-of-the-core-mechanism-of-runtime/</a><br>[2]<a href="https://ververica.cn/developers/flink-training-course2/" target="_blank" rel="noopener">https://ververica.cn/developers/flink-training-course2/</a></p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>经典Hive-SQL面试题</title>
      <link href="/2019/10/15/%E7%BB%8F%E5%85%B8Hive-SQL%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
      <url>/2019/10/15/%E7%BB%8F%E5%85%B8Hive-SQL%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p>HQL练习</p><a id="more"></a><h2 id="第一题"><a href="#第一题" class="headerlink" title="第一题"></a>第一题</h2><h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">我们有如下的用户访问数据</span><br><span class="line">userId  visitDate   visitCount</span><br><span class="line">u01 2017/1/21   5</span><br><span class="line">u02 2017/1/23   6</span><br><span class="line">u03 2017/1/22   8</span><br><span class="line">u04 2017/1/20   3</span><br><span class="line">u01 2017/1/23   6</span><br><span class="line">u01 2017/2/21   8</span><br><span class="line">U02 2017/1/23   6</span><br><span class="line">U01 2017/2/22   4</span><br><span class="line">要求使用SQL统计出每个用户的累积访问次数，如下表所示：</span><br><span class="line">用户id    月份  小计  累积</span><br><span class="line">u01 2017-01 11  11</span><br><span class="line">u01 2017-02 12  23</span><br><span class="line">u02 2017-01 12  12</span><br><span class="line">u03 2017-01 8   8</span><br><span class="line">u04 2017-01 3   3</span><br></pre></td></tr></table></figure><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><h4 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CREATE TABLE test_sql.test1 ( </span><br><span class="line">userId string, </span><br><span class="line">visitDate string,</span><br><span class="line">visitCount INT )</span><br><span class="line">ROW format delimited FIELDS TERMINATED BY <span class="string">"\t"</span>;</span><br><span class="line">INSERT INTO TABLE test_sql.test1</span><br><span class="line">VALUES</span><br><span class="line">( <span class="string">'u01'</span>, <span class="string">'2017/1/21'</span>, 5 ),</span><br><span class="line">( <span class="string">'u02'</span>, <span class="string">'2017/1/23'</span>, 6 ),</span><br><span class="line">( <span class="string">'u03'</span>, <span class="string">'2017/1/22'</span>, 8 ),</span><br><span class="line">( <span class="string">'u04'</span>, <span class="string">'2017/1/20'</span>, 3 ),</span><br><span class="line">( <span class="string">'u01'</span>, <span class="string">'2017/1/23'</span>, 6 ),</span><br><span class="line">( <span class="string">'u01'</span>, <span class="string">'2017/2/21'</span>, 8 ),</span><br><span class="line">( <span class="string">'u02'</span>, <span class="string">'2017/1/23'</span>, 6 ),</span><br><span class="line">( <span class="string">'u01'</span>, <span class="string">'2017/2/22'</span>, 4 );</span><br></pre></td></tr></table></figure><h4 id="查询SQL"><a href="#查询SQL" class="headerlink" title="查询SQL"></a>查询SQL</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">SELECT t2.userid,</span><br><span class="line">   t2.visitmonth,</span><br><span class="line">   subtotal_visit_cnt,</span><br><span class="line">   sum(subtotal_visit_cnt) over (partition BY userid</span><br><span class="line"> ORDER BY visitmonth) AS total_visit_cnt</span><br><span class="line">FROM</span><br><span class="line">  (SELECT userid,</span><br><span class="line">  visitmonth,</span><br><span class="line">  sum(visitcount) AS subtotal_visit_cnt</span><br><span class="line">   FROM</span><br><span class="line"> (SELECT userid,</span><br><span class="line"> date_format(regexp_replace(visitdate,<span class="string">'/'</span>,<span class="string">'-'</span>),<span class="string">'yyyy-MM'</span>) AS visitmonth,</span><br><span class="line"> visitcount</span><br><span class="line">  FROM test_sql.test1) t1</span><br><span class="line">   GROUP BY userid,</span><br><span class="line">visitmonth)t2</span><br><span class="line">ORDER BY t2.userid,</span><br><span class="line"> t2.visitmonth</span><br></pre></td></tr></table></figure><h2 id="第二题"><a href="#第二题" class="headerlink" title="第二题"></a>第二题</h2><h3 id="需求-1"><a href="#需求-1" class="headerlink" title="需求"></a>需求</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">有50W个京东店铺，每个顾客访客访问任何一个店铺的任何一个商品时都会产生一条访问日志，</span><br><span class="line">访问日志存储的表名为Visit，访客的用户id为user_id，被访问的店铺名称为shop，数据如下：</span><br><span class="line"></span><br><span class="line">u1a</span><br><span class="line">u2b</span><br><span class="line">u1b</span><br><span class="line">u1a</span><br><span class="line">u3c</span><br><span class="line">u4b</span><br><span class="line">u1a</span><br><span class="line">u2c</span><br><span class="line">u5b</span><br><span class="line">u4b</span><br><span class="line">u6c</span><br><span class="line">u2c</span><br><span class="line">u1b</span><br><span class="line">u2a</span><br><span class="line">u2a</span><br><span class="line">u3a</span><br><span class="line">u5a</span><br><span class="line">u5a</span><br><span class="line">u5a</span><br><span class="line">请统计：</span><br><span class="line">(1)每个店铺的UV（访客数）</span><br><span class="line">(2)每个店铺访问次数top3的访客信息。输出店铺名称、访客id、访问次数</span><br></pre></td></tr></table></figure><h3 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h3><h4 id="数据准备-1"><a href="#数据准备-1" class="headerlink" title="数据准备"></a>数据准备</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CREATE TABLE test_sql.test2 ( </span><br><span class="line"> user_id string, </span><br><span class="line"> shop string )</span><br><span class="line">ROW format delimited FIELDS TERMINATED BY <span class="string">'\t'</span>;</span><br><span class="line">INSERT INTO TABLE test_sql.test2 VALUES</span><br><span class="line">( <span class="string">'u1'</span>, <span class="string">'a'</span> ),</span><br><span class="line">( <span class="string">'u2'</span>, <span class="string">'b'</span> ),</span><br><span class="line">( <span class="string">'u1'</span>, <span class="string">'b'</span> ),</span><br><span class="line">( <span class="string">'u1'</span>, <span class="string">'a'</span> ),</span><br><span class="line">( <span class="string">'u3'</span>, <span class="string">'c'</span> ),</span><br><span class="line">( <span class="string">'u4'</span>, <span class="string">'b'</span> ),</span><br><span class="line">( <span class="string">'u1'</span>, <span class="string">'a'</span> ),</span><br><span class="line">( <span class="string">'u2'</span>, <span class="string">'c'</span> ),</span><br><span class="line">( <span class="string">'u5'</span>, <span class="string">'b'</span> ),</span><br><span class="line">( <span class="string">'u4'</span>, <span class="string">'b'</span> ),</span><br><span class="line">( <span class="string">'u6'</span>, <span class="string">'c'</span> ),</span><br><span class="line">( <span class="string">'u2'</span>, <span class="string">'c'</span> ),</span><br><span class="line">( <span class="string">'u1'</span>, <span class="string">'b'</span> ),</span><br><span class="line">( <span class="string">'u2'</span>, <span class="string">'a'</span> ),</span><br><span class="line">( <span class="string">'u2'</span>, <span class="string">'a'</span> ),</span><br><span class="line">( <span class="string">'u3'</span>, <span class="string">'a'</span> ),</span><br><span class="line">( <span class="string">'u5'</span>, <span class="string">'a'</span> ),</span><br><span class="line">( <span class="string">'u5'</span>, <span class="string">'a'</span> ),</span><br><span class="line">( <span class="string">'u5'</span>, <span class="string">'a'</span> );</span><br></pre></td></tr></table></figure><h4 id="查询SQL实现"><a href="#查询SQL实现" class="headerlink" title="查询SQL实现"></a>查询SQL实现</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(1)方式1：</span><br><span class="line">SELECT shop,</span><br><span class="line">   count(DISTINCT user_id)</span><br><span class="line">FROM test_sql.test2</span><br><span class="line">GROUP BY shop</span><br><span class="line">方式2：</span><br><span class="line">SELECT t.shop,</span><br><span class="line">   count(*)</span><br><span class="line">FROM</span><br><span class="line">  (SELECT user_id,</span><br><span class="line">  shop</span><br><span class="line">   FROM test_sql.test2</span><br><span class="line">   GROUP BY user_id,</span><br><span class="line">shop) t</span><br><span class="line">GROUP BY t.shop</span><br><span class="line">(2)</span><br><span class="line">SELECT t2.shop,</span><br><span class="line">   t2.user_id,</span><br><span class="line">   t2.cnt</span><br><span class="line">FROM</span><br><span class="line">  (SELECT t1.*,</span><br><span class="line">  row_number() over(partition BY t1.shop</span><br><span class="line">ORDER BY t1.cnt DESC) rank</span><br><span class="line">   FROM</span><br><span class="line"> (SELECT user_id,</span><br><span class="line"> shop,</span><br><span class="line"> count(*) AS cnt</span><br><span class="line">  FROM test_sql.test2</span><br><span class="line">  GROUP BY user_id,</span><br><span class="line">   shop) t1)t2</span><br><span class="line">WHERE rank &lt;= 3</span><br></pre></td></tr></table></figure><h2 id="第三题"><a href="#第三题" class="headerlink" title="第三题"></a>第三题</h2><h3 id="需求-2"><a href="#需求-2" class="headerlink" title="需求"></a>需求</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">已知一个表STG.ORDER，有如下字段:Date，Order_id，User_id，amount。</span><br><span class="line">数据样例:2017-01-01,10029028,1000003251,33.57。</span><br><span class="line">请给出sql进行统计:</span><br><span class="line">(1)给出 2017年每个月的订单数、用户数、总成交金额。</span><br><span class="line">(2)给出2017年11月的新客数(指在11月才有第一笔订单)</span><br></pre></td></tr></table></figure><h3 id="实现-2"><a href="#实现-2" class="headerlink" title="实现"></a>实现</h3><h4 id="数据准备-2"><a href="#数据准备-2" class="headerlink" title="数据准备"></a>数据准备</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CREATE TABLE test_sql.test3 ( </span><br><span class="line">dt string,</span><br><span class="line">order_id string, </span><br><span class="line">user_id string, </span><br><span class="line">amount DECIMAL ( 10, 2 ) )</span><br><span class="line">ROW format delimited FIELDS TERMINATED BY <span class="string">'\t'</span>;</span><br><span class="line">INSERT INTO TABLE test_sql.test3 VALUES (<span class="string">'2017-01-01'</span>,<span class="string">'10029028'</span>,<span class="string">'1000003251'</span>,33.57);</span><br><span class="line">INSERT INTO TABLE test_sql.test3 VALUES (<span class="string">'2017-01-01'</span>,<span class="string">'10029029'</span>,<span class="string">'1000003251'</span>,33.57);</span><br><span class="line">INSERT INTO TABLE test_sql.test3 VALUES (<span class="string">'2017-01-01'</span>,<span class="string">'100290288'</span>,<span class="string">'1000003252'</span>,33.57);</span><br><span class="line">INSERT INTO TABLE test_sql.test3 VALUES (<span class="string">'2017-02-02'</span>,<span class="string">'10029088'</span>,<span class="string">'1000003251'</span>,33.57);</span><br><span class="line">INSERT INTO TABLE test_sql.test3 VALUES (<span class="string">'2017-02-02'</span>,<span class="string">'100290281'</span>,<span class="string">'1000003251'</span>,33.57);</span><br><span class="line">INSERT INTO TABLE test_sql.test3 VALUES (<span class="string">'2017-02-02'</span>,<span class="string">'100290282'</span>,<span class="string">'1000003253'</span>,33.57);</span><br><span class="line">INSERT INTO TABLE test_sql.test3 VALUES (<span class="string">'2017-11-02'</span>,<span class="string">'10290282'</span>,<span class="string">'100003253'</span>,234);</span><br><span class="line">INSERT INTO TABLE test_sql.test3 VALUES (<span class="string">'2018-11-02'</span>,<span class="string">'10290284'</span>,<span class="string">'100003243'</span>,234);</span><br></pre></td></tr></table></figure><h4 id="查询SQL-1"><a href="#查询SQL-1" class="headerlink" title="查询SQL"></a>查询SQL</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(1)</span><br><span class="line">SELECT t1.mon,</span><br><span class="line">   count(t1.order_id) AS order_cnt,</span><br><span class="line">   count(DISTINCT t1.user_id) AS user_cnt,</span><br><span class="line">   sum(amount) AS total_amount</span><br><span class="line">FROM</span><br><span class="line">  (SELECT order_id,</span><br><span class="line">  user_id,</span><br><span class="line">  amount,</span><br><span class="line">  date_format(dt,<span class="string">'yyyy-MM'</span>) mon</span><br><span class="line">   FROM test_sql.test3</span><br><span class="line">   WHERE date_format(dt,<span class="string">'yyyy'</span>) = <span class="string">'2017'</span>) t1</span><br><span class="line">GROUP BY t1.mon</span><br><span class="line">(2)</span><br><span class="line">SELECT count(user_id)</span><br><span class="line">FROM test_sql.test3</span><br><span class="line">GROUP BY user_id</span><br><span class="line">HAVING date_format(min(dt),<span class="string">'yyyy-MM'</span>)=<span class="string">'2017-11'</span>;</span><br></pre></td></tr></table></figure><h2 id="第四题"><a href="#第四题" class="headerlink" title="第四题"></a>第四题</h2><h3 id="需求-3"><a href="#需求-3" class="headerlink" title="需求"></a>需求</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">有一个5000万的用户文件(user_id，name，age)，一个2亿记录的用户看电影的记录文件(user_id，url)，根据年龄段观看电影的次数进行排序？</span><br></pre></td></tr></table></figure><h3 id="实现-3"><a href="#实现-3" class="headerlink" title="实现"></a>实现</h3><h4 id="数据准备-3"><a href="#数据准备-3" class="headerlink" title="数据准备"></a>数据准备</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CREATE TABLE test_sql.test4user</span><br><span class="line">   (user_id string,</span><br><span class="line">name string,</span><br><span class="line">age int);</span><br><span class="line"></span><br><span class="line">CREATE TABLE test_sql.test4log</span><br><span class="line">(user_id string,</span><br><span class="line">url string);</span><br><span class="line"></span><br><span class="line">INSERT INTO TABLE test_sql.test4user VALUES(<span class="string">'001'</span>,<span class="string">'u1'</span>,10);</span><br><span class="line">INSERT INTO TABLE test_sql.test4user VALUES(<span class="string">'002'</span>,<span class="string">'u2'</span>,15);   </span><br><span class="line">INSERT INTO TABLE test_sql.test4user VALUES(<span class="string">'003'</span>,<span class="string">'u3'</span>,15);   </span><br><span class="line">INSERT INTO TABLE test_sql.test4user VALUES(<span class="string">'004'</span>,<span class="string">'u4'</span>,20);   </span><br><span class="line">INSERT INTO TABLE test_sql.test4user VALUES(<span class="string">'005'</span>,<span class="string">'u5'</span>,25);   </span><br><span class="line">INSERT INTO TABLE test_sql.test4user VALUES(<span class="string">'006'</span>,<span class="string">'u6'</span>,35);   </span><br><span class="line">INSERT INTO TABLE test_sql.test4user VALUES(<span class="string">'007'</span>,<span class="string">'u7'</span>,40);</span><br><span class="line">INSERT INTO TABLE test_sql.test4user VALUES(<span class="string">'008'</span>,<span class="string">'u8'</span>,45);  </span><br><span class="line">INSERT INTO TABLE test_sql.test4user VALUES(<span class="string">'009'</span>,<span class="string">'u9'</span>,50);  </span><br><span class="line">INSERT INTO TABLE test_sql.test4user VALUES(<span class="string">'0010'</span>,<span class="string">'u10'</span>,65);  </span><br><span class="line">INSERT INTO TABLE test_sql.test4log VALUES(<span class="string">'001'</span>,<span class="string">'url1'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test4log VALUES(<span class="string">'002'</span>,<span class="string">'url1'</span>);   </span><br><span class="line">INSERT INTO TABLE test_sql.test4log VALUES(<span class="string">'003'</span>,<span class="string">'url2'</span>);   </span><br><span class="line">INSERT INTO TABLE test_sql.test4log VALUES(<span class="string">'004'</span>,<span class="string">'url3'</span>);   </span><br><span class="line">INSERT INTO TABLE test_sql.test4log VALUES(<span class="string">'005'</span>,<span class="string">'url3'</span>);   </span><br><span class="line">INSERT INTO TABLE test_sql.test4log VALUES(<span class="string">'006'</span>,<span class="string">'url1'</span>);   </span><br><span class="line">INSERT INTO TABLE test_sql.test4log VALUES(<span class="string">'007'</span>,<span class="string">'url5'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test4log VALUES(<span class="string">'008'</span>,<span class="string">'url7'</span>);  </span><br><span class="line">INSERT INTO TABLE test_sql.test4log VALUES(<span class="string">'009'</span>,<span class="string">'url5'</span>);  </span><br><span class="line">INSERT INTO TABLE test_sql.test4log VALUES(<span class="string">'0010'</span>,<span class="string">'url1'</span>);</span><br></pre></td></tr></table></figure><h4 id="查询SQL-2"><a href="#查询SQL-2" class="headerlink" title="查询SQL"></a>查询SQL</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line">t2.age_phase,</span><br><span class="line">sum(t1.cnt) as view_cnt</span><br><span class="line">FROM</span><br><span class="line"></span><br><span class="line">(SELECT user_id,</span><br><span class="line">  count(*) cnt</span><br><span class="line">FROM test_sql.test4log</span><br><span class="line">GROUP BY user_id) t1</span><br><span class="line">JOIN</span><br><span class="line">(SELECT user_id,</span><br><span class="line">  CASE WHEN age &lt;= 10 AND age &gt; 0 THEN <span class="string">'0-10'</span> </span><br><span class="line">  WHEN age &lt;= 20 AND age &gt; 10 THEN <span class="string">'10-20'</span></span><br><span class="line">  WHEN age &gt;20 AND age &lt;=30 THEN <span class="string">'20-30'</span></span><br><span class="line">  WHEN age &gt;30 AND age &lt;=40 THEN <span class="string">'30-40'</span></span><br><span class="line">  WHEN age &gt;40 AND age &lt;=50 THEN <span class="string">'40-50'</span></span><br><span class="line">  WHEN age &gt;50 AND age &lt;=60 THEN <span class="string">'50-60'</span></span><br><span class="line">  WHEN age &gt;60 AND age &lt;=70 THEN <span class="string">'60-70'</span></span><br><span class="line">  ELSE <span class="string">'70以上'</span> END as age_phase</span><br><span class="line">FROM test_sql.test4user) t2 ON t1.user_id = t2.user_id </span><br><span class="line">GROUP BY t2.age_phase</span><br></pre></td></tr></table></figure><h2 id="第五题"><a href="#第五题" class="headerlink" title="第五题"></a>第五题</h2><h3 id="需求-4"><a href="#需求-4" class="headerlink" title="需求"></a>需求</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">有日志如下，请写出代码求得所有用户和活跃用户的总数及平均年龄。（活跃用户指连续两天都有访问记录的用户）</span><br><span class="line">日期 用户 年龄</span><br><span class="line">2019-02-11,test_1,23</span><br><span class="line">2019-02-11,test_2,19</span><br><span class="line">2019-02-11,test_3,39</span><br><span class="line">2019-02-11,test_1,23</span><br><span class="line">2019-02-11,test_3,39</span><br><span class="line">2019-02-11,test_1,23</span><br><span class="line">2019-02-12,test_2,19</span><br><span class="line">2019-02-13,test_1,23</span><br><span class="line">2019-02-15,test_2,19</span><br><span class="line">2019-02-16,test_2,19</span><br></pre></td></tr></table></figure><h3 id="实现-4"><a href="#实现-4" class="headerlink" title="实现"></a>实现</h3><h4 id="数据准备-4"><a href="#数据准备-4" class="headerlink" title="数据准备"></a>数据准备</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CREATE TABLE test5(</span><br><span class="line">dt string,</span><br><span class="line">user_id string,</span><br><span class="line">age int)</span><br><span class="line">ROW format delimited fields terminated BY <span class="string">','</span>;</span><br><span class="line">INSERT INTO TABLE test_sql.test5 VALUES (<span class="string">'2019-02-11'</span>,<span class="string">'test_1'</span>,23);</span><br><span class="line">INSERT INTO TABLE test_sql.test5 VALUES (<span class="string">'2019-02-11'</span>,<span class="string">'test_2'</span>,19);</span><br><span class="line">INSERT INTO TABLE test_sql.test5 VALUES (<span class="string">'2019-02-11'</span>,<span class="string">'test_3'</span>,39);</span><br><span class="line">INSERT INTO TABLE test_sql.test5 VALUES (<span class="string">'2019-02-11'</span>,<span class="string">'test_1'</span>,23);</span><br><span class="line">INSERT INTO TABLE test_sql.test5 VALUES (<span class="string">'2019-02-11'</span>,<span class="string">'test_3'</span>,39);</span><br><span class="line">INSERT INTO TABLE test_sql.test5 VALUES (<span class="string">'2019-02-11'</span>,<span class="string">'test_1'</span>,23);</span><br><span class="line">INSERT INTO TABLE test_sql.test5 VALUES (<span class="string">'2019-02-12'</span>,<span class="string">'test_2'</span>,19);</span><br><span class="line">INSERT INTO TABLE test_sql.test5 VALUES (<span class="string">'2019-02-13'</span>,<span class="string">'test_1'</span>,23);</span><br><span class="line">INSERT INTO TABLE test_sql.test5 VALUES (<span class="string">'2019-02-15'</span>,<span class="string">'test_2'</span>,19);                                        </span><br><span class="line">INSERT INTO TABLE test_sql.test5 VALUES (<span class="string">'2019-02-16'</span>,<span class="string">'test_2'</span>,19);</span><br></pre></td></tr></table></figure><h4 id="查询SQL-3"><a href="#查询SQL-3" class="headerlink" title="查询SQL"></a>查询SQL</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">SELECT sum(total_user_cnt) total_user_cnt,</span><br><span class="line">   sum(total_user_avg_age) total_user_avg_age,</span><br><span class="line">   sum(two_days_cnt) two_days_cnt,</span><br><span class="line">   sum(avg_age) avg_age</span><br><span class="line">FROM</span><br><span class="line">  (SELECT 0 total_user_cnt,</span><br><span class="line">  0 total_user_avg_age,</span><br><span class="line">  count(*) AS two_days_cnt,</span><br><span class="line">  cast(sum(age) / count(*) AS decimal(5,2)) AS avg_age</span><br><span class="line">   FROM</span><br><span class="line"> (SELECT user_id,</span><br><span class="line"> max(age) age</span><br><span class="line">  FROM</span><br><span class="line">(SELECT user_id,</span><br><span class="line">max(age) age</span><br><span class="line"> FROM</span><br><span class="line">   (SELECT user_id,</span><br><span class="line">   age,</span><br><span class="line">   date_sub(dt,rank) flag</span><br><span class="line">FROM</span><br><span class="line">  (SELECT dt,</span><br><span class="line">  user_id,</span><br><span class="line">  max(age) age,</span><br><span class="line">  row_number() over(PARTITION BY user_id</span><br><span class="line">ORDER BY dt) rank</span><br><span class="line">   FROM test_sql.test5</span><br><span class="line">   GROUP BY dt,</span><br><span class="line">user_id) t1) t2</span><br><span class="line"> GROUP BY user_id,</span><br><span class="line">  flag</span><br><span class="line"> HAVING count(*) &gt;=2) t3</span><br><span class="line">  GROUP BY user_id) t4</span><br><span class="line">   UNION ALL SELECT count(*) total_user_cnt,</span><br><span class="line">cast(sum(age) /count(*) AS decimal(5,2)) total_user_avg_age,</span><br><span class="line">0 two_days_cnt,</span><br><span class="line">0 avg_age</span><br><span class="line">   FROM</span><br><span class="line"> (SELECT user_id,</span><br><span class="line"> max(age) age</span><br><span class="line">  FROM test_sql.test5</span><br><span class="line">  GROUP BY user_id) t5) t6</span><br></pre></td></tr></table></figure><h2 id="第六题"><a href="#第六题" class="headerlink" title="第六题"></a>第六题</h2><h3 id="需求-5"><a href="#需求-5" class="headerlink" title="需求"></a>需求</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">请用sql写出所有用户中在今年10月份第一次购买商品的金额，</span><br><span class="line">表ordertable字段:</span><br><span class="line">(购买用户：userid，金额：money，购买时间：paymenttime(格式：2017-10-01)，订单id：orderid</span><br></pre></td></tr></table></figure><h3 id="实现-5"><a href="#实现-5" class="headerlink" title="实现"></a>实现</h3><h4 id="数据准备-5"><a href="#数据准备-5" class="headerlink" title="数据准备"></a>数据准备</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CREATE TABLE test_sql.test6 (</span><br><span class="line">userid string,</span><br><span class="line">money decimal(10,2),</span><br><span class="line">paymenttime string,</span><br><span class="line">orderid string);</span><br><span class="line"></span><br><span class="line">INSERT INTO TABLE test_sql.test6 VALUES(<span class="string">'001'</span>,100,<span class="string">'2017-10-01'</span>,<span class="string">'123'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test6 VALUES(<span class="string">'001'</span>,200,<span class="string">'2017-10-02'</span>,<span class="string">'124'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test6 VALUES(<span class="string">'002'</span>,500,<span class="string">'2017-10-01'</span>,<span class="string">'125'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test6 VALUES(<span class="string">'001'</span>,100,<span class="string">'2017-11-01'</span>,<span class="string">'126'</span>);</span><br></pre></td></tr></table></figure><h4 id="查询SQL-4"><a href="#查询SQL-4" class="headerlink" title="查询SQL"></a>查询SQL</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">SELECT</span><br><span class="line">userid,</span><br><span class="line">paymenttime,</span><br><span class="line">money,</span><br><span class="line">orderid</span><br><span class="line">from</span><br><span class="line">(SELECT userid,</span><br><span class="line">   money,</span><br><span class="line">   paymenttime,</span><br><span class="line">   orderid,</span><br><span class="line">   row_number() over (PARTITION BY userid</span><br><span class="line">  ORDER BY paymenttime) rank</span><br><span class="line">FROM test_sql.test6</span><br><span class="line">WHERE date_format(paymenttime,<span class="string">'yyyy-MM'</span>) = <span class="string">'2017-10'</span>) t</span><br><span class="line">WHERE rank = 1</span><br></pre></td></tr></table></figure><h2 id="第七题"><a href="#第七题" class="headerlink" title="第七题"></a>第七题</h2><h3 id="需求-6"><a href="#需求-6" class="headerlink" title="需求"></a>需求</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">现有图书管理数据库的三个数据模型如下：</span><br><span class="line">图书（数据表名：BOOK）</span><br><span class="line">序号  字段名称    字段描述    字段类型</span><br><span class="line">1   BOOK_ID 总编号 文本</span><br><span class="line">2   SORT    分类号 文本</span><br><span class="line">3   BOOK_NAME   书名  文本</span><br><span class="line">4   WRITER  作者  文本</span><br><span class="line">5   OUTPUT  出版单位    文本</span><br><span class="line">6   PRICE   单价  数值（保留小数点后2位）</span><br><span class="line">读者（数据表名：READER）</span><br><span class="line">序号  字段名称    字段描述    字段类型</span><br><span class="line">1   READER_ID   借书证号    文本</span><br><span class="line">2   COMPANY 单位  文本</span><br><span class="line">3   NAME    姓名  文本</span><br><span class="line">4   SEX 性别  文本</span><br><span class="line">5   GRADE   职称  文本</span><br><span class="line">6   ADDR    地址  文本</span><br><span class="line">借阅记录（数据表名：BORROW LOG）</span><br><span class="line">序号  字段名称    字段描述    字段类型</span><br><span class="line">1   READER_ID   借书证号    文本</span><br><span class="line">2   BOOK_ID  总编号 文本</span><br><span class="line">3   BORROW_DATE  借书日期    日期</span><br><span class="line">（1）创建图书管理库的图书、读者和借阅三个基本表的表结构。请写出建表语句。</span><br><span class="line">（2）找出姓李的读者姓名（NAME）和所在单位（COMPANY）。</span><br><span class="line">（3）查找“高等教育出版社”的所有图书名称（BOOK_NAME）及单价（PRICE），结果按单价降序排序。</span><br><span class="line">（4）查找价格介于10元和20元之间的图书种类(SORT）出版单位（OUTPUT）和单价（PRICE），结果按出版单位（OUTPUT）和单价（PRICE）升序排序。</span><br><span class="line">（5）查找所有借了书的读者的姓名（NAME）及所在单位（COMPANY）。</span><br><span class="line">（6）求”科学出版社”图书的最高单价、最低单价、平均单价。</span><br><span class="line">（7）找出当前至少借阅了2本图书（大于等于2本）的读者姓名及其所在单位。</span><br><span class="line">（8）考虑到数据安全的需要，需定时将“借阅记录”中数据进行备份，请使用一条SQL语句，在备份用户bak下创建与“借阅记录”表结构完全一致的数据表BORROW_LOG_BAK.井且将“借阅记录”中现有数据全部复制到BORROW_L0G_ BAK中。</span><br><span class="line">（9）现在需要将原Oracle数据库中数据迁移至Hive仓库，请写出“图书”在Hive中的建表语句（Hive实现，提示：列分隔符|；数据表数据需要外部导入：分区分别以month＿part、day＿part 命名）</span><br><span class="line">（10）Hive中有表A，现在需要将表A的月分区　201505　中　user＿id为20000的user＿dinner字段更新为bonc8920，其他用户user＿dinner字段数据不变，请列出更新的方法步骤。（Hive实现，提示：Hlive中无update语法，请通过其他办法进行数据更新）</span><br></pre></td></tr></table></figure><h3 id="实现-6"><a href="#实现-6" class="headerlink" title="实现"></a>实现</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(1)</span><br><span class="line"></span><br><span class="line">-- 创建图书表book</span><br><span class="line"></span><br><span class="line">CREATE TABLE test_sql.book(book_id string,</span><br><span class="line">   `SORT` string,</span><br><span class="line">   book_name string,</span><br><span class="line">   writer string,</span><br><span class="line">   OUTPUT string,</span><br><span class="line">   price decimal(10,2));</span><br><span class="line">INSERT INTO TABLE test_sql.book VALUES (<span class="string">'001'</span>,<span class="string">'TP391'</span>,<span class="string">'信息处理'</span>,<span class="string">'author1'</span>,<span class="string">'机械工业出版社'</span>,<span class="string">'20'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.book VALUES (<span class="string">'002'</span>,<span class="string">'TP392'</span>,<span class="string">'数据库'</span>,<span class="string">'author12'</span>,<span class="string">'科学出版社'</span>,<span class="string">'15'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.book VALUES (<span class="string">'003'</span>,<span class="string">'TP393'</span>,<span class="string">'计算机网络'</span>,<span class="string">'author3'</span>,<span class="string">'机械工业出版社'</span>,<span class="string">'29'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.book VALUES (<span class="string">'004'</span>,<span class="string">'TP399'</span>,<span class="string">'微机原理'</span>,<span class="string">'author4'</span>,<span class="string">'科学出版社'</span>,<span class="string">'39'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.book VALUES (<span class="string">'005'</span>,<span class="string">'C931'</span>,<span class="string">'管理信息系统'</span>,<span class="string">'author5'</span>,<span class="string">'机械工业出版社'</span>,<span class="string">'40'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.book VALUES (<span class="string">'006'</span>,<span class="string">'C932'</span>,<span class="string">'运筹学'</span>,<span class="string">'author6'</span>,<span class="string">'科学出版社'</span>,<span class="string">'55'</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-- 创建读者表reader</span><br><span class="line"></span><br><span class="line">CREATE TABLE test_sql.reader (reader_id string,</span><br><span class="line">  company string,</span><br><span class="line">  name string,</span><br><span class="line">  sex string,</span><br><span class="line">  grade string,</span><br><span class="line">  addr string);</span><br><span class="line">INSERT INTO TABLE test_sql.reader VALUES (<span class="string">'0001'</span>,<span class="string">'阿里巴巴'</span>,<span class="string">'jack'</span>,<span class="string">'男'</span>,<span class="string">'vp'</span>,<span class="string">'addr1'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.reader VALUES (<span class="string">'0002'</span>,<span class="string">'百度'</span>,<span class="string">'robin'</span>,<span class="string">'男'</span>,<span class="string">'vp'</span>,<span class="string">'addr2'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.reader VALUES (<span class="string">'0003'</span>,<span class="string">'腾讯'</span>,<span class="string">'tony'</span>,<span class="string">'男'</span>,<span class="string">'vp'</span>,<span class="string">'addr3'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.reader VALUES (<span class="string">'0004'</span>,<span class="string">'京东'</span>,<span class="string">'jasper'</span>,<span class="string">'男'</span>,<span class="string">'cfo'</span>,<span class="string">'addr4'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.reader VALUES (<span class="string">'0005'</span>,<span class="string">'网易'</span>,<span class="string">'zhangsan'</span>,<span class="string">'女'</span>,<span class="string">'ceo'</span>,<span class="string">'addr5'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.reader VALUES (<span class="string">'0006'</span>,<span class="string">'搜狐'</span>,<span class="string">'lisi'</span>,<span class="string">'女'</span>,<span class="string">'ceo'</span>,<span class="string">'addr6'</span>);</span><br><span class="line"></span><br><span class="line">-- 创建借阅记录表borrow_log</span><br><span class="line"></span><br><span class="line">CREATE TABLE test_sql.borrow_log(reader_id string,</span><br><span class="line"> book_id string,</span><br><span class="line"> borrow_date string);</span><br><span class="line"> </span><br><span class="line">INSERT INTO TABLE test_sql.borrow_log VALUES (<span class="string">'0001'</span>,<span class="string">'002'</span>,<span class="string">'2019-10-14'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.borrow_log VALUES (<span class="string">'0002'</span>,<span class="string">'001'</span>,<span class="string">'2019-10-13'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.borrow_log VALUES (<span class="string">'0003'</span>,<span class="string">'005'</span>,<span class="string">'2019-09-14'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.borrow_log VALUES (<span class="string">'0004'</span>,<span class="string">'006'</span>,<span class="string">'2019-08-15'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.borrow_log VALUES (<span class="string">'0005'</span>,<span class="string">'003'</span>,<span class="string">'2019-10-10'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.borrow_log VALUES (<span class="string">'0006'</span>,<span class="string">'004'</span>,<span class="string">'2019-17-13'</span>);</span><br><span class="line"></span><br><span class="line">(2)</span><br><span class="line">SELECT name,</span><br><span class="line">   company</span><br><span class="line">FROM test_sql.reader</span><br><span class="line">WHERE name LIKE <span class="string">'李%'</span>;</span><br><span class="line">(3)</span><br><span class="line">SELECT book_name,</span><br><span class="line">   price</span><br><span class="line">FROM test_sql.book</span><br><span class="line">WHERE OUTPUT = <span class="string">"高等教育出版社"</span></span><br><span class="line">ORDER BY price DESC;</span><br><span class="line">(4)</span><br><span class="line">SELECT sort,</span><br><span class="line">   output,</span><br><span class="line">   price</span><br><span class="line">FROM test_sql.book</span><br><span class="line">WHERE price &gt;= 10 and price &lt;= 20</span><br><span class="line">ORDER BY output,price ;</span><br><span class="line">(5)</span><br><span class="line">SELECT b.name,</span><br><span class="line">   b.company</span><br><span class="line">FROM test_sql.borrow_log a</span><br><span class="line">JOIN test_sql.reader b ON a.reader_id = b.reader_id;</span><br><span class="line">(6)</span><br><span class="line">SELECT max(price),</span><br><span class="line">   min(price),</span><br><span class="line">   avg(price)</span><br><span class="line">FROM test_sql.book</span><br><span class="line">WHERE OUTPUT = <span class="string">'科学出版社'</span>;</span><br><span class="line">(7)</span><br><span class="line">SELECT b.name,</span><br><span class="line">   b.company</span><br><span class="line">FROM</span><br><span class="line">  (SELECT reader_id</span><br><span class="line">   FROM test_sql.borrow_log</span><br><span class="line">   GROUP BY reader_id</span><br><span class="line">   HAVING count(*) &gt;= 2) a</span><br><span class="line">JOIN test_sql.reader b ON a.reader_id = b.reader_id;</span><br><span class="line"></span><br><span class="line">(8)</span><br><span class="line">CREATE TABLE test_sql.borrow_log_bak AS</span><br><span class="line">SELECT *</span><br><span class="line">FROM test_sql.borrow_log;</span><br><span class="line">(9)</span><br><span class="line">CREATE TABLE book_hive ( </span><br><span class="line">book_id string,</span><br><span class="line">SORT string, </span><br><span class="line">book_name string,</span><br><span class="line">writer string, </span><br><span class="line">OUTPUT string, </span><br><span class="line">price DECIMAL ( 10, 2 ) )</span><br><span class="line">partitioned BY ( month_part string, day_part string )</span><br><span class="line">ROW format delimited FIELDS TERMINATED BY <span class="string">'\\|'</span> stored AS textfile;</span><br><span class="line">(10)</span><br><span class="line">方式1：配置hive支持事务操作，分桶表，orc存储格式</span><br><span class="line">方式2：第一步找到要更新的数据，将要更改的字段替换为新的值，第二步找到不需要更新的数据，第三步将上两步的数据插入一张新表中。</span><br></pre></td></tr></table></figure><h2 id="第八题"><a href="#第八题" class="headerlink" title="第八题"></a>第八题</h2><h3 id="需求-7"><a href="#需求-7" class="headerlink" title="需求"></a>需求</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">有一个线上服务器访问日志格式如下（用sql答题）</span><br><span class="line">时间                    接口                         ip地址</span><br><span class="line">2016-11-09 14:22:05/api/user/login110.23.5.33</span><br><span class="line">2016-11-09 14:23:10/api/user/detail57.3.2.16</span><br><span class="line">2016-11-09 15:59:40/api/user/login200.6.5.166</span><br><span class="line">… …</span><br><span class="line">求11月9号下午14点（14-15点），访问/api/user/login接口的top10的ip地址</span><br></pre></td></tr></table></figure><h3 id="实现-7"><a href="#实现-7" class="headerlink" title="实现"></a>实现</h3><h4 id="数据准备-6"><a href="#数据准备-6" class="headerlink" title="数据准备"></a>数据准备</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CREATE TABLE test_sql.test8(`date` string,</span><br><span class="line">interface string,</span><br><span class="line">ip string);</span><br><span class="line"></span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES (<span class="string">'2016-11-09 11:22:05'</span>,<span class="string">'/api/user/login'</span>,<span class="string">'110.23.5.23'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES (<span class="string">'2016-11-09 11:23:10'</span>,<span class="string">'/api/user/detail'</span>,<span class="string">'57.3.2.16'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES (<span class="string">'2016-11-09 23:59:40'</span>,<span class="string">'/api/user/login'</span>,<span class="string">'200.6.5.166'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES(<span class="string">'2016-11-09 11:14:23'</span>,<span class="string">'/api/user/login'</span>,<span class="string">'136.79.47.70'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES(<span class="string">'2016-11-09 11:15:23'</span>,<span class="string">'/api/user/detail'</span>,<span class="string">'94.144.143.141'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES(<span class="string">'2016-11-09 11:16:23'</span>,<span class="string">'/api/user/login'</span>,<span class="string">'197.161.8.206'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES(<span class="string">'2016-11-09 12:14:23'</span>,<span class="string">'/api/user/detail'</span>,<span class="string">'240.227.107.145'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES(<span class="string">'2016-11-09 13:14:23'</span>,<span class="string">'/api/user/login'</span>,<span class="string">'79.130.122.205'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES(<span class="string">'2016-11-09 14:14:23'</span>,<span class="string">'/api/user/detail'</span>,<span class="string">'65.228.251.189'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES(<span class="string">'2016-11-09 14:15:23'</span>,<span class="string">'/api/user/detail'</span>,<span class="string">'245.23.122.44'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES(<span class="string">'2016-11-09 14:17:23'</span>,<span class="string">'/api/user/detail'</span>,<span class="string">'22.74.142.137'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES(<span class="string">'2016-11-09 14:19:23'</span>,<span class="string">'/api/user/detail'</span>,<span class="string">'54.93.212.87'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES(<span class="string">'2016-11-09 14:20:23'</span>,<span class="string">'/api/user/detail'</span>,<span class="string">'218.15.167.248'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES(<span class="string">'2016-11-09 14:24:23'</span>,<span class="string">'/api/user/detail'</span>,<span class="string">'20.117.19.75'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES(<span class="string">'2016-11-09 15:14:23'</span>,<span class="string">'/api/user/login'</span>,<span class="string">'183.162.66.97'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES(<span class="string">'2016-11-09 16:14:23'</span>,<span class="string">'/api/user/login'</span>,<span class="string">'108.181.245.147'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES(<span class="string">'2016-11-09 14:17:23'</span>,<span class="string">'/api/user/login'</span>,<span class="string">'22.74.142.137'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test8 VALUES(<span class="string">'2016-11-09 14:19:23'</span>,<span class="string">'/api/user/login'</span>,<span class="string">'22.74.142.137'</span>);</span><br></pre></td></tr></table></figure><h4 id="查询SQL-5"><a href="#查询SQL-5" class="headerlink" title="查询SQL"></a>查询SQL</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">SELECT ip,</span><br><span class="line">   count(*) AS cnt</span><br><span class="line">FROM test_sql.test8</span><br><span class="line">WHERE date_format(date,<span class="string">'yyyy-MM-dd HH'</span>) &gt;= <span class="string">'2016-11-09 14'</span></span><br><span class="line">  AND date_format(date,<span class="string">'yyyy-MM-dd HH'</span>) &lt; <span class="string">'2016-11-09 15'</span></span><br><span class="line">  AND interface=<span class="string">'/api/user/login'</span></span><br><span class="line">GROUP BY ip</span><br><span class="line">ORDER BY cnt desc</span><br><span class="line">LIMIT 10;</span><br></pre></td></tr></table></figure><h2 id="第九题"><a href="#第九题" class="headerlink" title="第九题"></a>第九题</h2><h3 id="需求-8"><a href="#需求-8" class="headerlink" title="需求"></a>需求</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">有一个充值日志表credit_log，字段如下：</span><br><span class="line"></span><br><span class="line">`dist_id` int  <span class="string">'区组id'</span>,</span><br><span class="line">`account` string  <span class="string">'账号'</span>,</span><br><span class="line">`money` int   <span class="string">'充值金额'</span>,</span><br><span class="line">`create_time` string  <span class="string">'订单时间'</span></span><br><span class="line"></span><br><span class="line">请写出SQL语句，查询充值日志表2019年01月02号每个区组下充值额最大的账号，要求结果：</span><br><span class="line">区组id，账号，金额，充值时间</span><br></pre></td></tr></table></figure><h3 id="实现-8"><a href="#实现-8" class="headerlink" title="实现"></a>实现</h3><h4 id="数据准备-7"><a href="#数据准备-7" class="headerlink" title="数据准备"></a>数据准备</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CREATE TABLE test_sql.test9(</span><br><span class="line">dist_id string COMMENT <span class="string">'区组id'</span>,</span><br><span class="line">account string COMMENT <span class="string">'账号'</span>,</span><br><span class="line">   `money` decimal(10,2) COMMENT <span class="string">'充值金额'</span>,</span><br><span class="line">create_time string COMMENT <span class="string">'订单时间'</span>);</span><br><span class="line"></span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'1'</span>,<span class="string">'11'</span>,100006,<span class="string">'2019-01-02 13:00:01'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'1'</span>,<span class="string">'22'</span>,110000,<span class="string">'2019-01-02 13:00:02'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'1'</span>,<span class="string">'33'</span>,102000,<span class="string">'2019-01-02 13:00:03'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'1'</span>,<span class="string">'44'</span>,100300,<span class="string">'2019-01-02 13:00:04'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'1'</span>,<span class="string">'55'</span>,100040,<span class="string">'2019-01-02 13:00:05'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'1'</span>,<span class="string">'66'</span>,100005,<span class="string">'2019-01-02 13:00:06'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'1'</span>,<span class="string">'77'</span>,180000,<span class="string">'2019-01-03 13:00:07'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'1'</span>,<span class="string">'88'</span>,106000,<span class="string">'2019-01-02 13:00:08'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'1'</span>,<span class="string">'99'</span>,100400,<span class="string">'2019-01-02 13:00:09'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'1'</span>,<span class="string">'12'</span>,100030,<span class="string">'2019-01-02 13:00:10'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'1'</span>,<span class="string">'13'</span>,100003,<span class="string">'2019-01-02 13:00:20'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'1'</span>,<span class="string">'14'</span>,100020,<span class="string">'2019-01-02 13:00:30'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'1'</span>,<span class="string">'15'</span>,100500,<span class="string">'2019-01-02 13:00:40'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'1'</span>,<span class="string">'16'</span>,106000,<span class="string">'2019-01-02 13:00:50'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'1'</span>,<span class="string">'17'</span>,100800,<span class="string">'2019-01-02 13:00:59'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'2'</span>,<span class="string">'18'</span>,100800,<span class="string">'2019-01-02 13:00:11'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'2'</span>,<span class="string">'19'</span>,100030,<span class="string">'2019-01-02 13:00:12'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'2'</span>,<span class="string">'10'</span>,100000,<span class="string">'2019-01-02 13:00:13'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'2'</span>,<span class="string">'45'</span>,100010,<span class="string">'2019-01-02 13:00:14'</span>);</span><br><span class="line">INSERT INTO TABLE test_sql.test9 VALUES (<span class="string">'2'</span>,<span class="string">'78'</span>,100070,<span class="string">'2019-01-02 13:00:15'</span>);</span><br></pre></td></tr></table></figure><h4 id="查询SQL-6"><a href="#查询SQL-6" class="headerlink" title="查询SQL"></a>查询SQL</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">WITH TEMP AS</span><br><span class="line">  (SELECT dist_id,</span><br><span class="line">  account,</span><br><span class="line">  sum(`money`) sum_money</span><br><span class="line">   FROM test_sql.test9</span><br><span class="line">   WHERE date_format(create_time,<span class="string">'yyyy-MM-dd'</span>) = <span class="string">'2019-01-02'</span></span><br><span class="line">   GROUP BY dist_id,</span><br><span class="line">account)</span><br><span class="line">SELECT t1.dist_id,</span><br><span class="line">   t1.account,</span><br><span class="line">   t1.sum_money</span><br><span class="line">FROM</span><br><span class="line">  (SELECT temp.dist_id,</span><br><span class="line">  temp.account,</span><br><span class="line">  temp.sum_money,</span><br><span class="line">  rank() over(partition BY temp.dist_id</span><br><span class="line">  ORDER BY temp.sum_money DESC) ranks</span><br><span class="line">   FROM TEMP) t1</span><br><span class="line">WHERE ranks = 1</span><br></pre></td></tr></table></figure><h2 id="第十题"><a href="#第十题" class="headerlink" title="第十题"></a>第十题</h2><h3 id="需求-9"><a href="#需求-9" class="headerlink" title="需求"></a>需求</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">有一个账号表如下，请写出SQL语句，查询各自区组的money排名前十的账号（分组取前10）</span><br><span class="line">dist_id string  <span class="string">'区组id'</span>,</span><br><span class="line">account string  <span class="string">'账号'</span>,</span><br><span class="line">gold     int    <span class="string">'金币'</span></span><br></pre></td></tr></table></figure><h3 id="实现-9"><a href="#实现-9" class="headerlink" title="实现"></a>实现</h3><h4 id="数据准备-8"><a href="#数据准备-8" class="headerlink" title="数据准备"></a>数据准备</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CREATE TABLE test_sql.test10(</span><br><span class="line">`dist_id` string COMMENT <span class="string">'区组id'</span>,</span><br><span class="line">`account` string COMMENT <span class="string">'账号'</span>,</span><br><span class="line">`gold` int COMMENT <span class="string">'金币'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">INSERT INTO TABLE test_sql.test10 VALUES (<span class="string">'1'</span>,<span class="string">'77'</span>,18);</span><br><span class="line">INSERT INTO TABLE test_sql.test10 VALUES (<span class="string">'1'</span>,<span class="string">'88'</span>,106);</span><br><span class="line">INSERT INTO TABLE test_sql.test10 VALUES (<span class="string">'1'</span>,<span class="string">'99'</span>,10);</span><br><span class="line">INSERT INTO TABLE test_sql.test10 VALUES (<span class="string">'1'</span>,<span class="string">'12'</span>,13);</span><br><span class="line">INSERT INTO TABLE test_sql.test10 VALUES (<span class="string">'1'</span>,<span class="string">'13'</span>,14);</span><br><span class="line">INSERT INTO TABLE test_sql.test10 VALUES (<span class="string">'1'</span>,<span class="string">'14'</span>,25);</span><br><span class="line">INSERT INTO TABLE test_sql.test10 VALUES (<span class="string">'1'</span>,<span class="string">'15'</span>,36);</span><br><span class="line">INSERT INTO TABLE test_sql.test10 VALUES (<span class="string">'1'</span>,<span class="string">'16'</span>,12);</span><br><span class="line">INSERT INTO TABLE test_sql.test10 VALUES (<span class="string">'1'</span>,<span class="string">'17'</span>,158);</span><br><span class="line">INSERT INTO TABLE test_sql.test10 VALUES (<span class="string">'2'</span>,<span class="string">'18'</span>,12);</span><br><span class="line">INSERT INTO TABLE test_sql.test10 VALUES (<span class="string">'2'</span>,<span class="string">'19'</span>,44);</span><br><span class="line">INSERT INTO TABLE test_sql.test10 VALUES (<span class="string">'2'</span>,<span class="string">'10'</span>,66);</span><br><span class="line">INSERT INTO TABLE test_sql.test10 VALUES (<span class="string">'2'</span>,<span class="string">'45'</span>,80);</span><br><span class="line">INSERT INTO TABLE test_sql.test10 VALUES (<span class="string">'2'</span>,<span class="string">'78'</span>,98);</span><br></pre></td></tr></table></figure><h4 id="查询SQL-7"><a href="#查询SQL-7" class="headerlink" title="查询SQL"></a>查询SQL</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">SELECT dist_id,</span><br><span class="line">   account,</span><br><span class="line">   gold</span><br><span class="line">FROM</span><br><span class="line">(SELECT dist_id,</span><br><span class="line">  account,</span><br><span class="line">  gold,</span><br><span class="line">  row_number () over (PARTITION BY dist_id</span><br><span class="line">  ORDER BY gold DESC) rank</span><br><span class="line">FROM test_sql.test10) t</span><br><span class="line">WHERE rank &lt;= 10</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Hive </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink的Window Function介绍</title>
      <link href="/2019/09/26/Flink%E7%9A%84Window-Function%E4%BB%8B%E7%BB%8D/"/>
      <url>/2019/09/26/Flink%E7%9A%84Window-Function%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Impala使用的端口</title>
      <link href="/2019/08/29/Impala%E4%BD%BF%E7%94%A8%E7%9A%84%E7%AB%AF%E5%8F%A3/"/>
      <url>/2019/08/29/Impala%E4%BD%BF%E7%94%A8%E7%9A%84%E7%AB%AF%E5%8F%A3/</url>
      
        <content type="html"><![CDATA[<p>本文主要介绍了Impala所使用的端口号，在部署Impala的时候，确保下面列出的端口是开启的。</p><a id="more"></a><table><thead><tr><th align="center">组件</th><th>服务</th><th>端口</th><th align="center"><span style="white-space:nowrap;">访问需求&emsp;&emsp;</span></th><th>备注</th></tr></thead><tbody><tr><td align="center">Impala Daemon</td><td>Impala Daemon Frontend Port</td><td>21000</td><td align="center">外部</td><td>被 impala-shell, Beeswax, Cloudera ODBC 1.2 驱动 用于传递命令和接收结果</td></tr><tr><td align="center">Impala Daemon</td><td>Impala Daemon Frontend Port</td><td>21050</td><td align="center">外部</td><td>被使用 JDBC 或 Cloudera ODBC 2.0 及以上驱动的诸如 BI 工具之类的应用用来传递命令和接收结果</td></tr><tr><td align="center">Impala Daemon</td><td>Impala Daemon Backend Port</td><td>22000</td><td align="center">内部</td><td>仅内部使用。Impala</td></tr><tr><td align="center">Impala Daemon</td><td>StateStoreSubscriber Service Port</td><td>23000</td><td align="center">内部</td><td>仅内部使用。Impala 守护进程监听该端口接收来源于 state store 的更新</td></tr><tr><td align="center">Catalog Daemon</td><td>StateStoreSubscriber Service Port</td><td>23020</td><td align="center">内部</td><td>仅内部使用，catalog daemon监听该端口接收来源于 state store 的更新</td></tr><tr><td align="center">Impala Daemon</td><td>Impala Daemon HTTP Server Port</td><td>25000</td><td align="center">外部</td><td>Impala Daemon的Web端口，用于管理员监控和线上故障排查</td></tr><tr><td align="center">Impala StateStore Daemon</td><td>StateStore HTTP Server Port</td><td>25010</td><td align="center">外部</td><td>StateStore的Web端口，用于管理员监控和线上故障排查</td></tr><tr><td align="center">Impala Catalog Daemon</td><td>Catalog HTTP Server Port</td><td>25020</td><td align="center">外部</td><td>Catalog的Web端口，用于管理员监控和线上故障排查，从Impala1.2开始加入</td></tr><tr><td align="center">Impala StateStore Daemon</td><td>StateStore Service Port</td><td>24000</td><td align="center">内部</td><td>仅内部使用，statestore daemon监听的端口，用于registration/unregistration请求</td></tr><tr><td align="center">Impala Catalog Daemon</td><td>Catalog Service Port</td><td>26000</td><td align="center">内部</td><td>仅内部使用，catalog服务使用此端口与Impala Daemon进行通信，从Impala1.2开始加入</td></tr><tr><td align="center">Impala Daemon</td><td>KRPC Port</td><td>27000</td><td align="center">内部</td><td>仅内部使用，Impala daemon使用此端口进行基于krpc的相互通信。</td></tr></tbody></table><hr><p>Refrence:<a href="https://www.cloudera.com/documentation/enterprise/6/latest/topics/impala_ports.html#ports" target="_blank" rel="noopener">https://www.cloudera.com/documentation/enterprise/6/latest/topics/impala_ports.html#ports</a></p>]]></content>
      
      
      <categories>
          
          <category> Impala </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Impala </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Azkaban安装部署</title>
      <link href="/2019/08/28/Azkaban%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
      <url>/2019/08/28/Azkaban%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<p>Azkaban是由Linkedin开源的一个批量工作流任务调度器。用于在一个工作流内以一个特定的顺序运行一组工作和流程。Azkaban定义了一种KV文件格式来建立任务之间的依赖关系，并提供一个易于使用的web用户界面维护和跟踪你的工作流。</p><a id="more"></a><h1 id="安装前准备"><a href="#安装前准备" class="headerlink" title="安装前准备"></a>安装前准备</h1><p>(1)将Azkaban Web服务器、Azkaban执行服务器要安装机器的/opt/software目录下：  </p><ul><li>azkaban-web-server-2.5.0.tar.gz  </li><li>azkaban-executor-server-2.5.0.tar.gz  </li><li>azkaban-sql-script-2.5.0.tar.gz  </li><li>mysql-libs.zip  </li></ul><p>(2)目前azkaban只支持 mysql作为元数据库，需安装mysql，本文档中默认已安装好mysql服务器</p><h1 id="安装Azkaban"><a href="#安装Azkaban" class="headerlink" title="安装Azkaban"></a>安装Azkaban</h1><p>(1)在/opt/module/目录下创建azkaban目录<br>(2)解压azkaban-web-server-2.5.0.tar.gz、azkaban-executor-server-2.5.0.tar.gz、azkaban-sql-script-2.5.0.tar.gz到/opt/module/azkaban目录下<br>解压完成后的文件夹如下图所示：<br><img src="//jiamaoxiang.top/2019/08/28/Azkaban安装部署/1.png" alt><br>(3)初始化Azkaban的元数据库<br>登录mysql，创建azkaban的数据库，并执行脚本create-all-sql-2.5.0.sql，如下所示：  </p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql&gt; create database azkaban;  </span><br><span class="line">Query OK, 1 row affected (0.00 sec)  </span><br><span class="line">mysql&gt; use azkaban;  </span><br><span class="line">Database changed  </span><br><span class="line">mysql&gt; <span class="built_in">source</span> /opt/module/azkaban/azkaban-2.5.0/create-all-sql-2.5.0.sql</span><br></pre></td></tr></table></figure><h2 id="创建SSL配置"><a href="#创建SSL配置" class="headerlink" title="创建SSL配置"></a>创建SSL配置</h2><p>(1)生成 keystore的密码及相应信息  </p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@cdh02 azkaban]$ keytool -keystore keystore -<span class="built_in">alias</span> jetty -genkey -keyalg RSA  </span><br><span class="line">输入keystore密码：   </span><br><span class="line">再次输入新密码:    </span><br><span class="line">您的名字与姓氏是什么？    </span><br><span class="line">[Unknown]：     </span><br><span class="line">您的组织单位名称是什么？    </span><br><span class="line">[Unknown]：     </span><br><span class="line">您的组织名称是什么？    </span><br><span class="line">[Unknown]：     </span><br><span class="line">您所在的城市或区域名称是什么？    </span><br><span class="line">[Unknown]：     </span><br><span class="line">您所在的州或省份名称是什么？    </span><br><span class="line">[Unknown]：     </span><br><span class="line">该单位的两字母国家代码是什么    </span><br><span class="line">[Unknown]：  CN    </span><br><span class="line">CN=Unknown, OU=Unknown, O=Unknown, L=Unknown, ST=Unknown, C=CN 正确吗？  </span><br><span class="line">[否]：  y    </span><br><span class="line"> </span><br><span class="line">输入&lt;jetty&gt;的主密码    </span><br><span class="line">（如果和 keystore 密码相同，按回车）  ：</span><br></pre></td></tr></table></figure><p>(2)将keystore 考贝到 azkaban web服务器根目录中</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@cdh02 azkaban]<span class="comment"># mv keystore  azkaban-web-2.5.0/</span></span><br></pre></td></tr></table></figure><h2 id="Web服务器配置"><a href="#Web服务器配置" class="headerlink" title="Web服务器配置"></a>Web服务器配置</h2><p>(1)进入azkaban web服务器安装目录 conf目录，修改azkaban.properties文件<br>(2)按照如下配置修改azkaban.properties文件</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Azkaban Personalization Settings      </span></span><br><span class="line"><span class="comment">#服务器UI名称,用于服务器上方显示的名字      </span></span><br><span class="line">azkaban.name=Test      </span><br><span class="line"><span class="comment">#描述                            </span></span><br><span class="line">azkaban.label=My Local Azkaban     </span><br><span class="line"><span class="comment">#UI颜色                         </span></span><br><span class="line">azkaban.color=<span class="comment">#FF3601                                         </span></span><br><span class="line">azkaban.default.servlet.path=/index  </span><br><span class="line"><span class="comment">#根web目录,配置绝对路径，即web的目录  </span></span><br><span class="line">web.resource.dir=/opt/module/azkaban/azkaban-web-2.5.0/web   </span><br><span class="line"><span class="comment">#默认时区,已改为亚洲/上海 默认为美国                                            </span></span><br><span class="line">default.timezone.id=Asia/Shanghai                           </span><br><span class="line"><span class="comment">#用户权限管理默认类  </span></span><br><span class="line">user.manager.class=azkaban.user.XmlUserManager    </span><br><span class="line"><span class="comment">#用户配置,配置绝对路径，即azkaban-users.xml的路径     </span></span><br><span class="line">user.manager.xml.file=/opt/module/azkaban/azkaban-web-2.5.0/conf/azkaban-users.xml             </span><br><span class="line"><span class="comment">#Loader for projects .global配置文件所在位置,即global.properties绝对路径    </span></span><br><span class="line">executor.global.properties=/opt/module/azkaban/azkaban-executor-2.5.0/conf/global.properties    </span><br><span class="line">azkaban.project.dir=projects                                                 </span><br><span class="line"><span class="comment">#数据库类型  </span></span><br><span class="line">database.type=mysql                                                            </span><br><span class="line">mysql.port=3306                                                                  </span><br><span class="line">mysql.host=cdh01                                                    </span><br><span class="line">mysql.database=azkaban                                                      </span><br><span class="line">mysql.user=root  </span><br><span class="line"><span class="comment">#数据库密码                                                               </span></span><br><span class="line">mysql.password=123qwe                                                     </span><br><span class="line">mysql.numconnections=100                                                </span><br><span class="line"><span class="comment"># Velocity dev mode   </span></span><br><span class="line">velocity.dev.mode=<span class="literal">false</span>  </span><br><span class="line"><span class="comment"># Jetty服务器属性.  </span></span><br><span class="line"><span class="comment">#最大线程数     </span></span><br><span class="line">jetty.maxThreads=25   </span><br><span class="line"><span class="comment">#Jetty SSL端口                                                                 </span></span><br><span class="line">jetty.ssl.port=8443  </span><br><span class="line"><span class="comment">#Jetty端口                                                                      </span></span><br><span class="line">jetty.port=8081    </span><br><span class="line"><span class="comment">#SSL文件名,即keystore绝对路径                                                                              </span></span><br><span class="line">jetty.keystore=/opt/module/azkaban/azkaban-web-2.5.0/keystore    </span><br><span class="line"><span class="comment">#SSL文件密码,本配置与keystore密码相同                                                           </span></span><br><span class="line">jetty.password=123qwe  </span><br><span class="line"><span class="comment">#Jetty主密码 与 keystore文件相同                                                          </span></span><br><span class="line">jetty.keypassword=123qwe  </span><br><span class="line"><span class="comment">#SSL文件名,即keystore绝对路径                                                            </span></span><br><span class="line">jetty.truststore=/opt/module/azkaban/azkaban-web-2.5.0/keystore    </span><br><span class="line"><span class="comment"># SSL文件密码                                                             </span></span><br><span class="line">jetty.trustpassword=123qwe                                                    </span><br><span class="line"><span class="comment"># 执行服务器属性, 执行服务器端口  </span></span><br><span class="line">executor.port=12321                                                                </span><br><span class="line"><span class="comment"># 邮件设置,发送邮箱    </span></span><br><span class="line">mail.sender=xxxxxxxx@163.com    </span><br><span class="line"><span class="comment">#发送邮箱smtp地址                                           </span></span><br><span class="line">mail.host=smtp.163.com     </span><br><span class="line"><span class="comment">#发送邮件时显示的名称                                                            </span></span><br><span class="line">mail.user=xxxxxxxx  </span><br><span class="line"><span class="comment">#邮箱密码                                            </span></span><br><span class="line">mail.password=**********   </span><br><span class="line"><span class="comment">#任务失败时发送邮件的地址                                                        </span></span><br><span class="line">job.failure.email=xxxxxxxx@163.com   </span><br><span class="line"><span class="comment">#任务成功时发送邮件的地址                                 </span></span><br><span class="line">job.success.email=xxxxxxxx@163.com                            </span><br><span class="line">lockdown.create.projects=<span class="literal">false</span>    </span><br><span class="line"><span class="comment">#缓存目录                                            </span></span><br><span class="line">cache.directory=cache</span><br></pre></td></tr></table></figure><p>(3)web服务器用户配置<br>在azkaban web服务器安装目录 conf目录，按照如下配置修改azkaban-users.xml 文件，增加管理员用户。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;azkaban-users&gt;  </span><br><span class="line">       &lt;user username=<span class="string">"azkaban"</span> password=<span class="string">"azkaban"</span> roles=<span class="string">"admin"</span> groups=<span class="string">"azkaban"</span> /&gt;    </span><br><span class="line">       &lt;user username=<span class="string">"metrics"</span> password=<span class="string">"metrics"</span> roles=<span class="string">"metrics"</span>/&gt;  </span><br><span class="line">       &lt;user username=<span class="string">"admin"</span> password=<span class="string">"admin"</span> roles=<span class="string">"admin,metrics"</span> /&gt;  </span><br><span class="line">       &lt;role name=<span class="string">"admin"</span> permissions=<span class="string">"ADMIN"</span> /&gt;  </span><br><span class="line">       &lt;role name=<span class="string">"metrics"</span> permissions=<span class="string">"METRICS"</span>/&gt;    </span><br><span class="line">&lt;/azkaban-users&gt;</span><br></pre></td></tr></table></figure><h2 id="executor服务器配置"><a href="#executor服务器配置" class="headerlink" title="executor服务器配置"></a>executor服务器配置</h2><p>(1)进入executor安装目录，修改azkaban.properties</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Azkaban  </span></span><br><span class="line">default.timezone.id=Asia/Shanghai  </span><br><span class="line"><span class="comment"># Azkaban JobTypes Plugins  </span></span><br><span class="line">azkaban.jobtype.plugin.dir=./../plugins/jobtypes  </span><br><span class="line"><span class="comment">#Loader for projects  </span></span><br><span class="line">executor.global.properties=/opt/module/azkaban/azkaban-executor-2.5.0/conf/global.properties  </span><br><span class="line">azkaban.project.dir=projects  </span><br><span class="line">database.type=mysql  </span><br><span class="line">mysql.port=3306  </span><br><span class="line">mysql.host=cdh01  </span><br><span class="line">mysql.database=azkaban  </span><br><span class="line">mysql.user=root  </span><br><span class="line">mysql.password=123qwe    </span><br><span class="line">mysql.numconnections=100    </span><br><span class="line"><span class="comment"># Azkaban Executor settings  </span></span><br><span class="line">executor.maxThreads=50  </span><br><span class="line">executor.port=12321  </span><br><span class="line">executor.flow.threads=30</span><br></pre></td></tr></table></figure><h1 id="启动web服务器"><a href="#启动web服务器" class="headerlink" title="启动web服务器"></a>启动web服务器</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@cdh02 azkaban-web-2.5.0]<span class="comment"># bin/azkaban-web-start.sh  &amp;</span></span><br></pre></td></tr></table></figure><h1 id="启动executor服务器"><a href="#启动executor服务器" class="headerlink" title="启动executor服务器"></a>启动executor服务器</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@cdh02 azkaban-executor-2.5.0]<span class="comment"># bin/azkaban-executor-start.sh  &amp;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Azkaban </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Azkaban </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink的数据类型</title>
      <link href="/2019/08/27/Flink%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"/>
      <url>/2019/08/27/Flink%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<p>Flink使用type information来代表数据类型，Flink还具有一个类型提取系统，该系统分析函数的输入和返回类型，以自动获取类型信息(type information)，从而获得序列化程序和反序列化程序。但是，在某些情况下，例如lambda函数或泛型类型，需要显式地提供类型信息((type information)),从而提高其性能。本文主要讨论包括：(1)Flink支持的数据类型,(2)如何为数据类型创建type information，（3）如果无法自动推断函数的返回类型，如何使用提示(hints)来帮助Flink的类型系统识别类型信息。</p><a id="more"></a><h2 id="支持的数据类型"><a href="#支持的数据类型" class="headerlink" title="支持的数据类型"></a>支持的数据类型</h2><p>Flink支持Java和Scala中所有常见的数据类型，使用比较广泛的类型主要包括以下五种：</p><ul><li>原始类型  </li><li>Java和Scala的tuple类型  </li><li>Scala样例类  </li><li>POJO类型  </li><li>一些特殊的类型  </li></ul><p><strong>NOTE：</strong>不能被处理的类型将会被视为普通的数据类型，通过Kyro序列化框架进行序列化。</p><h3 id="原始类型"><a href="#原始类型" class="headerlink" title="原始类型"></a>原始类型</h3><p>Flink支持所有Java和Scala的原始类型，比如Int(Java中的Integer)，String、Double等。下面的例子是处理一个Long类型的数据流，处理每个元素+1  </p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> numbers: <span class="type">DataStream</span>[<span class="type">Long</span>] = env.fromElements(<span class="number">1</span>L, <span class="number">2</span>L,<span class="number">3</span>L, <span class="number">4</span>L)  </span><br><span class="line">numbers.map( n =&gt; n + <span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="Java和Scala的tuple类型"><a href="#Java和Scala的tuple类型" class="headerlink" title="Java和Scala的tuple类型"></a>Java和Scala的tuple类型</h3><p>基于Scala的DataStream API使用的Scala的tuple。下面的例子是过滤一个具有两个字段的tuple类型的数据流.  </p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// DataStream of Tuple2[String, Integer] for Person(name,age)  </span></span><br><span class="line"><span class="keyword">val</span> persons: <span class="type">DataStream</span>[(<span class="type">String</span>, <span class="type">Integer</span>)] = env.fromElements((<span class="string">"Adam"</span>, <span class="number">17</span>),(<span class="string">"Sarah"</span>, <span class="number">23</span>))  </span><br><span class="line"><span class="comment">// filter for persons of age &gt; 18  </span></span><br><span class="line">persons.filter(p =&gt; p._2 &gt; <span class="number">18</span>)</span><br></pre></td></tr></table></figure><p>Flink提供了有效的Java tuple实现，Flink的Java tuple最多包括25个字段，分别为tuple1，tuple2，直到tuple25，tuple类型是强类型的。使用Java DataStream API重写上面的例子:</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// DataStream of Tuple2&lt;String, Integer&gt; for Person(name,age)  </span></span><br><span class="line">DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; persons =env.fromElements(Tuple2.of(<span class="string">"Adam"</span>, <span class="number">17</span>),Tuple2.of(<span class="string">"Sarah"</span>,<span class="number">23</span>));  </span><br><span class="line"><span class="comment">// filter for persons of age &gt; 18  </span></span><br><span class="line">persons.filter(p -&gt; p.f1 &gt; <span class="number">18</span>);</span><br></pre></td></tr></table></figure><p>Tuple字段可以通过使用f0，f1，f2的形式访问，也可以通过getField(int pos)方法访问，参数的索引起始值为0，比如:</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Tuple2&lt;String, Integer&gt; personTuple = Tuple2.of(<span class="string">"Alex"</span>,<span class="string">"42"</span>);  </span><br><span class="line">Integer age = personTuple.getField(<span class="number">1</span>); <span class="comment">// age = 42</span></span><br></pre></td></tr></table></figure><p>与Scala相比，Flink的Java tuple是可变的，所以tuple的元素值是可以被重新复制的。Function可以重用Java tuple,从而减小垃圾回收的压力。下面的例子展示了如何更新一个tuple字段值</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">personTuple.f1 = <span class="number">42</span>; <span class="comment">// set the 2nd field to 42     </span></span><br><span class="line">personTuple.setField(<span class="number">43</span>, <span class="number">1</span>); <span class="comment">// set the 2nd field to 43</span></span><br></pre></td></tr></table></figure><h3 id="Scala的样例类"><a href="#Scala的样例类" class="headerlink" title="Scala的样例类"></a>Scala的样例类</h3><p>Flink支持Scala的样例类，可以通过字段名称来访问样例类的字段，下面的例子定义了一个<code>Person</code>样例类，该样例类有两个字段：<code>name</code>和<code>age</code>,按<code>age</code>过滤DataStream，如下所示</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Int</span></span>)  </span></span><br><span class="line"><span class="class"><span class="title">val</span> <span class="title">persons</span></span>: <span class="type">DataStream</span>[<span class="type">Person</span>] = env.fromElements(<span class="type">Person</span>(<span class="string">"Adam"</span>, <span class="number">17</span>),<span class="type">Person</span>(<span class="string">"Sarah"</span>, <span class="number">23</span>))  </span><br><span class="line"><span class="comment">// filter for persons with age &gt; 18  </span></span><br><span class="line">persons.filter(p =&gt; p.age &gt; <span class="number">18</span>)</span><br></pre></td></tr></table></figure><h3 id="POJO"><a href="#POJO" class="headerlink" title="POJO"></a>POJO</h3><p>Flink接受的POJO类型需满足以下条件：</p><ul><li>public 类  </li><li>无参的共有构造方法  </li><li>所有字段都是public的，可以通过getter和setter方法访问  </li><li>所有字段类型必须是Flink能够支持的<br>下面的例子定义一个<code>Person</code>POJO</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;  </span><br><span class="line"><span class="comment">// both fields are public  </span></span><br><span class="line"><span class="keyword">public</span> String name;  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">int</span> age;  </span><br><span class="line"><span class="comment">// default constructor is present  </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">()</span> </span>&#123;&#125;  </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name, <span class="keyword">int</span> age)</span> </span>&#123;  </span><br><span class="line"><span class="keyword">this</span>.name = name;  </span><br><span class="line"><span class="keyword">this</span>.age = age;  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;  </span><br><span class="line">DataStream&lt;Person&gt; persons = env.fromElements(   </span><br><span class="line"><span class="keyword">new</span> Person(<span class="string">"Alex"</span>, <span class="number">42</span>),  </span><br><span class="line"><span class="keyword">new</span> Person(<span class="string">"Wendy"</span>, <span class="number">23</span>));</span><br></pre></td></tr></table></figure><h3 id="一些特殊的类型"><a href="#一些特殊的类型" class="headerlink" title="一些特殊的类型"></a>一些特殊的类型</h3><p>Flink支持一些有特殊作用的数据类型，比如Array，Java中的ArrayList、HashMap和Enum等，也支持Hadoop的Writable类型。  </p><h2 id="为数据类型创建类型信息-type-information"><a href="#为数据类型创建类型信息-type-information" class="headerlink" title="为数据类型创建类型信息(type information)"></a>为数据类型创建类型信息(type information)</h2><h2 id="显示地指定类型信息-type-information"><a href="#显示地指定类型信息-type-information" class="headerlink" title="显示地指定类型信息(type information)"></a>显示地指定类型信息(type information)</h2>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于SparkStreaming的日志分析项目</title>
      <link href="/2019/08/26/%E5%9F%BA%E4%BA%8ESparkStreaming%E7%9A%84%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E9%A1%B9%E7%9B%AE/"/>
      <url>/2019/08/26/%E5%9F%BA%E4%BA%8ESparkStreaming%E7%9A%84%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E9%A1%B9%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;基于SparkStreaming实现实时的日志分析，首先基于discuz搭建一个论坛平台，然后将该论坛的日志写入到指定文件，最后通过SparkStreaming实时对日志进行分析。</p><a id="more"></a><h1 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h1><ul><li>统计指定时间段的热门文章</li></ul><ul><li>统计指定时间段内的最受欢迎的用户（以 ip 为单位）</li></ul><ul><li>统计指定时间段内的不同模块的访问量  </li></ul><h1 id="项目架构"><a href="#项目架构" class="headerlink" title="项目架构"></a>项目架构</h1><p><img src="//jiamaoxiang.top/2019/08/26/基于SparkStreaming的日志分析项目/%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84.png" alt></p><h1 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h1><p>resources<br>&emsp;&emsp;&emsp;&emsp;access_log.txt:日志样例<br>&emsp;&emsp;&emsp;&emsp;log_sta.conf ：配置文件<br>scala.com.jmx.analysis<br>&emsp;&emsp;&emsp;&emsp;AccessLogParser.scala :日志解析<br>&emsp;&emsp;&emsp;&emsp;logAnalysis：日志分析<br>scala.com.jmx.util<br>&emsp;&emsp;&emsp;&emsp;Utility.scala:工具类<br>scala<br>&emsp;&emsp;&emsp;&emsp;Run：驱动程序(main)<br>具体代码详见<a href="https://github.com/jiamx/log_analysis" target="_blank" rel="noopener">github</a></p><h1 id="搭建discuz论坛"><a href="#搭建discuz论坛" class="headerlink" title="搭建discuz论坛"></a>搭建discuz论坛</h1><h2 id="安装XAMPP"><a href="#安装XAMPP" class="headerlink" title="安装XAMPP"></a>安装XAMPP</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p><code>wget https://www.apachefriends.org/xampp-files/5.6.33/xampp-linux-x64-5.6.33-0-installer.run</code></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p><code># 赋予文件执行权限</code><br><code>chmod u+x xampp-linux-x64-5.6.33-0-installer.run</code><br><code># 运行安装文件</code><br>`./xampp-linux-x64-5.6.33-0-installer.run``</p><h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><p>将以下内容加入到 ~/.bash_profile<br><code>export XAMPP=/opt/lampp/</code><br><code>export PATH=$PATH:$XAMPP:$XAMPP/bin</code>   </p><h3 id="刷新环境变量"><a href="#刷新环境变量" class="headerlink" title="刷新环境变量"></a>刷新环境变量</h3><p><code>source ~/.bash_profile</code></p><h3 id="启动XAMPP"><a href="#启动XAMPP" class="headerlink" title="启动XAMPP"></a>启动XAMPP</h3><p><code>xampp restart</code></p><h2 id="root用户密码和权限修改"><a href="#root用户密码和权限修改" class="headerlink" title="root用户密码和权限修改"></a>root用户密码和权限修改</h2><p><code>#修改root用户密码为123</code><br><code>update mysql.user set password=PASSWORD(&#39;123&#39;) where user=&#39;root&#39;;</code><br><code>flush privileges;</code><br><code>#赋予root用户远程登录权限</code><br><code>grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; identified by &#39;123&#39; with grant option;</code><br><code>flush privileges;</code>  </p><h2 id="安装Discuz"><a href="#安装Discuz" class="headerlink" title="安装Discuz"></a>安装Discuz</h2><h3 id="下载discuz"><a href="#下载discuz" class="headerlink" title="下载discuz"></a>下载discuz</h3><p><code>wget http://download.comsenz.com/DiscuzX/3.2/Discuz_X3.2_SC_UTF8.zip</code>  </p><h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><p><code>#删除原有的web应用</code><br><code>rm -rf /opt/lampp/htdocs/*</code><br><code>unzip Discuz_X3.2_SC_UTF8.zip –d /opt/lampp/htdocs/</code><br><code>cd /opt/lampp/htdocs/</code><br><code>mv upload/*</code><br><code>#修改目录权限</code><br><code>chmod 777 -R /opt/lampp/htdocs/config/</code><br><code>chmod 777 -R /opt/lampp/htdocs/data/</code><br><code>chmod 777 -R /opt/lampp/htdocs/uc_client/</code><br><code>chmod 777 -R /opt/lampp/htdocs/uc_server/</code>  </p><h2 id="Discuz基本操作"><a href="#Discuz基本操作" class="headerlink" title="Discuz基本操作"></a>Discuz基本操作</h2><h3 id="自定义版块"><a href="#自定义版块" class="headerlink" title="自定义版块"></a>自定义版块</h3><ul><li>进入discuz后台：<a href="http://slave1/admin.php" target="_blank" rel="noopener">http://slave1/admin.php</a>  </li><li>点击顶部的“论坛”菜单  </li><li>按照页面提示创建所需版本，可以创建父子版块  </li></ul><h3 id="查看访问日志"><a href="#查看访问日志" class="headerlink" title="查看访问日志"></a>查看访问日志</h3><p>日志默认地址<br><code>/opt/lampp/logs/access_log</code><br>实时查看日志命令<br><code>tail –f /opt/lampp/logs/access_log</code>  </p><h2 id="Discuz帖子-版块存储简介"><a href="#Discuz帖子-版块存储简介" class="headerlink" title="Discuz帖子/版块存储简介"></a>Discuz帖子/版块存储简介</h2><p><code>mysql -uroot -p123 ultrax # 登录ultrax数据库</code><br><code>查看包含帖子id及标题对应关系的表</code><br><code>#tid, subject（文章id、标题）</code><br><code>select tid, subject from pre_forum_post limit 10;</code><br><code>#fid, name（版块id、标题）</code><br><code>select fid, name from pre_forum_forum limit 40;</code>  </p><h2 id="修改日志格式"><a href="#修改日志格式" class="headerlink" title="修改日志格式"></a>修改日志格式</h2><h3 id="找到Apache配置文件"><a href="#找到Apache配置文件" class="headerlink" title="找到Apache配置文件"></a>找到Apache配置文件</h3><p>Apache配置文件名称为httpd.conf，所在目录为 /opt/lampp/etc/ ，完整路径为 /opt/lampp/etc/httpd.conf</p><h3 id="修改日志格式-1"><a href="#修改日志格式-1" class="headerlink" title="修改日志格式"></a>修改日志格式</h3><p>关闭通用日志文件的使用<br><code>CustomLog &quot;logs/access_log&quot; common</code><br>启用组合日志文件<br><code>CustomLog &quot;logs/access_log&quot; combined</code><br>重新加载配置文件<br><code>xampp reload</code><br>检查访问日志<br><code>tail -f /opt/lampp/logs/access_log</code>  </p><h3 id="Flume与Kafka配置"><a href="#Flume与Kafka配置" class="headerlink" title="Flume与Kafka配置"></a>Flume与Kafka配置</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#agent的名称为a1  </span><br><span class="line">a1.sources = source1  </span><br><span class="line">a1.channels = channel1  </span><br><span class="line">a1.sinks = sink1</span><br><span class="line">#set source</span><br><span class="line">a1.sources.source1.type = TAILDIR  </span><br><span class="line">a1.sources.source1.filegroups = f1  </span><br><span class="line">a1.sources.source1.filegroups.f1 = /opt/lampp/logs/access_log  </span><br><span class="line">a1sources.source1.fileHeader = flase  </span><br><span class="line">#set sink</span><br><span class="line">a1.sinks.sink1.type = org.apache.flume.sink.kafka.KafkaSink  </span><br><span class="line">a1.sinks.sink1.brokerList=kms-2.apache.com:9092,kms-3.apache.com:9092,kms-4.apache.com:9092    </span><br><span class="line">​a1.sinks.sink1.topic= discuzlog  </span><br><span class="line">​a1.sinks.sink1.kafka.flumeBatchSize = 20  </span><br><span class="line">​a1.sinks.sink1.kafka.producer.acks = 1  </span><br><span class="line">​a1.sinks.sink1.kafka.producer.linger.ms = 1  </span><br><span class="line">​a1.sinks.sink1.kafka.producer.compression.type = snappy  </span><br><span class="line">#set channel</span><br><span class="line">​a1.channels.channel1.type = file  </span><br><span class="line">​a1.channels.channel1.checkpointDir = /home/kms/data/flume_data/checkpoint  </span><br><span class="line">​a1.channels.channel1.dataDirs= /home/kms/data/flume_data/data  </span><br><span class="line">#bind</span><br><span class="line">​a1.sources.source1.channels = channel1  </span><br><span class="line">​a1.sinks.sink1.channel = channel1</span><br></pre></td></tr></table></figure><h2 id="创建MySQL数据库和所需要的表"><a href="#创建MySQL数据库和所需要的表" class="headerlink" title="创建MySQL数据库和所需要的表"></a>创建MySQL数据库和所需要的表</h2><p><strong>创建数据库</strong>  </p><p><code>CREATE DATABASE</code>statistics<code>CHARACTER SET &#39;utf8&#39; COLLATE &#39;utf8_general_ci&#39;;</code>  </p><p><strong>创建表:</strong><br>&emsp;&emsp;特定时间段内不同ip的访问次数：client_ip_access<br>CREATE TABLE client_ip_access (<br>&emsp;&emsp;&emsp;&emsp;client_ip text COMMENT ‘客户端ip’,<br>&emsp;&emsp;&emsp;&emsp;sum BIGINT ( 20 ) NOT NULL COMMENT ‘访问次数’,<br>&emsp;&emsp;&emsp;&emsp;time text NOT NULL COMMENT ‘统计时间’<br>) ENGINE = INNODB DEFAULT CHARSET = utf8;  </p><p>&emsp;&emsp;特定时间段内不同文章的访问次数：hot_article<br>CREATE TABLE hot_article (<br>&emsp;&emsp;&emsp;&emsp;article_id text COMMENT ‘文章id’,<br>&emsp;&emsp;&emsp;&emsp;subject text NOT NULL COMMENT ‘文章标题’,<br>&emsp;&emsp;&emsp;&emsp;sum BIGINT ( 20 ) NOT NULL COMMENT ‘访问次数’,<br>&emsp;&emsp;&emsp;&emsp;time text NOT NULL COMMENT ‘统计时间’<br>) ENGINE = INNODB DEFAULT CHARSET = utf8;  </p><p>&emsp;&emsp;特定时间段内不同版块的访问次数：hot_section<br>CREATE TABLE hot_section (<br>&emsp;&emsp;&emsp;&emsp;section_id text COMMENT ‘版块id’,<br>&emsp;&emsp;&emsp;&emsp;name text NOT NULL COMMENT ‘版块标题’,<br>&emsp;&emsp;&emsp;&emsp;sum BIGINT ( 20 ) NOT NULL COMMENT ‘访问次数’,<br>&emsp;&emsp;&emsp;&emsp;time text NOT NULL COMMENT ‘统计时间’<br>) ENGINE = INNODB DEFAULT CHARSET = utf8; </p><h2 id="打包部署存在的问题"><a href="#打包部署存在的问题" class="headerlink" title="打包部署存在的问题"></a>打包部署存在的问题</h2><p><strong>问题1</strong> </p><pre><code>Exception in thread &quot;main&quot; java.lang.SecurityException: Invalid signature file digest for Manifest main attributes</code></pre><p><strong>解决方式</strong>  </p><p>原因:使用sbt打包的时候导致某些包的重复引用，所以打包之后的META-INF的目录下多出了一些<em>.SF,</em>.DSA,*.RSA文件  </p><p>解决办法：删除掉多于的<em>.SF,</em>.DSA,*.RSA文件  </p><p><code>zip -d log_analysis-1.0-SNAPSHOT.jar META-INF/*.RSA META-INF/*.DSA META-INF/*.SF</code>  </p><p><strong>问题2</strong>    </p><pre><code>Exception in thread &quot;main&quot; java.io.FileNotFoundException: File file:/data/spark_data/history/event-log does not exist</code></pre><p><strong>解决方式</strong>  </p><p>原因:由于spark的spark-defaults.conf配置文件中配置 eventLog 时指定的路径在本机不存在。  </p><p>解决办法：创建对应的文件夹，并赋予对应权限<br><code>sudo mkdir -p /data/spark_data/history/spark-events</code><br><code>sudo mkdir -p /data/spark_data/history/event-log</code><br><code>sudo chmod 777 -R /data</code>  </p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>首先，基于discuz搭建了论坛，针对论坛产生的日志，对其进行分析。主要的处理流程为log—&gt;flume—&gt;kafka—&gt;sparkstreaming—&gt;MySQL,最后将处理的结果写入MySQL共报表查询。</p>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink的状态后端(State Backends)</title>
      <link href="/2019/08/23/Flink%E7%9A%84%E7%8A%B6%E6%80%81%E5%90%8E%E7%AB%AF-State-Backends/"/>
      <url>/2019/08/23/Flink%E7%9A%84%E7%8A%B6%E6%80%81%E5%90%8E%E7%AB%AF-State-Backends/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;当使用checkpoint时，状态(state)会被持久化到checkpoint上，以防止数据的丢失并确保发生故障时能够完全恢复。状态是通过什么方式在哪里持久化，取决于使用的状态后端。</p><a id="more"></a><h2 id="可用的状态后端"><a href="#可用的状态后端" class="headerlink" title="可用的状态后端"></a>可用的状态后端</h2><p><strong>MemoryStateBackend</strong><br><strong>FsStateBackend</strong><br><strong>FsStateBackend</strong>  </p><p>注意：如果什么都不配置，系统默认的是MemoryStateBackend</p><h2 id="MemoryStateBackend"><a href="#MemoryStateBackend" class="headerlink" title="MemoryStateBackend"></a>MemoryStateBackend</h2><p><img src="//jiamaoxiang.top/2019/08/23/Flink的状态后端-State-Backends/memorystatebackend.png" alt><br>&emsp;&emsp;<code>MemoryStateBackend</code> 是将状态维护在 Java 堆上的一个内部状态后端。键值状态和窗口算子使用哈希表来存储数据（values）和定时器（timers）。当应用程序 checkpoint 时，此后端会在将状态发给 JobManager 之前快照下状态，JobManager 也将状态存储在 Java 堆上。默认情况下，<code>MemoryStateBackend</code> 配置成支持异步快照。异步快照可以避免阻塞数据流的处理，从而避免反压的发生。当然，使用 <code>new MemoryStateBackend(MAX_MEM_STATE_SIZE, false)</code>也可以禁用该特点。</p><p><strong>缺点</strong>：</p><ul><li>默认情况下，每一个状态的大小限制为 5 MB。可以通过 <code>MemoryStateBackend</code> 的构造函数增加这个大小。状态大小受到 akka 帧大小的限制(maxStateSize &lt;= akka.framesize 默认 10 M)，所以无论怎么调整状态大小配置，都不能大于 akka 的帧大小。也可以通过 akka.framesize 调整 akka 帧大小。</li><li>状态的总大小不能超过 JobManager 的内存。</li></ul><p><strong>推荐使用的场景</strong>：</p><ul><li>本地测试、几乎无状态的作业，比如 ETL、JobManager 不容易挂，或挂掉影响不大的情况。</li><li>不推荐在生产场景使用。</li></ul><h2 id="FsStateBackend"><a href="#FsStateBackend" class="headerlink" title="FsStateBackend"></a>FsStateBackend</h2><p><img src="//jiamaoxiang.top/2019/08/23/Flink的状态后端-State-Backends/fsstatebackend.png" alt><br>&emsp;&emsp;<code>FsStateBackend</code>需要配置的主要是文件系统，如 URL（类型，地址，路径）。比如可以是：<br><code>“hdfs://namenode:40010/flink/checkpoints”</code> 或<code>“s3://flink/checkpoints”</code></p><p>&emsp;&emsp;当选择使用 <code>FsStateBackend</code>时，正在进行的数据会被存在TaskManager的内存中。在checkpoint时，此后端会将状态快照写入配置的文件系统和目录的文件中，同时会在JobManager的内存中（在高可用场景下会存在 Zookeeper 中）存储极少的元数据。容量限制上，单 TaskManager 上 State 总量不超过它的内存，总大小不超过配置的文件系统容量。</p><p>&emsp;&emsp;默认情况下，<code>FsStateBackend</code> 配置成提供异步快照，以避免在状态 checkpoint 时阻塞数据流的处理。该特性可以实例化 <code>FsStateBackend</code> 时传入false的布尔标志来禁用掉，例如：<code>new FsStateBackend(path, false)</code></p><p><strong>推荐使用的场景</strong>：</p><ul><li>处理大状态，长窗口，或大键值状态的有状态处理任务， 例如分钟级窗口聚合或 join。</li><li>适合用于高可用方案（需要开启HA的作业）。</li><li>可以在生产环境中使用</li></ul><h2 id="RocksDBStateBackend"><a href="#RocksDBStateBackend" class="headerlink" title="RocksDBStateBackend"></a>RocksDBStateBackend</h2><p><img src="//jiamaoxiang.top/2019/08/23/Flink的状态后端-State-Backends/rocksdbstatebackend.png" alt><br>&emsp;&emsp;<code>RocksDBStateBackend</code> 的配置也需要一个文件系统（类型，地址，路径），如下所示：<br>“hdfs://namenode:40010/flink/checkpoints” 或“s3://flink/checkpoints”<br>RocksDB 是一种嵌入式的本地数据库。RocksDBStateBackend 将处理中的数据使用 <a href="https://rocksdb.org/" target="_blank" rel="noopener">RocksDB</a> 存储在本地磁盘上。在 checkpoint 时，整个 RocksDB 数据库会被存储到配置的文件系统中，或者在超大状态作业时可以将增量的数据存储到配置的文件系统中。同时 Flink 会将极少的元数据存储在 JobManager 的内存中，或者在 Zookeeper 中（对于高可用的情况）。<a href="https://rocksdb.org/" target="_blank" rel="noopener">RocksDB</a> 默认也是配置成异步快照的模式。</p><p>&emsp;&emsp;<a href="https://rocksdb.org/" target="_blank" rel="noopener">RocksDB</a>是一个 key/value 的内存存储系统，和其他的 key/value 一样，先将状态放到内存中，如果内存快满时，则写入到磁盘中，但需要注意<a href="https://rocksdb.org/" target="_blank" rel="noopener">RocksDB</a>不支持同步的 Checkpoint，构造方法中没有同步快照这个选项。不过<a href="https://rocksdb.org/" target="_blank" rel="noopener">RocksDB</a>支持增量的 Checkpoint，也是目前唯一增量 Checkpoint 的 Backend，意味着并不需要把所有 sst 文件上传到 Checkpoint 目录，仅需要上传新生成的 sst 文件即可。它的 Checkpoint 存储在外部文件系统（本地或HDFS），其容量限制只要单个 TaskManager 上 State 总量不超过它的内存+磁盘，单Key最大2G，总大小不超过配置的文件系统容量即可。</p><p><strong>缺点</strong>：</p><ul><li><a href="https://rocksdb.org/" target="_blank" rel="noopener">RocksDB</a>支持的单key和单value的大小最大为每个 2^31 字节。这是因为 RocksDB 的 JNI API 是基于byte[]的。<br></li><li>对于使用具有合并操作的状态的应用程序，例如 ListState，随着时间可能会累积到超过 2^31 字节大小，这将会导致在接下来的查询中失败。</li></ul><p><strong>推荐使用的场景</strong>：</p><ul><li>最适合用于处理大状态，长窗口，或大键值状态的有状态处理任务。</li><li>非常适合用于高可用方案。</li><li>最好是对状态读写性能要求不高的作业</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>&emsp;&emsp;那如何选择状态的类型和存储方式？结合前面的内容，可以看到，首先是要分析清楚业务场景；比如想要做什么，状态到底大不大。比较各个方案的利弊，选择根据需求合适的状态类型和存储方式即可。</p><hr><p><strong>Reference</strong></p><p>[1]<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.8/ops/state/state_backends.html" target="_blank" rel="noopener">https://ci.apache.org/projects/flink/flink-docs-release-1.8/ops/state/state_backends.html</a><br>[2]<a href="https://ververica.cn/developers/state-management/" target="_blank" rel="noopener">https://ververica.cn/developers/state-management/</a><br>[3]<a href="https://www.ververica.com/blog/stateful-stream-processing-apache-flink-state-backends" target="_blank" rel="noopener">https://www.ververica.com/blog/stateful-stream-processing-apache-flink-state-backends</a></p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程之--运维与监控(七)</title>
      <link href="/2019/08/19/%E8%BF%90%E7%BB%B4%E4%B8%8E%E7%9B%91%E6%8E%A7/"/>
      <url>/2019/08/19/%E8%BF%90%E7%BB%B4%E4%B8%8E%E7%9B%91%E6%8E%A7/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程之--集群与部署(六)</title>
      <link href="/2019/08/19/%E9%9B%86%E7%BE%A4%E4%B8%8E%E9%83%A8%E7%BD%B2/"/>
      <url>/2019/08/19/%E9%9B%86%E7%BE%A4%E4%B8%8E%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程之--source/sink Connectors(五)</title>
      <link href="/2019/08/19/source-sink-Connectors/"/>
      <url>/2019/08/19/source-sink-Connectors/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程之--状态与容错（四）</title>
      <link href="/2019/08/19/%E7%8A%B6%E6%80%81%E4%B8%8E%E5%AE%B9%E9%94%99/"/>
      <url>/2019/08/19/%E7%8A%B6%E6%80%81%E4%B8%8E%E5%AE%B9%E9%94%99/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程之--基于时间的算子(三)</title>
      <link href="/2019/08/19/%E5%9F%BA%E4%BA%8E%E6%97%B6%E9%97%B4%E7%9A%84%E7%AE%97%E5%AD%90/"/>
      <url>/2019/08/19/%E5%9F%BA%E4%BA%8E%E6%97%B6%E9%97%B4%E7%9A%84%E7%AE%97%E5%AD%90/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程之--DataStream-API简介(二)</title>
      <link href="/2019/08/19/DataStream-API%E7%AE%80%E4%BB%8B/"/>
      <url>/2019/08/19/DataStream-API%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程之--Flink的几个重要概念(一)</title>
      <link href="/2019/08/19/Flink%E7%9A%84%E5%87%A0%E4%B8%AA%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5/"/>
      <url>/2019/08/19/Flink%E7%9A%84%E5%87%A0%E4%B8%AA%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p><h3 id="Event-time"><a href="#Event-time" class="headerlink" title="Event-time"></a>Event-time</h3><p>处理时间(process time)很好理解，指的是机器的本地时间，会产生不一致的、不可重复的结果。相反，事件时间(Event-time)能够产生一致的、可重复的结果。然而，相比基于处理时间的应用，基于事件时间的应用需要额外的配置。支持事件时间的流处理引擎的内部比仅仅支持处理时间的流处理引擎的内部更为复杂。</p><p>Flink不仅为常见的事件时间提供直观且易于使用的处理操作，而且也提供了API去自定义实现更高级的事件时间。 对于这样的高级应用，很好的理解Flink的内部时间处理通常是很有帮助的。Flink主要利用两个概念提供事件时间语义：记录时间戳(record timestamps)和watermarks。 接下来，我们将描述Flink内部如何实现和处理时间戳及watermark以支持流应用程序具有事件时间语义的。</p><h4 id="时间戳-timestamps"><a href="#时间戳-timestamps" class="headerlink" title="时间戳(timestamps)"></a>时间戳(timestamps)</h4><p>对于使用事件时间的应用，所处理的记录(record)必须携带时间戳。时间戳将记录与特定时间点相关联，代表事件发生的时间。当Flink以事件时间模式处理数据流时，比如窗口操作，内部会自动的按时间戳将事件发送到相对应的窗口。 Flink会将时间戳编码为16个字节的Long类型的值，并将它们作为元数据附加到记录中。Flink内置的算子会将Long型的值解析为精确到毫秒的Unix时间戳， 但是，自定义算子可以有自己的解析策略，例如，将精度调整为微秒。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅析数据库缓冲池与SQL查询成本</title>
      <link href="/2019/08/14/%E6%B5%85%E6%9E%90%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BC%93%E5%86%B2%E6%B1%A0%E4%B8%8ESQL%E6%9F%A5%E8%AF%A2%E6%88%90%E6%9C%AC/"/>
      <url>/2019/08/14/%E6%B5%85%E6%9E%90%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BC%93%E5%86%B2%E6%B1%A0%E4%B8%8ESQL%E6%9F%A5%E8%AF%A2%E6%88%90%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<p><img src="//jiamaoxiang.top/2019/08/14/浅析数据库缓冲池与SQL查询成本/background.jpg" alt><br>&emsp;&emsp;如果我们想要查找多行记录，查询时间是否会成倍地提升呢？其实数据库会采用缓冲池的方式提升页(page)的查找效率。数据库的缓冲池在数据库中起到了怎样的作用？如何查看一条 SQL 语句需要在缓冲池中进行加载的页的数量呢？</p><hr><h2 id="数据库缓冲池"><a href="#数据库缓冲池" class="headerlink" title="数据库缓冲池"></a>数据库缓冲池</h2><p>​        &emsp;&emsp;磁盘 I/O 需要消耗的时间很多，而在内存中进行操作，效率则会高很多，为了能让数据表或者索引中的数据随时被我们所用，DBMS 会申请占用内存来作为数据缓冲池，这样做的好处是可以让磁盘活动最小化，从而减少与磁盘直接进行 I/O 的时间。要知道，这种策略对提升 SQL 语句的查询性能来说至关重要。如果索引的数据在缓冲池里，那么访问的成本就会降低很多。<br>​       &emsp;&emsp;那么缓冲池如何读取数据呢？<br>​        &emsp;&emsp;缓冲池管理器会尽量将经常使用的数据保存起来，在数据库进行页面读操作的时候，首先会判断该页面是否在缓冲池中，如果存在就直接读取，如果不存在，就会通过内存或磁盘将页面存放到缓冲池中再进行读取。</p><h2 id="查看缓冲池大小"><a href="#查看缓冲池大小" class="headerlink" title="查看缓冲池大小"></a>查看缓冲池大小</h2><p>​         &emsp;&emsp;如果使用的是 MyISAM 存储引擎(只缓存索引，不缓存数据)，对应的键缓存参数为 key_buffer_size，可以用它进行查看。<br>​        &emsp;&emsp;如果使用的是 InnoDB 存储引擎，可以通过查看 innodb_buffer_pool_size 变量来查看缓冲池的大小，命令如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql&gt; show variables like <span class="string">'innodb_buffer_pool_size'</span>;</span><br></pre></td></tr></table></figure><p><img src="//jiamaoxiang.top/2019/08/14/浅析数据库缓冲池与SQL查询成本/query_innodb_buffer_size.png" alt><br>​        &emsp;&emsp;此时 InnoDB 的缓冲池大小只有 8388608/1024/1024=8MB，我们可以修改缓冲池大小为 128MB，方法如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql&gt; <span class="built_in">set</span> global innodb_buffer_pool_size = 1073741824;</span><br></pre></td></tr></table></figure><p>​      &emsp;&emsp; 在 InnoDB 存储引擎中，可以同时开启多个缓冲池，查看缓冲池的个数，使用命令：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql&gt; show variables like <span class="string">'innodb_buffer_pool_instances'</span>;</span><br></pre></td></tr></table></figure><p><img src="//jiamaoxiang.top/2019/08/14/浅析数据库缓冲池与SQL查询成本/innodb_buffer_pool_instance.png" alt><br>​        &emsp;&emsp;只有一个缓冲池。实际上innodb_buffer_pool_instances默认情况下为 8，为什么只显示只有一个呢？这里需要说明的是，如果想要开启多个缓冲池，你首先需要将innodb_buffer_pool_size参数设置为大于等于 1GB，这时innodb_buffer_pool_instances才会大于 1。你可以在 MySQL 的配置文件中对innodb_buffer_pool_size进行设置，大于等于 1GB，然后再针对innodb_buffer_pool_instances参数进行修改。</p><h2 id="查看SQL语句的查询成本"><a href="#查看SQL语句的查询成本" class="headerlink" title="查看SQL语句的查询成本"></a>查看SQL语句的查询成本</h2><p>​        &emsp;&emsp; 一条 SQL 查询语句在执行前需要确定查询计划，如果存在多种查询计划的话，MySQL 会计算每个查询计划所需要的成本，从中选择成本最小的一个作为最终执行的查询计划。</p><p>​          &emsp;&emsp;如果查看某条 SQL 语句的查询成本，可以在执行完这条 SQL 语句之后，通过查看当前会话中的 last_query_cost 变量值来得到当前查询的成本。这个查询成本对应的是 SQL 语句所需要读取的页(page)的数量。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql&gt; show status like <span class="string">'last_query_cost'</span></span><br></pre></td></tr></table></figure><p><strong>example</strong>  </p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql&gt; select userid,rating from movierating <span class="built_in">where</span> userid = 4169;</span><br></pre></td></tr></table></figure><p>结果：2313 rows in set (0.05 sec) </p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql&gt; show status like <span class="string">'last_query_cost'</span>;</span><br></pre></td></tr></table></figure><p><img src="//jiamaoxiang.top/2019/08/14/浅析数据库缓冲池与SQL查询成本/test1.png" alt></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql&gt; select userid,rating from movierating <span class="built_in">where</span> userid between 4168 and 4175;</span><br></pre></td></tr></table></figure><p>结果：2643 rows in set (0.01 sec) </p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql&gt; show status like <span class="string">'last_query_cost'</span>;</span><br></pre></td></tr></table></figure><p><img src="//jiamaoxiang.top/2019/08/14/浅析数据库缓冲池与SQL查询成本/test2.png" alt></p><p>&emsp;&emsp;你能看到页的数量是刚才的 1.4 倍，但是查询的效率并没有明显的变化，实际上这两个 SQL 查询的时间基本上一样，就是因为采用了顺序读取的方式将页面一次性加载到缓冲池中，然后再进行查找。虽然页数量（last_query_cost）增加了不少，但是通过缓冲池的机制，并没有增加多少查询时间。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程</title>
      <link href="/2019/08/13/Flink%E8%87%AA%E5%AD%A6%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B/"/>
      <url>/2019/08/13/Flink%E8%87%AA%E5%AD%A6%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p><img src="//jiamaoxiang.top/2019/08/13/Flink自学系列教程/logo.png" alt><br>&emsp;&emsp;Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p><hr><h4 id="1-Flink的几个重要概念"><a href="#1-Flink的几个重要概念" class="headerlink" title="1.Flink的几个重要概念"></a><a href="https://jiamaoxiang.top/2019/08/19/Flink%E7%9A%84%E5%87%A0%E4%B8%AA%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5/">1.Flink的几个重要概念</a></h4><h4 id="2-DataFrame-API"><a href="#2-DataFrame-API" class="headerlink" title="2. DataFrame API"></a><a href="https://jiamaoxiang.top/2019/08/19/DataFrame-API/">2. DataFrame API</a></h4><h4 id="3-基于时间的算子"><a href="#3-基于时间的算子" class="headerlink" title="3. 基于时间的算子"></a><a href="https://jiamaoxiang.top/2019/08/19/%E5%9F%BA%E4%BA%8E%E6%97%B6%E9%97%B4%E7%9A%84%E7%AE%97%E5%AD%90/">3. 基于时间的算子</a></h4><h4 id="4-状态与容错"><a href="#4-状态与容错" class="headerlink" title="4. 状态与容错"></a><a href="https://jiamaoxiang.top/2019/08/19/%E7%8A%B6%E6%80%81%E4%B8%8E%E5%AE%B9%E9%94%99/">4. 状态与容错</a></h4><h4 id="5-source-sink-Connectors"><a href="#5-source-sink-Connectors" class="headerlink" title="5. source/sink Connectors"></a><a href="https://jiamaoxiang.top/2019/08/19/source-sink-Connectors/">5. source/sink Connectors</a></h4><h4 id="6-集群与部署"><a href="#6-集群与部署" class="headerlink" title="6. 集群与部署"></a><a href="https://jiamaoxiang.top/2019/08/19/%E9%9B%86%E7%BE%A4%E4%B8%8E%E9%83%A8%E7%BD%B2/">6. 集群与部署</a></h4><h4 id="7-运维与监控"><a href="#7-运维与监控" class="headerlink" title="7.运维与监控"></a><a href="https://jiamaoxiang.top/2019/08/19/%E8%BF%90%E7%BB%B4%E4%B8%8E%E7%9B%91%E6%8E%A7/">7.运维与监控</a></h4>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/08/12/hello-world/"/>
      <url>/2019/08/12/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p><p><img src="//jiamaoxiang.top/2019/08/12/hello-world/logo.png" alt></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
