<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>基于SparkStreaming的日志分析项目</title>
      <link href="/2019/08/26/%E5%9F%BA%E4%BA%8ESparkStreaming%E7%9A%84%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E9%A1%B9%E7%9B%AE/"/>
      <url>/2019/08/26/%E5%9F%BA%E4%BA%8ESparkStreaming%E7%9A%84%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E9%A1%B9%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;基于SparkStreaming实现实时的日志分析，首先基于discuz搭建一个论坛平台，然后将该论坛的日志写入到指定文件，最后通过SparkStreaming实时对日志进行分析。</p><a id="more"></a><h1 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h1><ul><li>统计指定时间段的热门文章</li></ul><ul><li>统计指定时间段内的最受欢迎的用户（以 ip 为单位）</li></ul><ul><li>统计指定时间段内的不同模块的访问量  </li></ul><h1 id="项目架构"><a href="#项目架构" class="headerlink" title="项目架构"></a>项目架构</h1><p><img src="//jiamaoxiang.top/2019/08/26/基于SparkStreaming的日志分析项目/%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84.png" alt></p><h1 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h1><p>resources<br>&emsp;&emsp;&emsp;&emsp;access_log.txt:日志样例<br>&emsp;&emsp;&emsp;&emsp;log_sta.conf ：配置文件<br>scala.com.jmx.analysis<br>&emsp;&emsp;&emsp;&emsp;AccessLogParser.scala :日志解析<br>&emsp;&emsp;&emsp;&emsp;logAnalysis：日志分析<br>scala.com.jmx.util<br>&emsp;&emsp;&emsp;&emsp;Utility.scala:工具类<br>scala<br>&emsp;&emsp;&emsp;&emsp;Run：驱动程序(main)<br>具体代码详见<a href="https://github.com/jiamx/log_analysis" target="_blank" rel="noopener">github</a></p>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink的状态后端(State Backends)</title>
      <link href="/2019/08/23/Flink%E7%9A%84%E7%8A%B6%E6%80%81%E5%90%8E%E7%AB%AF-State-Backends/"/>
      <url>/2019/08/23/Flink%E7%9A%84%E7%8A%B6%E6%80%81%E5%90%8E%E7%AB%AF-State-Backends/</url>
      
        <content type="html"><![CDATA[<p>&emsp;&emsp;当使用checkpoint时，状态(state)会被持久化到checkpoint上，以防止数据的丢失并确保发生故障时能够完全恢复。状态是通过什么方式在哪里持久化，取决于使用的状态后端。</p><a id="more"></a><h2 id="可用的状态后端"><a href="#可用的状态后端" class="headerlink" title="可用的状态后端"></a>可用的状态后端</h2><p><strong>MemoryStateBackend</strong><br><strong>FsStateBackend</strong><br><strong>FsStateBackend</strong>  </p><p>注意：如果什么都不配置，系统默认的是MemoryStateBackend</p><h2 id="MemoryStateBackend"><a href="#MemoryStateBackend" class="headerlink" title="MemoryStateBackend"></a>MemoryStateBackend</h2><p><img src="//jiamaoxiang.top/2019/08/23/Flink的状态后端-State-Backends/memorystatebackend.png" alt><br>&emsp;&emsp;<code>MemoryStateBackend</code> 是将状态维护在 Java 堆上的一个内部状态后端。键值状态和窗口算子使用哈希表来存储数据（values）和定时器（timers）。当应用程序 checkpoint 时，此后端会在将状态发给 JobManager 之前快照下状态，JobManager 也将状态存储在 Java 堆上。默认情况下，<code>MemoryStateBackend</code> 配置成支持异步快照。异步快照可以避免阻塞数据流的处理，从而避免反压的发生。当然，使用 <code>new MemoryStateBackend(MAX_MEM_STATE_SIZE, false)</code>也可以禁用该特点。</p><p><strong>缺点</strong>：</p><ul><li>默认情况下，每一个状态的大小限制为 5 MB。可以通过 <code>MemoryStateBackend</code> 的构造函数增加这个大小。状态大小受到 akka 帧大小的限制(maxStateSize &lt;= akka.framesize 默认 10 M)，所以无论怎么调整状态大小配置，都不能大于 akka 的帧大小。也可以通过 akka.framesize 调整 akka 帧大小。</li><li>状态的总大小不能超过 JobManager 的内存。</li></ul><p><strong>推荐使用的场景</strong>：</p><ul><li>本地测试、几乎无状态的作业，比如 ETL、JobManager 不容易挂，或挂掉影响不大的情况。</li><li>不推荐在生产场景使用。</li></ul><h2 id="FsStateBackend"><a href="#FsStateBackend" class="headerlink" title="FsStateBackend"></a>FsStateBackend</h2><p><img src="//jiamaoxiang.top/2019/08/23/Flink的状态后端-State-Backends/fsstatebackend.png" alt><br>&emsp;&emsp;<code>FsStateBackend</code>需要配置的主要是文件系统，如 URL（类型，地址，路径）。比如可以是：<br><code>“hdfs://namenode:40010/flink/checkpoints”</code> 或<code>“s3://flink/checkpoints”</code></p><p>&emsp;&emsp;当选择使用 <code>FsStateBackend</code>时，正在进行的数据会被存在TaskManager的内存中。在checkpoint时，此后端会将状态快照写入配置的文件系统和目录的文件中，同时会在JobManager的内存中（在高可用场景下会存在 Zookeeper 中）存储极少的元数据。容量限制上，单 TaskManager 上 State 总量不超过它的内存，总大小不超过配置的文件系统容量。</p><p>&emsp;&emsp;默认情况下，<code>FsStateBackend</code> 配置成提供异步快照，以避免在状态 checkpoint 时阻塞数据流的处理。该特性可以实例化 <code>FsStateBackend</code> 时传入false的布尔标志来禁用掉，例如：<code>new FsStateBackend(path, false)</code></p><p><strong>推荐使用的场景</strong>：</p><ul><li>处理大状态，长窗口，或大键值状态的有状态处理任务， 例如分钟级窗口聚合或 join。</li><li>适合用于高可用方案（需要开启HA的作业）。</li><li>可以在生产环境中使用</li></ul><h2 id="RocksDBStateBackend"><a href="#RocksDBStateBackend" class="headerlink" title="RocksDBStateBackend"></a>RocksDBStateBackend</h2><p><img src="//jiamaoxiang.top/2019/08/23/Flink的状态后端-State-Backends/rocksdbstatebackend.png" alt><br>&emsp;&emsp;<code>RocksDBStateBackend</code> 的配置也需要一个文件系统（类型，地址，路径），如下所示：<br>“hdfs://namenode:40010/flink/checkpoints” 或“s3://flink/checkpoints”<br>RocksDB 是一种嵌入式的本地数据库。RocksDBStateBackend 将处理中的数据使用 <a href="https://rocksdb.org/" target="_blank" rel="noopener">RocksDB</a> 存储在本地磁盘上。在 checkpoint 时，整个 RocksDB 数据库会被存储到配置的文件系统中，或者在超大状态作业时可以将增量的数据存储到配置的文件系统中。同时 Flink 会将极少的元数据存储在 JobManager 的内存中，或者在 Zookeeper 中（对于高可用的情况）。<a href="https://rocksdb.org/" target="_blank" rel="noopener">RocksDB</a> 默认也是配置成异步快照的模式。</p><p>&emsp;&emsp;<a href="https://rocksdb.org/" target="_blank" rel="noopener">RocksDB</a>是一个 key/value 的内存存储系统，和其他的 key/value 一样，先将状态放到内存中，如果内存快满时，则写入到磁盘中，但需要注意<a href="https://rocksdb.org/" target="_blank" rel="noopener">RocksDB</a>不支持同步的 Checkpoint，构造方法中没有同步快照这个选项。不过<a href="https://rocksdb.org/" target="_blank" rel="noopener">RocksDB</a>支持增量的 Checkpoint，也是目前唯一增量 Checkpoint 的 Backend，意味着并不需要把所有 sst 文件上传到 Checkpoint 目录，仅需要上传新生成的 sst 文件即可。它的 Checkpoint 存储在外部文件系统（本地或HDFS），其容量限制只要单个 TaskManager 上 State 总量不超过它的内存+磁盘，单Key最大2G，总大小不超过配置的文件系统容量即可。</p><p><strong>缺点</strong>：</p><ul><li><a href="https://rocksdb.org/" target="_blank" rel="noopener">RocksDB</a>支持的单key和单value的大小最大为每个 2^31 字节。这是因为 RocksDB 的 JNI API 是基于byte[]的。<br></li><li>对于使用具有合并操作的状态的应用程序，例如 ListState，随着时间可能会累积到超过 2^31 字节大小，这将会导致在接下来的查询中失败。</li></ul><p><strong>推荐使用的场景</strong>：</p><ul><li>最适合用于处理大状态，长窗口，或大键值状态的有状态处理任务。</li><li>非常适合用于高可用方案。</li><li>最好是对状态读写性能要求不高的作业</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>&emsp;&emsp;那如何选择状态的类型和存储方式？结合前面的内容，可以看到，首先是要分析清楚业务场景；比如想要做什么，状态到底大不大。比较各个方案的利弊，选择根据需求合适的状态类型和存储方式即可。</p><hr><p><strong>Reference</strong></p><p>[1]<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.8/ops/state/state_backends.html" target="_blank" rel="noopener">https://ci.apache.org/projects/flink/flink-docs-release-1.8/ops/state/state_backends.html</a><br>[2]<a href="https://ververica.cn/developers/state-management/" target="_blank" rel="noopener">https://ververica.cn/developers/state-management/</a><br>[3]<a href="https://www.ververica.com/blog/stateful-stream-processing-apache-flink-state-backends" target="_blank" rel="noopener">https://www.ververica.com/blog/stateful-stream-processing-apache-flink-state-backends</a></p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程之--运维与监控(七)</title>
      <link href="/2019/08/19/%E8%BF%90%E7%BB%B4%E4%B8%8E%E7%9B%91%E6%8E%A7/"/>
      <url>/2019/08/19/%E8%BF%90%E7%BB%B4%E4%B8%8E%E7%9B%91%E6%8E%A7/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程之--集群与部署(六)</title>
      <link href="/2019/08/19/%E9%9B%86%E7%BE%A4%E4%B8%8E%E9%83%A8%E7%BD%B2/"/>
      <url>/2019/08/19/%E9%9B%86%E7%BE%A4%E4%B8%8E%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程之--source/sink Connectors(五)</title>
      <link href="/2019/08/19/source-sink-Connectors/"/>
      <url>/2019/08/19/source-sink-Connectors/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程之--状态与容错（四）</title>
      <link href="/2019/08/19/%E7%8A%B6%E6%80%81%E4%B8%8E%E5%AE%B9%E9%94%99/"/>
      <url>/2019/08/19/%E7%8A%B6%E6%80%81%E4%B8%8E%E5%AE%B9%E9%94%99/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程之--基于时间的算子(三)</title>
      <link href="/2019/08/19/%E5%9F%BA%E4%BA%8E%E6%97%B6%E9%97%B4%E7%9A%84%E7%AE%97%E5%AD%90/"/>
      <url>/2019/08/19/%E5%9F%BA%E4%BA%8E%E6%97%B6%E9%97%B4%E7%9A%84%E7%AE%97%E5%AD%90/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程之--DataStream-API简介(二)</title>
      <link href="/2019/08/19/DataStream-API%E7%AE%80%E4%BB%8B/"/>
      <url>/2019/08/19/DataStream-API%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程之--Flink的几个重要概念(一)</title>
      <link href="/2019/08/19/Flink%E7%9A%84%E5%87%A0%E4%B8%AA%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5/"/>
      <url>/2019/08/19/Flink%E7%9A%84%E5%87%A0%E4%B8%AA%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<p>Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p><h3 id="Event-time"><a href="#Event-time" class="headerlink" title="Event-time"></a>Event-time</h3><p>处理时间(process time)很好理解，指的是机器的本地时间，会产生不一致的、不可重复的结果。相反，事件时间(Event-time)能够产生一致的、可重复的结果。然而，相比基于处理时间的应用，基于事件时间的应用需要额外的配置。支持事件时间的流处理引擎的内部比仅仅支持处理时间的流处理引擎的内部更为复杂。</p><p>Flink不仅为常见的事件时间提供直观且易于使用的处理操作，而且也提供了API去自定义实现更高级的事件时间。 对于这样的高级应用，很好的理解Flink的内部时间处理通常是很有帮助的。Flink主要利用两个概念提供事件时间语义：记录时间戳(record timestamps)和watermarks。 接下来，我们将描述Flink内部如何实现和处理时间戳及watermark以支持流应用程序具有事件时间语义的。</p><h4 id="时间戳-timestamps"><a href="#时间戳-timestamps" class="headerlink" title="时间戳(timestamps)"></a>时间戳(timestamps)</h4><p>对于使用事件时间的应用，所处理的记录(record)必须携带时间戳。时间戳将记录与特定时间点相关联，代表事件发生的时间。当Flink以事件时间模式处理数据流时，比如窗口操作，内部会自动的按时间戳将事件发送到相对应的窗口。 Flink会将时间戳编码为16个字节的Long类型的值，并将它们作为元数据附加到记录中。Flink内置的算子会将Long型的值解析为精确到毫秒的Unix时间戳， 但是，自定义算子可以有自己的解析策略，例如，将精度调整为微秒。</p>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅析数据库缓冲池与SQL查询成本</title>
      <link href="/2019/08/14/%E6%B5%85%E6%9E%90%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BC%93%E5%86%B2%E6%B1%A0%E4%B8%8ESQL%E6%9F%A5%E8%AF%A2%E6%88%90%E6%9C%AC/"/>
      <url>/2019/08/14/%E6%B5%85%E6%9E%90%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BC%93%E5%86%B2%E6%B1%A0%E4%B8%8ESQL%E6%9F%A5%E8%AF%A2%E6%88%90%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<p><img src="//jiamaoxiang.top/2019/08/14/浅析数据库缓冲池与SQL查询成本/background.jpg" alt><br>&emsp;&emsp;如果我们想要查找多行记录，查询时间是否会成倍地提升呢？其实数据库会采用缓冲池的方式提升页(page)的查找效率。数据库的缓冲池在数据库中起到了怎样的作用？如何查看一条 SQL 语句需要在缓冲池中进行加载的页的数量呢？</p><hr><h2 id="1-数据库缓冲池"><a href="#1-数据库缓冲池" class="headerlink" title="1.数据库缓冲池"></a>1.数据库缓冲池</h2><p>​        &emsp;&emsp;磁盘 I/O 需要消耗的时间很多，而在内存中进行操作，效率则会高很多，为了能让数据表或者索引中的数据随时被我们所用，DBMS 会申请占用内存来作为数据缓冲池，这样做的好处是可以让磁盘活动最小化，从而减少与磁盘直接进行 I/O 的时间。要知道，这种策略对提升 SQL 语句的查询性能来说至关重要。如果索引的数据在缓冲池里，那么访问的成本就会降低很多。<br>​       &emsp;&emsp;那么缓冲池如何读取数据呢？<br>​        &emsp;&emsp;缓冲池管理器会尽量将经常使用的数据保存起来，在数据库进行页面读操作的时候，首先会判断该页面是否在缓冲池中，如果存在就直接读取，如果不存在，就会通过内存或磁盘将页面存放到缓冲池中再进行读取。</p><h2 id="2-查看缓冲池大小"><a href="#2-查看缓冲池大小" class="headerlink" title="2.查看缓冲池大小"></a>2.查看缓冲池大小</h2><p>​         &emsp;&emsp;如果使用的是 MyISAM 存储引擎(只缓存索引，不缓存数据)，对应的键缓存参数为 key_buffer_size，可以用它进行查看。<br>​        &emsp;&emsp;如果使用的是 InnoDB 存储引擎，可以通过查看 innodb_buffer_pool_size 变量来查看缓冲池的大小，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like <span class="string">'innodb_buffer_pool_size'</span>;</span><br></pre></td></tr></table></figure><p><img src="//jiamaoxiang.top/2019/08/14/浅析数据库缓冲池与SQL查询成本/query_innodb_buffer_size.png" alt><br>​        &emsp;&emsp;此时 InnoDB 的缓冲池大小只有 8388608/1024/1024=8MB，我们可以修改缓冲池大小为 128MB，方法如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; <span class="built_in">set</span> global innodb_buffer_pool_size = 1073741824;</span><br></pre></td></tr></table></figure><p>​      &emsp;&emsp; 在 InnoDB 存储引擎中，可以同时开启多个缓冲池，查看缓冲池的个数，使用命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like <span class="string">'innodb_buffer_pool_instances'</span>;</span><br></pre></td></tr></table></figure><p><img src="//jiamaoxiang.top/2019/08/14/浅析数据库缓冲池与SQL查询成本/innodb_buffer_pool_instance.png" alt><br>​        &emsp;&emsp;只有一个缓冲池。实际上innodb_buffer_pool_instances默认情况下为 8，为什么只显示只有一个呢？这里需要说明的是，如果想要开启多个缓冲池，你首先需要将innodb_buffer_pool_size参数设置为大于等于 1GB，这时innodb_buffer_pool_instances才会大于 1。你可以在 MySQL 的配置文件中对innodb_buffer_pool_size进行设置，大于等于 1GB，然后再针对innodb_buffer_pool_instances参数进行修改。</p><h2 id="3-查看SQL语句的查询成本"><a href="#3-查看SQL语句的查询成本" class="headerlink" title="3.查看SQL语句的查询成本"></a>3.查看SQL语句的查询成本</h2><p>​        &emsp;&emsp; 一条 SQL 查询语句在执行前需要确定查询计划，如果存在多种查询计划的话，MySQL 会计算每个查询计划所需要的成本，从中选择成本最小的一个作为最终执行的查询计划。</p><p>​          &emsp;&emsp;如果查看某条 SQL 语句的查询成本，可以在执行完这条 SQL 语句之后，通过查看当前会话中的 last_query_cost 变量值来得到当前查询的成本。这个查询成本对应的是 SQL 语句所需要读取的页(page)的数量。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show status like <span class="string">'last_query_cost'</span></span><br></pre></td></tr></table></figure><h4 id="example"><a href="#example" class="headerlink" title="example"></a>example</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select userid,rating from movierating <span class="built_in">where</span> userid = 4169;</span><br></pre></td></tr></table></figure><p>结果：2313 rows in set (0.05 sec) </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show status like <span class="string">'last_query_cost'</span>;</span><br></pre></td></tr></table></figure><p><img src="//jiamaoxiang.top/2019/08/14/浅析数据库缓冲池与SQL查询成本/test1.png" alt></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select userid,rating from movierating <span class="built_in">where</span> userid between 4168 and 4175;</span><br></pre></td></tr></table></figure><p>结果：2643 rows in set (0.01 sec) </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show status like <span class="string">'last_query_cost'</span>;</span><br></pre></td></tr></table></figure><p><img src="//jiamaoxiang.top/2019/08/14/浅析数据库缓冲池与SQL查询成本/test2.png" alt></p><p>&emsp;&emsp;你能看到页的数量是刚才的 1.4 倍，但是查询的效率并没有明显的变化，实际上这两个 SQL 查询的时间基本上一样，就是因为采用了顺序读取的方式将页面一次性加载到缓冲池中，然后再进行查找。虽然页数量（last_query_cost）增加了不少，但是通过缓冲池的机制，并没有增加多少查询时间。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Flink自学系列教程</title>
      <link href="/2019/08/13/Flink%E8%87%AA%E5%AD%A6%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B/"/>
      <url>/2019/08/13/Flink%E8%87%AA%E5%AD%A6%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p><img src="//jiamaoxiang.top/2019/08/13/Flink自学系列教程/logo.png" alt><br>&emsp;&emsp;Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态计算。可部署在各种集群环境，对各种大小的数据规模进行快速计算。</p><hr><h4 id="1-Flink的几个重要概念"><a href="#1-Flink的几个重要概念" class="headerlink" title="1.Flink的几个重要概念"></a><a href="https://jiamaoxiang.top/2019/08/19/Flink%E7%9A%84%E5%87%A0%E4%B8%AA%E9%87%8D%E8%A6%81%E6%A6%82%E5%BF%B5/">1.Flink的几个重要概念</a></h4><h4 id="2-DataFrame-API"><a href="#2-DataFrame-API" class="headerlink" title="2. DataFrame API"></a><a href="https://jiamaoxiang.top/2019/08/19/DataFrame-API/">2. DataFrame API</a></h4><h4 id="3-基于时间的算子"><a href="#3-基于时间的算子" class="headerlink" title="3. 基于时间的算子"></a><a href="https://jiamaoxiang.top/2019/08/19/%E5%9F%BA%E4%BA%8E%E6%97%B6%E9%97%B4%E7%9A%84%E7%AE%97%E5%AD%90/">3. 基于时间的算子</a></h4><h4 id="4-状态与容错"><a href="#4-状态与容错" class="headerlink" title="4. 状态与容错"></a><a href="https://jiamaoxiang.top/2019/08/19/%E7%8A%B6%E6%80%81%E4%B8%8E%E5%AE%B9%E9%94%99/">4. 状态与容错</a></h4><h4 id="5-source-sink-Connectors"><a href="#5-source-sink-Connectors" class="headerlink" title="5. source/sink Connectors"></a><a href="https://jiamaoxiang.top/2019/08/19/source-sink-Connectors/">5. source/sink Connectors</a></h4><h4 id="6-集群与部署"><a href="#6-集群与部署" class="headerlink" title="6. 集群与部署"></a><a href="https://jiamaoxiang.top/2019/08/19/%E9%9B%86%E7%BE%A4%E4%B8%8E%E9%83%A8%E7%BD%B2/">6. 集群与部署</a></h4><h4 id="7-运维与监控"><a href="#7-运维与监控" class="headerlink" title="7.运维与监控"></a><a href="https://jiamaoxiang.top/2019/08/19/%E8%BF%90%E7%BB%B4%E4%B8%8E%E7%9B%91%E6%8E%A7/">7.运维与监控</a></h4>]]></content>
      
      
      <categories>
          
          <category> Flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/08/12/hello-world/"/>
      <url>/2019/08/12/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p><p><img src="//jiamaoxiang.top/2019/08/12/hello-world/logo.png" alt></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
