<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jmx&#39;s Blog</title>
  
  <subtitle>Keep it Simple and Stupid!</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://jiamaoxiang.top/"/>
  <updated>2020-04-19T14:00:21.298Z</updated>
  <id>https://jiamaoxiang.top/</id>
  
  <author>
    <name>Jia Maoxiang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Flink的时间与watermarks详解</title>
    <link href="https://jiamaoxiang.top/2020/04/17/Flink%E5%9F%BA%E4%BA%8E%E6%97%B6%E9%97%B4%E4%B8%8E%E7%AA%97%E5%8F%A3%E7%9A%84%E7%AE%97%E5%AD%90/"/>
    <id>https://jiamaoxiang.top/2020/04/17/Flink基于时间与窗口的算子/</id>
    <published>2020-04-17T10:12:57.000Z</published>
    <updated>2020-04-19T14:00:21.298Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;当我们在使用Flink的时候，避免不了要和时间(time)、水位线(watermarks)打交道，理解这些概念是开发分布式流处理应用的基础。那么Flink支持哪些时间语义？Flink是如何处理乱序事件的？什么是水位线？水位线是如何生成的？水位线的传播方式是什么？让我们带着这些问题来开始本文的内容。&lt;/p&gt;
    
    </summary>
    
      <category term="flink" scheme="https://jiamaoxiang.top/categories/flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink DataStream API编程指南</title>
    <link href="https://jiamaoxiang.top/2020/04/12/Flink-DataStream-API%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97/"/>
    <id>https://jiamaoxiang.top/2020/04/12/Flink-DataStream-API编程指南/</id>
    <published>2020-04-12T13:39:43.000Z</published>
    <updated>2020-04-16T15:39:33.802Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Flink DataStream API主要分为三个部分，分别为Source、Transformation以及Sink，其中Source是数据源，Flink内置了很多数据源，比如最常用的Kafka。Transformation是具体的转换操作，主要是用户定义的处理数据的逻辑，比如Map，FlatMap等。Sink(数据汇)是数据的输出，可以把处理之后的数据输出到存储设备上，Flink内置了许多的Sink，比如Kafka，HDFS等。另外除了Flink内置的Source和Sink外，用户可以实现自定义的Source与Sink。考虑到内置的Source与Sink使用起来比较简单且方便，所以，关于内置的Source与Sink的使用方式不在本文的讨论范围之内，本文会先从自定义Source开始说起，然后详细描述一些常见算子的使用方式，最后会实现一个自定义的Sink。&lt;/p&gt;
    
    </summary>
    
      <category term="flink" scheme="https://jiamaoxiang.top/categories/flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>如何使用Hive进行OLAP分析</title>
    <link href="https://jiamaoxiang.top/2020/04/09/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Hive%E8%BF%9B%E8%A1%8COLAP%E5%88%86%E6%9E%90/"/>
    <id>https://jiamaoxiang.top/2020/04/09/如何使用Hive进行OLAP分析/</id>
    <published>2020-04-09T13:44:13.000Z</published>
    <updated>2020-04-11T09:48:43.306Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;本文首先介绍了什么是OLAP，接着介绍Hive中提供的几种OLAP分析的函数，并对每一种函数进行了详细说明，并给出了相关的图示解释，最后以一个案例说明了这几种函数的使用方式，可以进一步加深理解。&lt;/p&gt;
    
    </summary>
    
      <category term="Hive" scheme="https://jiamaoxiang.top/categories/Hive/"/>
    
    
      <category term="Hive" scheme="https://jiamaoxiang.top/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>你真的了解Flink Kafka source吗？</title>
    <link href="https://jiamaoxiang.top/2020/04/02/%E4%BD%A0%E7%9C%9F%E7%9A%84%E4%BA%86%E8%A7%A3Flink-Kafka-connector%E5%90%97%EF%BC%9F/"/>
    <id>https://jiamaoxiang.top/2020/04/02/你真的了解Flink-Kafka-connector吗？/</id>
    <published>2020-04-02T06:29:12.000Z</published>
    <updated>2020-04-11T09:20:58.832Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Flink 提供了专门的 Kafka 连接器，向 Kafka topic 中读取或者写入数据。Flink Kafka Consumer 集成了 Flink 的 Checkpoint 机制，可提供 exactly-once 的处理语义。为此，Flink 并不完全依赖于跟踪 Kafka 消费组的偏移量，而是在内部跟踪和检查偏移量。&lt;/p&gt;
    
    </summary>
    
      <category term="flink" scheme="https://jiamaoxiang.top/categories/flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink1.10集成Hive快速入门</title>
    <link href="https://jiamaoxiang.top/2020/03/31/Flink1-10%E9%9B%86%E6%88%90Hive%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"/>
    <id>https://jiamaoxiang.top/2020/03/31/Flink1-10集成Hive快速入门/</id>
    <published>2020-03-31T04:54:09.000Z</published>
    <updated>2020-04-11T09:46:34.903Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Hive 是大数据领域最早出现的 SQL 引擎，发展至今有着丰富的功能和广泛的用户基础。之后出现的 SQL 引擎，如 Spark SQL、Impala 等，都在一定程度上提供了与 Hive 集成的功能，从而方便用户使用现有的数据仓库、进行作业迁移等。&lt;/p&gt;
    
    </summary>
    
      <category term="flink" scheme="https://jiamaoxiang.top/categories/flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink的八种分区策略源码解读</title>
    <link href="https://jiamaoxiang.top/2020/03/30/Flink%E7%9A%84%E5%85%AB%E7%A7%8D%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"/>
    <id>https://jiamaoxiang.top/2020/03/30/Flink的八种分区策略源码解读/</id>
    <published>2020-03-30T01:47:45.000Z</published>
    <updated>2020-04-14T03:03:45.718Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Flink包含8中分区策略，这8中分区策略(分区器)分别如下面所示，本文将从源码的角度一一解读每个分区器的实现方式。&lt;/p&gt;
    
    </summary>
    
      <category term="flink" scheme="https://jiamaoxiang.top/categories/flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>基于Canal与Flink实现数据实时增量同步(二)</title>
    <link href="https://jiamaoxiang.top/2020/03/24/%E5%9F%BA%E4%BA%8ECanal%E4%B8%8EFlink%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%97%B6%E5%A2%9E%E9%87%8F%E5%90%8C%E6%AD%A5-%E4%BA%8C/"/>
    <id>https://jiamaoxiang.top/2020/03/24/基于Canal与Flink实现数据实时增量同步-二/</id>
    <published>2020-03-24T05:56:57.000Z</published>
    <updated>2020-03-27T14:36:52.958Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;本文主要从Binlog实时采集和离线处理Binlog还原业务数据两个方面，来介绍如何实现DB数据准确、高效地进入Hive数仓。&lt;/p&gt;
    
    </summary>
    
      <category term="Flink" scheme="https://jiamaoxiang.top/categories/Flink/"/>
    
    
      <category term="Flink" scheme="https://jiamaoxiang.top/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>分布式数据集成框架gobblin快速入门</title>
    <link href="https://jiamaoxiang.top/2020/03/22/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90%E6%A1%86%E6%9E%B6gobblin%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"/>
    <id>https://jiamaoxiang.top/2020/03/22/分布式数据集成框架gobblin快速入门/</id>
    <published>2020-03-22T09:45:28.000Z</published>
    <updated>2020-03-22T12:50:45.632Z</updated>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
      <category term="gobblin" scheme="https://jiamaoxiang.top/categories/gobblin/"/>
    
    
      <category term="gobblin" scheme="https://jiamaoxiang.top/tags/gobblin/"/>
    
  </entry>
  
  <entry>
    <title>基于Canal与Flink实现数据实时增量同步(一)</title>
    <link href="https://jiamaoxiang.top/2020/03/05/%E5%9F%BA%E4%BA%8ECanal%E4%B8%8EFlink%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%97%B6%E5%A2%9E%E9%87%8F%E5%90%8C%E6%AD%A5-%E4%B8%80/"/>
    <id>https://jiamaoxiang.top/2020/03/05/基于Canal与Flink实现数据实时增量同步-一/</id>
    <published>2020-03-05T06:46:45.000Z</published>
    <updated>2020-04-11T09:28:35.694Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;canal是阿里巴巴旗下的一款开源项目，纯Java开发。基于数据库增量日志解析，提供增量数据订阅&amp;amp;消费，目前主要支持了MySQL（也支持mariaDB）。&lt;/p&gt;
    
    </summary>
    
      <category term="canal" scheme="https://jiamaoxiang.top/categories/canal/"/>
    
    
      <category term="canal" scheme="https://jiamaoxiang.top/tags/canal/"/>
    
  </entry>
  
  <entry>
    <title>SQL中的相关子查询解析</title>
    <link href="https://jiamaoxiang.top/2019/12/10/SQL%E4%B8%AD%E7%9A%84%E7%9B%B8%E5%85%B3%E5%AD%90%E6%9F%A5%E8%AF%A2%E8%A7%A3%E6%9E%90/"/>
    <id>https://jiamaoxiang.top/2019/12/10/SQL中的相关子查询解析/</id>
    <published>2019-12-10T05:18:59.000Z</published>
    <updated>2019-12-12T05:24:39.067Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;分步骤解析SQL的相关子查询&lt;/p&gt;
    
    </summary>
    
      <category term="SQL" scheme="https://jiamaoxiang.top/categories/SQL/"/>
    
    
      <category term="SQL" scheme="https://jiamaoxiang.top/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>LeeCode数据库部分题目汇总</title>
    <link href="https://jiamaoxiang.top/2019/12/09/LeeCode%E6%95%B0%E6%8D%AE%E5%BA%93%E9%83%A8%E5%88%86%E9%A2%98%E7%9B%AE%E6%B1%87%E6%80%BB/"/>
    <id>https://jiamaoxiang.top/2019/12/09/LeeCode数据库部分题目汇总/</id>
    <published>2019-12-09T02:53:09.000Z</published>
    <updated>2020-03-29T09:53:34.823Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;LeeCode数据库部分SQL题目总结&lt;/p&gt;
    
    </summary>
    
      <category term="LeeCode" scheme="https://jiamaoxiang.top/categories/LeeCode/"/>
    
    
      <category term="LeeCode" scheme="https://jiamaoxiang.top/tags/LeeCode/"/>
    
  </entry>
  
  <entry>
    <title>电商业务常用指标分析之SQL实现</title>
    <link href="https://jiamaoxiang.top/2019/12/05/%E7%94%B5%E5%95%86%E4%B8%9A%E5%8A%A1%E5%B8%B8%E7%94%A8%E6%8C%87%E6%A0%87%E5%88%86%E6%9E%90%E4%B9%8BSQL%E5%AE%9E%E7%8E%B0/"/>
    <id>https://jiamaoxiang.top/2019/12/05/电商业务常用指标分析之SQL实现/</id>
    <published>2019-12-05T01:49:31.000Z</published>
    <updated>2019-12-05T06:50:55.318Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;当构建好电商业务数仓之后，需要对业务需要的指标进行计算，从而进一步进行报表的展示，那么，电商的业务知识大概涉及哪些？关于电商业务的常用指标计算都有哪些？这些常用的指标该如何通过Hive数仓进行分析？本文将进行一一梳理.&lt;/p&gt;
    
    </summary>
    
      <category term="Hive" scheme="https://jiamaoxiang.top/categories/Hive/"/>
    
    
      <category term="Hive" scheme="https://jiamaoxiang.top/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>CDH集群之YARN性能调优</title>
    <link href="https://jiamaoxiang.top/2019/12/03/CDH%E9%9B%86%E7%BE%A4%E4%B9%8BYARN%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"/>
    <id>https://jiamaoxiang.top/2019/12/03/CDH集群之YARN性能调优/</id>
    <published>2019-12-03T03:19:09.000Z</published>
    <updated>2019-12-03T06:35:20.835Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;本文主要讨论CDH集群的YARN调优配置，关于YARN的调优配置，主要关注CPU和内存的调优，其中CPU是指物理CPU个数乘以CPU核数，即Vcores = CPU数量*CPU核数。YARN是以container容器的形式封装资源的，task在container内部执行。&lt;/p&gt;
    
    </summary>
    
      <category term="CDH,YARN" scheme="https://jiamaoxiang.top/categories/CDH-YARN/"/>
    
    
      <category term="CDH,YARN" scheme="https://jiamaoxiang.top/tags/CDH-YARN/"/>
    
  </entry>
  
  <entry>
    <title>历史拉链表实战</title>
    <link href="https://jiamaoxiang.top/2019/11/08/%E5%8E%86%E5%8F%B2%E6%8B%89%E9%93%BE%E8%A1%A8%E5%AE%9E%E6%88%98/"/>
    <id>https://jiamaoxiang.top/2019/11/08/历史拉链表实战/</id>
    <published>2019-11-08T03:12:41.000Z</published>
    <updated>2020-04-08T05:12:33.547Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;历史拉链表是一种数据模型，主要是针对数据仓库设计中表存储数据的方式而定义的。所谓历史拉链表，就是指记录一个事物从开始一直到当前状态的所有变化信息。拉所有记录链表可以避免按每一天存储造成的海量存储问题，同时也是处理缓慢变化数据的一种常见方式。&lt;/p&gt;
    
    </summary>
    
      <category term="数据仓库" scheme="https://jiamaoxiang.top/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"/>
    
    
      <category term="数据仓库" scheme="https://jiamaoxiang.top/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Flink运行架构剖析</title>
    <link href="https://jiamaoxiang.top/2019/10/23/Flink%E8%BF%90%E8%A1%8C%E6%9E%B6%E6%9E%84%E5%89%96%E6%9E%90/"/>
    <id>https://jiamaoxiang.top/2019/10/23/Flink运行架构剖析/</id>
    <published>2019-10-23T03:18:10.000Z</published>
    <updated>2019-10-23T05:30:32.793Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;本文主要介绍 Flink Runtime 的作业执行的核心机制。首先介绍 Flink Runtime 的整体架构以及 Job 的基本执行流程，然后介绍Flink 的Standalone运行架构，最后对Flink on YARN的两种模式进行了详细剖析。&lt;/p&gt;
    
    </summary>
    
      <category term="Flink" scheme="https://jiamaoxiang.top/categories/Flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>经典Hive-SQL面试题</title>
    <link href="https://jiamaoxiang.top/2019/10/15/%E7%BB%8F%E5%85%B8Hive-SQL%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <id>https://jiamaoxiang.top/2019/10/15/经典Hive-SQL面试题/</id>
    <published>2019-10-15T03:04:40.000Z</published>
    <updated>2019-10-23T05:22:36.282Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;HQL练习&lt;/p&gt;
    
    </summary>
    
      <category term="Hive" scheme="https://jiamaoxiang.top/categories/Hive/"/>
    
    
      <category term="Hive" scheme="https://jiamaoxiang.top/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>Impala使用的端口</title>
    <link href="https://jiamaoxiang.top/2019/08/29/Impala%E4%BD%BF%E7%94%A8%E7%9A%84%E7%AB%AF%E5%8F%A3/"/>
    <id>https://jiamaoxiang.top/2019/08/29/Impala使用的端口/</id>
    <published>2019-08-29T05:49:15.000Z</published>
    <updated>2020-04-03T13:06:40.271Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;本文主要介绍了Impala所使用的端口号，在部署Impala的时候，确保下面列出的端口是开启的。&lt;/p&gt;
    
    </summary>
    
      <category term="Impala" scheme="https://jiamaoxiang.top/categories/Impala/"/>
    
    
      <category term="Impala" scheme="https://jiamaoxiang.top/tags/Impala/"/>
    
  </entry>
  
  <entry>
    <title>Azkaban安装部署</title>
    <link href="https://jiamaoxiang.top/2019/08/28/Azkaban%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>https://jiamaoxiang.top/2019/08/28/Azkaban安装部署/</id>
    <published>2019-08-28T02:22:04.000Z</published>
    <updated>2019-08-30T05:35:30.658Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Azkaban是由Linkedin开源的一个批量工作流任务调度器。用于在一个工作流内以一个特定的顺序运行一组工作和流程。Azkaban定义了一种KV文件格式来建立任务之间的依赖关系，并提供一个易于使用的web用户界面维护和跟踪你的工作流。&lt;/p&gt;
    
    </summary>
    
      <category term="Azkaban" scheme="https://jiamaoxiang.top/categories/Azkaban/"/>
    
    
      <category term="Azkaban" scheme="https://jiamaoxiang.top/tags/Azkaban/"/>
    
  </entry>
  
  <entry>
    <title>Flink的数据类型</title>
    <link href="https://jiamaoxiang.top/2019/08/27/Flink%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"/>
    <id>https://jiamaoxiang.top/2019/08/27/Flink的数据类型/</id>
    <published>2019-08-27T01:27:09.000Z</published>
    <updated>2019-08-30T06:48:19.279Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Flink使用type information来代表数据类型，Flink还具有一个类型提取系统，该系统分析函数的输入和返回类型，以自动获取类型信息(type information)，从而获得序列化程序和反序列化程序。但是，在某些情况下，例如lambda函数或泛型类型，需要显式地提供类型信息((type information)),从而提高其性能。本文主要讨论包括：(1)Flink支持的数据类型,(2)如何为数据类型创建type information，（3）如果无法自动推断函数的返回类型，如何使用提示(hints)来帮助Flink的类型系统识别类型信息。&lt;/p&gt;
    
    </summary>
    
      <category term="Flink" scheme="https://jiamaoxiang.top/categories/Flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>基于SparkStreaming的日志分析项目</title>
    <link href="https://jiamaoxiang.top/2019/08/26/%E5%9F%BA%E4%BA%8ESparkStreaming%E7%9A%84%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E9%A1%B9%E7%9B%AE/"/>
    <id>https://jiamaoxiang.top/2019/08/26/基于SparkStreaming的日志分析项目/</id>
    <published>2019-08-26T02:06:04.000Z</published>
    <updated>2019-08-26T06:18:49.821Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;基于SparkStreaming实现实时的日志分析，首先基于discuz搭建一个论坛平台，然后将该论坛的日志写入到指定文件，最后通过SparkStreaming实时对日志进行分析。&lt;/p&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://jiamaoxiang.top/categories/Spark/"/>
    
    
      <category term="Spark" scheme="https://jiamaoxiang.top/tags/Spark/"/>
    
  </entry>
  
</feed>
