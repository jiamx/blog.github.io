<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jmx&#39;s Blog</title>
  
  <subtitle>Keep it Simple and Stupid!</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://jiamaoxiang.top/"/>
  <updated>2020-06-27T15:21:38.683Z</updated>
  <id>https://jiamaoxiang.top/</id>
  
  <author>
    <name>Jia Maoxiang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hive的架构剖析</title>
    <link href="https://jiamaoxiang.top/2020/06/27/Hive%E7%9A%84%E6%9E%B6%E6%9E%84%E5%89%96%E6%9E%90/"/>
    <id>https://jiamaoxiang.top/2020/06/27/Hive的架构剖析/</id>
    <published>2020-06-27T12:01:37.000Z</published>
    <updated>2020-06-27T15:21:38.683Z</updated>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
      <category term="Hive" scheme="https://jiamaoxiang.top/categories/Hive/"/>
    
    
      <category term="Hive" scheme="https://jiamaoxiang.top/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>数据分析|使用多元线性回归构建销售额预测模型</title>
    <link href="https://jiamaoxiang.top/2020/06/26/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-%E4%BD%BF%E7%94%A8%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%9E%84%E5%BB%BA%E9%94%80%E5%94%AE%E9%A2%9D%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B/"/>
    <id>https://jiamaoxiang.top/2020/06/26/数据分析-使用多元线性回归构建销售额预测模型/</id>
    <published>2020-06-26T13:29:31.000Z</published>
    <updated>2020-06-26T15:46:44.936Z</updated>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
      <category term="回归分析" scheme="https://jiamaoxiang.top/categories/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/"/>
    
    
      <category term="回归分析" scheme="https://jiamaoxiang.top/tags/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>‘Hive on MR执行计划与执行日志解析</title>
    <link href="https://jiamaoxiang.top/2020/06/10/%E2%80%98Hive-on-MR%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E8%A7%A3%E6%9E%90/"/>
    <id>https://jiamaoxiang.top/2020/06/10/‘Hive-on-MR执行计划解析/</id>
    <published>2020-06-10T03:34:45.000Z</published>
    <updated>2020-06-19T10:32:34.451Z</updated>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
      <category term="Hive" scheme="https://jiamaoxiang.top/categories/Hive/"/>
    
    
      <category term="Hive" scheme="https://jiamaoxiang.top/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>数仓|Hive性能调优指北</title>
    <link href="https://jiamaoxiang.top/2020/06/06/%E6%95%B0%E4%BB%93-Hive%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E6%8C%87%E5%8C%97/"/>
    <id>https://jiamaoxiang.top/2020/06/06/数仓-Hive性能调优指北/</id>
    <published>2020-06-06T07:05:52.000Z</published>
    <updated>2020-06-07T07:26:55.636Z</updated>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
      <category term="Hive" scheme="https://jiamaoxiang.top/categories/Hive/"/>
    
    
      <category term="Hive" scheme="https://jiamaoxiang.top/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>‘实时数仓|基于Flink SQL构建实时数仓探索实践</title>
    <link href="https://jiamaoxiang.top/2020/06/05/%E2%80%98%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93-%E5%9F%BA%E4%BA%8EFlink-SQL%E6%9E%84%E5%BB%BA%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E6%8E%A2%E7%B4%A2%E5%AE%9E%E8%B7%B5/"/>
    <id>https://jiamaoxiang.top/2020/06/05/‘实时数仓-基于Flink-SQL构建实时数仓探索实践/</id>
    <published>2020-06-05T03:30:09.000Z</published>
    <updated>2020-06-05T03:30:09.917Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>实时数仓|Flink SQL之维表join</title>
    <link href="https://jiamaoxiang.top/2020/06/05/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93-Flink-SQL%E4%B9%8B%E7%BB%B4%E8%A1%A8join/"/>
    <id>https://jiamaoxiang.top/2020/06/05/实时数仓-Flink-SQL之维表join/</id>
    <published>2020-06-05T03:27:59.000Z</published>
    <updated>2020-06-09T15:06:20.479Z</updated>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
      <category term="Flink" scheme="https://jiamaoxiang.top/categories/Flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink Table API&amp;SQL编程指南之时间属性(3)</title>
    <link href="https://jiamaoxiang.top/2020/06/02/Flink-Table-API-SQL%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97%E4%B9%8B%E6%97%B6%E9%97%B4%E5%B1%9E%E6%80%A7-3/"/>
    <id>https://jiamaoxiang.top/2020/06/02/Flink-Table-API-SQL编程指南之时间属性-3/</id>
    <published>2020-06-02T07:12:47.000Z</published>
    <updated>2020-06-02T09:14:50.214Z</updated>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
      <category term="Flink" scheme="https://jiamaoxiang.top/categories/Flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>数仓开发需要了解的BI数据分析方法</title>
    <link href="https://jiamaoxiang.top/2020/05/28/%E6%95%B0%E4%BB%93%E5%BC%80%E5%8F%91%E9%9C%80%E8%A6%81%E4%BA%86%E8%A7%A3%E7%9A%84BI%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95/"/>
    <id>https://jiamaoxiang.top/2020/05/28/数仓开发需要了解的BI数据分析方法/</id>
    <published>2020-05-28T08:47:47.000Z</published>
    <updated>2020-05-30T16:03:10.057Z</updated>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
      <category term="数仓" scheme="https://jiamaoxiang.top/categories/%E6%95%B0%E4%BB%93/"/>
    
    
      <category term="数仓" scheme="https://jiamaoxiang.top/tags/%E6%95%B0%E4%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Flink Table API &amp; SQL编程指南之动态表(2)</title>
    <link href="https://jiamaoxiang.top/2020/05/28/Flink-Table-API-SQL%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97-2/"/>
    <id>https://jiamaoxiang.top/2020/05/28/Flink-Table-API-SQL编程指南-2/</id>
    <published>2020-05-28T01:56:25.000Z</published>
    <updated>2020-06-02T14:07:02.619Z</updated>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
      <category term="Flink" scheme="https://jiamaoxiang.top/categories/Flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink Table API &amp; SQL编程指南(1)</title>
    <link href="https://jiamaoxiang.top/2020/05/25/Flink-Table-API-SQL%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97/"/>
    <id>https://jiamaoxiang.top/2020/05/25/Flink-Table-API-SQL编程指南/</id>
    <published>2020-05-25T08:40:50.000Z</published>
    <updated>2020-05-28T01:50:01.801Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Apache Flink提供了两种顶层的关系型API，分别为Table API和SQL，Flink通过Table API&amp;amp;SQL实现了批流统一。其中Table API是用于Scala和Java的语言集成查询API，它允许以非常直观的方式组合关系运算符（例如select，where和join）的查询。Flink SQL基于&lt;a href=&quot;https://calcite.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Apache Calcite&lt;/a&gt; 实现了标准的SQL，用户可以使用标准的SQL处理数据集。Table API和SQL与Flink的DataStream和DataSet API紧密集成在一起，用户可以实现相互转化，比如可以将DataStream或者DataSet注册为table进行操作数据。值得注意的是，&lt;strong&gt;Table API and SQL&lt;/strong&gt;目前尚未完全完善，还在积极的开发中，所以并不是所有的算子操作都可以通过其实现。&lt;/p&gt;
    
    </summary>
    
      <category term="Flink" scheme="https://jiamaoxiang.top/categories/Flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>一统江湖的数仓开发辅助神器--DBeaver</title>
    <link href="https://jiamaoxiang.top/2020/05/21/%E4%B8%80%E7%BB%9F%E6%B1%9F%E6%B9%96%E7%9A%84%E6%95%B0%E4%BB%93%E5%BC%80%E5%8F%91%E8%BE%85%E5%8A%A9%E7%A5%9E%E5%99%A8-DBeaver/"/>
    <id>https://jiamaoxiang.top/2020/05/21/一统江湖的数仓开发辅助神器-DBeaver/</id>
    <published>2020-05-21T14:02:16.000Z</published>
    <updated>2020-05-23T15:09:43.725Z</updated>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
      <category term="数仓" scheme="https://jiamaoxiang.top/categories/%E6%95%B0%E4%BB%93/"/>
    
    
      <category term="DBeaver" scheme="https://jiamaoxiang.top/tags/DBeaver/"/>
    
  </entry>
  
  <entry>
    <title>Hive的条件函数与日期函数全面汇总解析</title>
    <link href="https://jiamaoxiang.top/2020/05/20/Hive%E7%9A%84%E6%9D%A1%E4%BB%B6%E5%87%BD%E6%95%B0%E4%B8%8E%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0%E5%85%A8%E9%9D%A2%E6%B1%87%E6%80%BB%E8%A7%A3%E6%9E%90/"/>
    <id>https://jiamaoxiang.top/2020/05/20/Hive的条件函数与日期函数全面汇总解析/</id>
    <published>2020-05-20T05:52:22.000Z</published>
    <updated>2020-05-20T09:40:10.600Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;在&lt;a href=&quot;https://mp.weixin.qq.com/s/K2TA_PhNzGEkucYxBXqhLw&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hive的开窗函数实战&lt;/a&gt;的文章中，主要介绍了Hive的分析函数的基本使用。本文是这篇文章的延续，涵盖了Hive所有的条件函数和日期函数，对于每个函数，本文都给出了具体的解释和使用案例，方便在工作中查阅。&lt;/p&gt;
    
    </summary>
    
      <category term="Hive" scheme="https://jiamaoxiang.top/categories/Hive/"/>
    
    
      <category term="Hive" scheme="https://jiamaoxiang.top/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>Greenplum集群Master与Segment节点故障检测与恢复</title>
    <link href="https://jiamaoxiang.top/2020/05/18/Greenplum%E9%9B%86%E7%BE%A4Master%E4%B8%8ESegment%E8%8A%82%E7%82%B9%E6%95%85%E9%9A%9C%E6%A3%80%E6%B5%8B%E4%B8%8E%E6%81%A2%E5%A4%8D/"/>
    <id>https://jiamaoxiang.top/2020/05/18/Greenplum集群Master与Segment节点故障检测与恢复/</id>
    <published>2020-05-18T13:07:17.000Z</published>
    <updated>2020-05-18T15:43:34.972Z</updated>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
      <category term="greenplum" scheme="https://jiamaoxiang.top/categories/greenplum/"/>
    
    
      <category term="greenplum" scheme="https://jiamaoxiang.top/tags/greenplum/"/>
    
  </entry>
  
  <entry>
    <title>Flink DataSet API编程指南</title>
    <link href="https://jiamaoxiang.top/2020/05/09/Flink-DataSet-API%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97/"/>
    <id>https://jiamaoxiang.top/2020/05/09/Flink-DataSet-API编程指南/</id>
    <published>2020-05-09T02:12:40.000Z</published>
    <updated>2020-05-12T07:47:19.337Z</updated>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
      <category term="Flink" scheme="https://jiamaoxiang.top/categories/Flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink DataStream API 中的多面手——Process Function详解</title>
    <link href="https://jiamaoxiang.top/2020/04/30/Flink-DataStream-API-%E4%B8%AD%E7%9A%84%E5%A4%9A%E9%9D%A2%E6%89%8B%E2%80%94%E2%80%94Process-Function%E8%AF%A6%E8%A7%A3/"/>
    <id>https://jiamaoxiang.top/2020/04/30/Flink-DataStream-API-中的多面手——Process-Function详解/</id>
    <published>2020-04-30T07:01:11.000Z</published>
    <updated>2020-05-06T01:43:02.002Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;在&lt;a href=&quot;https://mp.weixin.qq.com/s/ycz_N5m6RjsW9ZBhNMvACw&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Flink的时间与watermarks详解&lt;/a&gt;这篇文章中，阐述了Flink的时间与水位线的相关内容。你可能不禁要发问，该如何访问时间戳和水位线呢？首先通过普通的DataStream API是无法访问的，需要借助Flink提供的一个底层的API——Process  Function。Process Function不仅能够访问时间戳与水位线，而且还可以注册在将来的某个特定时间触发的计时器(timers)。除此之外，还可以将数据通过Side Outputs发送到多个输出流中。这样以来，可以实现数据分流的功能，同时也是处理迟到数据的一种方式。下面我们将从源码入手，结合具体的使用案例来说明该如何使用Process  Function。&lt;/p&gt;
    
    </summary>
    
      <category term="Flink" scheme="https://jiamaoxiang.top/categories/Flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink内部Exactly Once三板斧:状态、状态后端与检查点</title>
    <link href="https://jiamaoxiang.top/2020/04/25/Flink%E5%86%85%E9%83%A8Exactly-Once%E4%B8%89%E6%9D%BF%E6%96%A7-%E7%8A%B6%E6%80%81%E3%80%81%E7%8A%B6%E6%80%81%E5%90%8E%E7%AB%AF%E4%B8%8E%E6%A3%80%E6%9F%A5%E7%82%B9/"/>
    <id>https://jiamaoxiang.top/2020/04/25/Flink内部Exactly-Once三板斧-状态、状态后端与检查点/</id>
    <published>2020-04-25T12:00:00.000Z</published>
    <updated>2020-05-06T01:43:54.778Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Flink是一个分布式的流处理引擎，而流处理的其中一个特点就是7X24。那么，如何保障Flink作业的持续运行呢？Flink的内部会将应用状态(state)存储到本地内存或者嵌入式的kv数据库(RocksDB)中，由于采用的是分布式架构，Flink需要对本地生成的状态进行持久化存储，以避免因应用或者节点机器故障等原因导致数据的丢失，Flink是通过checkpoint(检查点)的方式将状态写入到远程的持久化存储，从而就可以实现不同语义的结果保障。通过本文，你可以了解到什么是Flink的状态，Flink的状态是怎么存储的，Flink可选择的状态后端(statebackend)有哪些，什么是全局一致性检查点，Flink内部如何通过检查点实现Exactly Once的结果保障。另外，本文内容较长，建议关注加收藏。&lt;/p&gt;
    
    </summary>
    
      <category term="Flink" scheme="https://jiamaoxiang.top/categories/Flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink的时间与watermarks详解</title>
    <link href="https://jiamaoxiang.top/2020/04/17/Flink%E5%9F%BA%E4%BA%8E%E6%97%B6%E9%97%B4%E4%B8%8E%E7%AA%97%E5%8F%A3%E7%9A%84%E7%AE%97%E5%AD%90/"/>
    <id>https://jiamaoxiang.top/2020/04/17/Flink基于时间与窗口的算子/</id>
    <published>2020-04-17T10:12:57.000Z</published>
    <updated>2020-05-06T01:43:43.961Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;当我们在使用Flink的时候，避免不了要和时间(time)、水位线(watermarks)打交道，理解这些概念是开发分布式流处理应用的基础。那么Flink支持哪些时间语义？Flink是如何处理乱序事件的？什么是水位线？水位线是如何生成的？水位线的传播方式是什么？让我们带着这些问题来开始本文的内容。&lt;/p&gt;
    
    </summary>
    
      <category term="Flink" scheme="https://jiamaoxiang.top/categories/Flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink DataStream API编程指南</title>
    <link href="https://jiamaoxiang.top/2020/04/12/Flink-DataStream-API%E7%BC%96%E7%A8%8B%E6%8C%87%E5%8D%97/"/>
    <id>https://jiamaoxiang.top/2020/04/12/Flink-DataStream-API编程指南/</id>
    <published>2020-04-12T13:39:43.000Z</published>
    <updated>2020-05-06T01:42:51.059Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Flink DataStream API主要分为三个部分，分别为Source、Transformation以及Sink，其中Source是数据源，Flink内置了很多数据源，比如最常用的Kafka。Transformation是具体的转换操作，主要是用户定义的处理数据的逻辑，比如Map，FlatMap等。Sink(数据汇)是数据的输出，可以把处理之后的数据输出到存储设备上，Flink内置了许多的Sink，比如Kafka，HDFS等。另外除了Flink内置的Source和Sink外，用户可以实现自定义的Source与Sink。考虑到内置的Source与Sink使用起来比较简单且方便，所以，关于内置的Source与Sink的使用方式不在本文的讨论范围之内，本文会先从自定义Source开始说起，然后详细描述一些常见算子的使用方式，最后会实现一个自定义的Sink。&lt;/p&gt;
    
    </summary>
    
      <category term="Flink" scheme="https://jiamaoxiang.top/categories/Flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>如何使用Hive进行OLAP分析</title>
    <link href="https://jiamaoxiang.top/2020/04/09/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Hive%E8%BF%9B%E8%A1%8COLAP%E5%88%86%E6%9E%90/"/>
    <id>https://jiamaoxiang.top/2020/04/09/如何使用Hive进行OLAP分析/</id>
    <published>2020-04-09T13:44:13.000Z</published>
    <updated>2020-04-11T09:48:43.306Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;本文首先介绍了什么是OLAP，接着介绍Hive中提供的几种OLAP分析的函数，并对每一种函数进行了详细说明，并给出了相关的图示解释，最后以一个案例说明了这几种函数的使用方式，可以进一步加深理解。&lt;/p&gt;
    
    </summary>
    
      <category term="Hive" scheme="https://jiamaoxiang.top/categories/Hive/"/>
    
    
      <category term="Hive" scheme="https://jiamaoxiang.top/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>你真的了解Flink Kafka source吗？</title>
    <link href="https://jiamaoxiang.top/2020/04/02/%E4%BD%A0%E7%9C%9F%E7%9A%84%E4%BA%86%E8%A7%A3Flink-Kafka-connector%E5%90%97%EF%BC%9F/"/>
    <id>https://jiamaoxiang.top/2020/04/02/你真的了解Flink-Kafka-connector吗？/</id>
    <published>2020-04-02T06:29:12.000Z</published>
    <updated>2020-05-06T01:42:04.481Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Flink 提供了专门的 Kafka 连接器，向 Kafka topic 中读取或者写入数据。Flink Kafka Consumer 集成了 Flink 的 Checkpoint 机制，可提供 exactly-once 的处理语义。为此，Flink 并不完全依赖于跟踪 Kafka 消费组的偏移量，而是在内部跟踪和检查偏移量。&lt;/p&gt;
    
    </summary>
    
      <category term="Flink" scheme="https://jiamaoxiang.top/categories/Flink/"/>
    
    
      <category term="flink" scheme="https://jiamaoxiang.top/tags/flink/"/>
    
  </entry>
  
</feed>
